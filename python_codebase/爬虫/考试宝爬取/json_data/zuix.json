{
  "code": "200",
  "data": [
    {
      "chapter": "0",
      "question": " 关于GaussDB 200的逻辑架构，下列说法正确的是",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:46",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "D",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" DN是实际数据节点，所以只负责存储数据。\"},{\"Key\":\"B\",\"Value\":\" CN是协调节点，协助CM管理整个集群。\"},{\"Key\":\"C\",\"Value\":\" CM是集群的管理模块，那么负责集群的日常管理和运维。\"},{\"Key\":\"D\",\"Value\":\" GTM是全局事务控制器，负责生成和维护全局事务ID等全局唯一信息。\"}]",
      "id": "394096093",
      "paperid": "3211551",
      "hash": "f569b9101574b2c4e8c4f65b0c88d8edca0927dd",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "flume 传输数据过程中，为了防止数据不丢失，使用的 Channel 类型是？（）",
      "qtype": "1",
      "created_at": "2022-01-01 20:41:39",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"Memory Channel\"},{\"Key\":\"B\",\"Value\":\"File Channel\"},{\"Key\":\"C\",\"Value\":\"JDBC Channel\"},{\"Key\":\"D\",\"Value\":\"HDFS Channel\"}]",
      "id": "334414241",
      "paperid": "3211551",
      "hash": "aeda4f6710603c846276017eb051acd32204cfc9",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Action 是 RDD 的算子的一个类型， 不可以将结果写入( ) .",
      "qtype": "1",
      "created_at": "2022-01-01 20:41:39",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"磁盘\"},{\"Key\":\"B\",\"Value\":\"CPU\"},{\"Key\":\"C\",\"Value\":\"HDFS\"},{\"Key\":\"D\",\"Value\":\"数据库\"}]",
      "id": "334414046",
      "paperid": "3211551",
      "hash": "5f953a4e1cd1a5baad62f486d69d2ede1de43b8f",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "关于GES技术原理，下列错误的是哪—项?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:22",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "C",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 基于HBase的分布式存储机制，能够处理海量数据\"},{\"Key\":\"B\",\"Value\":\" 基于ElasticSearch的素引机制，能够根据索引快速查询数据\"},{\"Key\":\"C\",\"Value\":\" 基于Varn的资源调度，可以并行执行多任务\"},{\"Key\":\"D\",\"Value\":\" 基于Spark的分布式内存计算技术，支持数据快速导入\"}]",
      "id": "394095442",
      "paperid": "3211551",
      "hash": "1e226876f041f99cbb76eb30f2baa0c5d1e24d4a",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "金融行业实时风控场景中描述错误的是（）。",
      "qtype": "1",
      "created_at": "2022-01-21 16:56:55",
      "analysis": "",
      "parentid": "0",
      "difficulty": "1",
      "uid": "1090076",
      "path": "",
      "answer": "D",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[{\"Key\":\"A\",\"Value\":\"<p>风险识别需要对交易数据进行清洗补齐，并提取风险特征。<\\/p>\"},{\"Key\":\"B\",\"Value\":\"<p>数据采集从多种交易终端上实时采集交易数据，并针对历史交易数据同步抽取。<\\/p>\"},{\"Key\":\"C\",\"Value\":\"<p>业务需求要求快：分钟级欺诈识别。<\\/p>\"},{\"Key\":\"D\",\"Value\":\"<p>支持丰富的模型。<\\/p>\"}]",
      "id": "351080074",
      "paperid": "3211551",
      "hash": "83e6fd001af020e818536b1bcc367ee42ae381fb",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "大数据技术的4V特征不包括以下哪项？",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:46",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" Virtual\"},{\"Key\":\"B\",\"Value\":\" Velocity\"},{\"Key\":\"C\",\"Value\":\" Variety\"},{\"Key\":\"D\",\"Value\":\" Volume 、\"}]",
      "id": "394096005",
      "paperid": "3211551",
      "hash": "29e90442fd3f445713334137469dc0a58591c9de",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "对ElasticSearch描述正确的是（ ）。",
      "qtype": "1",
      "created_at": "2021-12-29 09:42:28",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[{\"Key\":\"A\",\"Value\":\"<p>客户端必须把索引请求发给shard<\\/p>\"},{\"Key\":\"B\",\"Value\":\"<p>客户端必须把索引请求发给EsNode<\\/p>\"},{\"Key\":\"C\",\"Value\":\"<p>客户端必须把索引请求发给EsMaster<\\/p>\"},{\"Key\":\"D\",\"Value\":\"<p>客户端必须把索引请求发给指定的EsNode<\\/p>\"}]",
      "id": "330824071",
      "paperid": "3211551",
      "hash": "65516ef4767c16e92a85a91acfc934f0bcfbd4d2",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "HBase客户端提供了很多命令，关于1ist命令，下列正确是哪一项？",
      "qtype": "1",
      "created_at": "2022-01-21 16:45:16",
      "analysis": "",
      "parentid": "0",
      "difficulty": "1",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[{\"Key\":\"A\",\"Value\":\"<p>查看帮助命令<\\/p>\"},{\"Key\":\"B\",\"Value\":\"<p>查看所有的表<\\/p>\"},{\"Key\":\"C\",\"Value\":\"<p>查询表数据<\\/p>\"},{\"Key\":\"D\",\"Value\":\"<p>查询命名空间<\\/p>\"}]",
      "id": "351068213",
      "paperid": "3211551",
      "hash": "5312ddd3585c5c1ee9790141393dc9a315a16dcf",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "考虑以下场景，HBase有列簇CF1.列C1.C2.当读取HBase 表时。只要求近回C1的列值，使用下列哪个选项可以实现该功能?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "C",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" ColumFilter\"},{\"Key\":\"B\",\"Value\":\" ValueFilte\"},{\"Key\":\"C\",\"Value\":\" QualifierFilte\"},{\"Key\":\"D\",\"Value\":\" RowFilter\"}]",
      "id": "394095118",
      "paperid": "3211551",
      "hash": "702da1048da1ec8e4651786ce91913ac22f436b1",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Flink中的DataStream数据流转不包含以下哪项?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "D",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" Data source\"},{\"Key\":\"B\",\"Value\":\" Transformations\"},{\"Key\":\"C\",\"Value\":\" Data sink\"},{\"Key\":\"D\",\"Value\":\" Actions\"}]",
      "id": "394095142",
      "paperid": "3211551",
      "hash": "7951422f41fdb672cf7b8aa3171474f743d4317e",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "如果想把Redis的Key中存储的数字值减1，该使用下列哪一个命令?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" decr\"},{\"Key\":\"B\",\"Value\":\" incr\"},{\"Key\":\"C\",\"Value\":\" incrby\"},{\"Key\":\"D\",\"Value\":\" decrby\"}]",
      "id": "394095106",
      "paperid": "3211551",
      "hash": "e04e5222bfa2cfbe7e633169bb7dae5b90ea997e",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " ElasticSearch数据写入阶段有很多调优方式，下列错误的是哪—项?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 写入前副本数设置为0\"},{\"Key\":\"B\",\"Value\":\" 禁用wildcard\"},{\"Key\":\"C\",\"Value\":\" 尽量使用自动生成的id\"},{\"Key\":\"D\",\"Value\":\" 写入过程中：采取bulk批量写入\"}]",
      "id": "394095111",
      "paperid": "3211551",
      "hash": "d1d43a875d43ab4afb9fbd499a832be1317761ea",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "以下哪个不是离线批处理的核心诉求?（）",
      "qtype": "1",
      "created_at": "2022-01-01 20:41:39",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "D",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"处理数据格式多样\"},{\"Key\":\"B\",\"Value\":\"处理数据量巨大\"},{\"Key\":\"C\",\"Value\":\"支持 SQL 类作业和自定义作业\"},{\"Key\":\"D\",\"Value\":\"处理时间要求高\"}]",
      "id": "334414248",
      "paperid": "3211551",
      "hash": "08052b13332c684e8411af90aafe95175c246a6a",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " 某开发小组计划利用GraphBase 实现一些功能，以下哪些功能可以实现?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:46",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "D",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 物流最优路径规划\"},{\"Key\":\"B\",\"Value\":\" 社交分析\"},{\"Key\":\"C\",\"Value\":\" 金融反欺诈\"},{\"Key\":\"D\",\"Value\":\" 以上全都正确\"}]",
      "id": "394096067",
      "paperid": "3211551",
      "hash": "9cf72a71e107a643d853ccf7ff497fbbe1023d2f",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "对于 HBase 表设计描述错误的是?（）",
      "qtype": "1",
      "created_at": "2022-01-01 20:41:39",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "D",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"一张表可以创建多个 Column Family\"},{\"Key\":\"B\",\"Value\":\"TTL 默认为一天\"},{\"Key\":\"C\",\"Value\":\"Region 建议预先创建\"},{\"Key\":\"D\",\"Value\":\"Max Version 无法人为修改\"}]",
      "id": "334414239",
      "paperid": "3211551",
      "hash": "ff3c38a9e399bd83f9aa2f492c6142305c14cd85",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "以下选项不属于Flume的特点的是?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:46",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "D",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 支持定制各类方数据发送\"},{\"Key\":\"B\",\"Value\":\" 支持结构化、非结构化数据源\"},{\"Key\":\"C\",\"Value\":\" 支持多级联操作\"},{\"Key\":\"D\",\"Value\":\" 支持数据实时检索\"}]",
      "id": "394095985",
      "paperid": "3211551",
      "hash": "744a415ce03a844ed4059e23a590eb0be4a6e0d2",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "企业数据分析平台在根据不同的业务场景需求，搭建不同的大数据分析平台，如适应离线批处理的Hadoop平台;适应实时处理的流计算平台等，这种架构属于哪种类型的架构?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 分离架构\"},{\"Key\":\"B\",\"Value\":\" 单一架构\"},{\"Key\":\"C\",\"Value\":\" 融合架构\"},{\"Key\":\"D\",\"Value\":\" 多维架构\"}]",
      "id": "394095097",
      "paperid": "3211551",
      "hash": "9c10ef4ab3dc6bddd102b66b5e8741da57307f2a",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "GaussDB 200 的 EXECUtE IMEDIATE 语法和 OPEN FOR 语法都可以实现动态语句的执行， 那么二者的异同是() ?",
      "qtype": "1",
      "created_at": "2022-01-01 20:41:39",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"EXECUTE IMMEDIATE 没有返回值，OPEN FOR 有返回值。\"},{\"Key\":\"B\",\"Value\":\"当需要将查询的结果保存在一个数据集时， 可使用 OPEN FOR 实现动态查询。\"},{\"Key\":\"C\",\"Value\":\"EXECUTE IMMEDIATE 通过动态执行 SELECT 语句， OPEN FOR 结合了游标的使用。\"},{\"Key\":\"D\",\"Value\":\"EXECUTE INMEDIATE 可以调用存储过程，OPEN FOR 则不行。\"}]",
      "id": "334414144",
      "paperid": "3211551",
      "hash": "beaca90dbd4d8f031462165e9ab9432afe5f6cf4",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " 下面关于GaussDB 200的跨集群协同分析，说法正确的是()?",
      "qtype": "1",
      "created_at": "2022-02-19 18:35:30",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 跨集群所指的集群是GaussDB集群。\"},{\"Key\":\"B\",\"Value\":\" 跨集群协同分析时其他集群会将要查询的数据移动到目标集群，供目标集群查询。\"},{\"Key\":\"C\",\"Value\":\" 跨集群协同分析支持SQL算子下推。\"},{\"Key\":\"D\",\"Value\":\" 跨集群过程中只需要输入集群IP地址和端口就可以访问其他集群的数据。\"}]",
      "id": "369558964",
      "paperid": "3211551",
      "hash": "a8684594406dbd113e60cc051ee2ebfc54428df7",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "HBase的Region是由哪个服务进程来管理的？",
      "qtype": "1",
      "created_at": "2022-01-21 16:49:29",
      "analysis": "",
      "parentid": "0",
      "difficulty": "1",
      "uid": "1090076",
      "path": "",
      "answer": "D",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[{\"Key\":\"A\",\"Value\":\"<p>DataNode<\\/p>\"},{\"Key\":\"B\",\"Value\":\"<p>ZooKeeper<\\/p>\"},{\"Key\":\"C\",\"Value\":\"<p>HMaster<\\/p>\"},{\"Key\":\"D\",\"Value\":\"<p>HRegionServer<\\/p>\"}]",
      "id": "351072053",
      "paperid": "3211551",
      "hash": "ac1bec0aacd116c59a7b79bedfcdbab95a430210",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "常用的数据收集工具不包括以下哪个选项？",
      "qtype": "1",
      "created_at": "2021-12-29 09:42:28",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "D",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" Loader\"},{\"Key\":\"B\",\"Value\":\" Sqoop\"},{\"Key\":\"C\",\"Value\":\" Kettle\"},{\"Key\":\"D\",\"Value\":\"Spark\"}]",
      "id": "330824051",
      "paperid": "3211551",
      "hash": "b95b52b382c0f5beb147cd5c27343a9f664ddf17",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "HBase 的物理存储单元是什么?（）",
      "qtype": "1",
      "created_at": "2022-01-01 20:41:39",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"Region\"},{\"Key\":\"B\",\"Value\":\"Column Family\"},{\"Key\":\"C\",\"Value\":\"Column\"},{\"Key\":\"D\",\"Value\":\"Row\"}]",
      "id": "334414246",
      "paperid": "3211551",
      "hash": "5bfd36290977ca777dc329e0838ad43eb36fed84",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " 对Base集群架构组成部分描述错误的是（ ）。",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:22",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 正常HBase表只有一个Region，随着数据增多Region不断分裂变成多个，Region的拆分非常慢。\"},{\"Key\":\"B\",\"Value\":\" Client包含访问HBase的接口，同时缓存维护已经访问过的Region的位置信息。\"},{\"Key\":\"C\",\"Value\":\" HMaster主要负责表和Region的管理工作，Region的负戴均衡\"},{\"Key\":\"D\",\"Value\":\" HRegionServer是Base的数据服务进程，负奏处理用户的数据读写请求。\"}]",
      "id": "394095435",
      "paperid": "3211551",
      "hash": "cb61da953cff059c378cc268c436ad6c9d31d86c",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "网站在运营过程中，会有用户访问并产生行为数据，要想对这些数据进行处理挖掘，如果是离线批处理下的方案配置，描述不正确的是",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "C",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 数据导入导出，Loader\"},{\"Key\":\"B\",\"Value\":\" 数据采集传输：Flume\"},{\"Key\":\"C\",\"Value\":\" 数据计算，Storm\"},{\"Key\":\"D\",\"Value\":\" 数据存储.HDFS或MySql\"}]",
      "id": "394095088",
      "paperid": "3211551",
      "hash": "af93be6fb1517995677a256f13b54e752320832d",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "HDFS默认的副本是几份?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:22",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 5\"},{\"Key\":\"B\",\"Value\":\" 3\"},{\"Key\":\"C\",\"Value\":\" 6\"},{\"Key\":\"D\",\"Value\":\" 4\"}]",
      "id": "394095438",
      "paperid": "3211551",
      "hash": "b14d8c9b0ee440e5ab5c9a89019e9f0c234dd9b7",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " 创建存储过程，CREATE OR REPLACE PROCEDURE proc_whi1e_1oop（maxval in integer） AS DECLAREl int: =maxval/2; BEGINWHILE i&lt;maxval LOOP raise info'%', i; i: =i+1; ENDLOOP:END:下面循环语句在 Messages 内的输出是（）CALL proc_while_loop（9）;",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "D",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 5678\"},{\"Key\":\"B\",\"Value\":\" 456789\"},{\"Key\":\"C\",\"Value\":\" 56789\"},{\"Key\":\"D\",\"Value\":\" 45678\"}]",
      "id": "394095183",
      "paperid": "3211551",
      "hash": "800ca36cb56afaf714ef7d67c8db1bcd2b076b7d",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "下列关于存储过程的特点说法正确的是（）",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:46",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "D",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 编写的SQL存储在数据库中，因此执行速度快。\"},{\"Key\":\"B\",\"Value\":\" 创建时编译，执行时调用，因此开发效率高。\"},{\"Key\":\"C\",\"Value\":\" 用户创建的存储过程或自定义函数可以重复调用，因此数据传输量少。\"},{\"Key\":\"D\",\"Value\":\" 通过指定存储过程的访问权限，因此安全系数高。\"}]",
      "id": "394096075",
      "paperid": "3211551",
      "hash": "c658ccfc057d7cbda10ae5bd58dfe5d65bf4bf44",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Hive SQL中DDL指定是哪一种语言？",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:46",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "D",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 数据删除语言\"},{\"Key\":\"B\",\"Value\":\" 数据管理语言\"},{\"Key\":\"C\",\"Value\":\" 数据查询语言\"},{\"Key\":\"D\",\"Value\":\" 数据定义语言\"}]",
      "id": "394096037",
      "paperid": "3211551",
      "hash": "c6a7c1ea215e605fff29b4fb0e1952b0c5dee2e3",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "HBase中数据存储的文件格式是下面哪一项？",
      "qtype": "1",
      "created_at": "2021-12-26 10:33:41",
      "analysis": "",
      "parentid": "0",
      "difficulty": "1",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[{\"Key\":\"A\",\"Value\":\"<p>SequenceFile<\\/p>\"},{\"Key\":\"B\",\"Value\":\"<p>Hfile<\\/p>\"},{\"Key\":\"C\",\"Value\":\"<p>TextFile<\\/p>\"},{\"Key\":\"D\",\"Value\":\"<p>HLog<\\/p>\"}]",
      "id": "326684144",
      "paperid": "3211551",
      "hash": "dffe224013e883bfd9896bb9ad6c22297b6b3204",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Kafka中数据从Producer到Broker和Broker到Consumer分别是哪种传递方式?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" push,push\"},{\"Key\":\"B\",\"Value\":\" push,pull\"},{\"Key\":\"C\",\"Value\":\" pullpull\"},{\"Key\":\"D\",\"Value\":\" pull,push\"}]",
      "id": "394095109",
      "paperid": "3211551",
      "hash": "a830e62346e7216ff74bbc2c8c9d590b1729beee",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Flume的应用中，如果要保证sink的负载均衡，需要使用以下哪一个组件?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "C",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" Static Interceptor\"},{\"Key\":\"B\",\"Value\":\" Default Sink Processor\"},{\"Key\":\"C\",\"Value\":\" Replicating Channel Selector\"},{\"Key\":\"D\",\"Value\":\" Failover Sink Processor\"}]",
      "id": "394095104",
      "paperid": "3211551",
      "hash": "0654e4aff5ea55259eae71cfdb192c1db0c853f9",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "下列代码的作用是?String vertexld=getVertexldByProperty（api.graphName,\"person\", \"name\" ,\" marko\"）;api.queryVertex（vertexld,graphName）;",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:46",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 查询点\"},{\"Key\":\"B\",\"Value\":\" 查询属性\"},{\"Key\":\"C\",\"Value\":\" 查询边\"},{\"Key\":\"D\",\"Value\":\" 以上全不正确\"}]",
      "id": "394096087",
      "paperid": "3211551",
      "hash": "a45e32a55a71690c2a5141faf418e7405344c4f1",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "某大数据运维人员想通过she11命令上传某个文件至HDFS文件系统中。以下哪个命令能帮助他完成这个操作？",
      "qtype": "1",
      "created_at": "2021-10-31 09:36:44",
      "analysis": "",
      "parentid": "0",
      "difficulty": "1",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[{\"Key\":\"A\",\"Value\":\"<p>-cat<\\/p>\"},{\"Key\":\"B\",\"Value\":\"<p>-put&nbsp;<\\/p>\"},{\"Key\":\"C\",\"Value\":\"<p>-upload&nbsp;<\\/p>\"},{\"Key\":\"D\",\"Value\":\"<p>-get<\\/p>\"}]",
      "id": "256717563",
      "paperid": "3211551",
      "hash": "375e726cb280d1c9c1710d31d6ed8fbfc532dfec",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "一般情况下，若要提高ElasticSearch检索效率，可以采取什么操作?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:46",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 调整索引分片数\"},{\"Key\":\"B\",\"Value\":\" 使用Hive做底层存储\"},{\"Key\":\"C\",\"Value\":\" 压缩素引\"},{\"Key\":\"D\",\"Value\":\" 正价EsMaster节点\"}]",
      "id": "394096086",
      "paperid": "3211551",
      "hash": "be1bacd0fd4ac0dbf17e27f0d807714a0ace8ae6",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "在Kafka集群中，Kafka服务端的角色是下列哪—项?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:22",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "D",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" Producer\"},{\"Key\":\"B\",\"Value\":\" ZooKeeper\"},{\"Key\":\"C\",\"Value\":\" Consumer\"},{\"Key\":\"D\",\"Value\":\" Broker\"}]",
      "id": "394095451",
      "paperid": "3211551",
      "hash": "b45d217be6a17319a64d9bd0147e39c3ca7b4622",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "关于Flink的角色，下列哪—项说法是错误的?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" TaskManager负责从用户提交的Flink程序配置中获取JobManager的地址。\"},{\"Key\":\"B\",\"Value\":\" Cient是Flink程序提交的客户端，对用户提交的Flink程序进行预处理，并提交到Flink集群中处理。\"},{\"Key\":\"C\",\"Value\":\" JobManager扮演着集群中的管理者Master的角色，它是整个集群的协调者。\"},{\"Key\":\"D\",\"Value\":\" TaskManager是实际负责执行计算的Worker.\"}]",
      "id": "394095103",
      "paperid": "3211551",
      "hash": "006ab3216125c65ebdfa48090cd9517863be7648",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Gauss DB 200 在创建表时， 需要注意以下哪些事项() ?",
      "qtype": "1",
      "created_at": "2022-01-01 20:41:39",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "C",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[{\"Key\":\"A\",\"Value\":\"<p>创建列存表之后，后续可以修改为行存表。<\\/p>\"},{\"Key\":\"B\",\"Value\":\"<p>创建列存表时压缩级别默认为 HIGH。<\\/p>\"},{\"Key\":\"C\",\"Value\":\"<p>如果指定表空间为普通表空间，创建表时默认是行式存储。<\\/p>\"},{\"Key\":\"D\",\"Value\":\"<p>创建一个行存表之后，后续可以修改为列存表。<\\/p>\"}]",
      "id": "334414204",
      "paperid": "3211551",
      "hash": "5ce7bdc988024000fde9c68b0bd60dec496a73e1",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "下列哪一个命令可以清空Redis实例下所有数据库的数据?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "D",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" dropdb\"},{\"Key\":\"B\",\"Value\":\" flushdb\"},{\"Key\":\"C\",\"Value\":\" dropall\"},{\"Key\":\"D\",\"Value\":\" flushall\"}]",
      "id": "394095105",
      "paperid": "3211551",
      "hash": "c634a9bad1cbf04514a9ad4f3375ea0f46d73c27",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "下列代码的作用是?String graphName =\"graphbase;Api.createGraph （graphName） ;",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "D",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 删除图\"},{\"Key\":\"B\",\"Value\":\" 获得图\"},{\"Key\":\"C\",\"Value\":\" 修改图\"},{\"Key\":\"D\",\"Value\":\" 创建图\"}]",
      "id": "394095145",
      "paperid": "3211551",
      "hash": "1b5c7c02cd05a8f1d64c8f6141726dacc08e02fb",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "ElasticSearch 进行全文检索一般需要哪几个步骤?()",
      "qtype": "1",
      "created_at": "2022-01-01 20:41:39",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"清洗.分词.建立索引\"},{\"Key\":\"B\",\"Value\":\"清洗.分词\"},{\"Key\":\"C\",\"Value\":\"清洗.建立索引\"},{\"Key\":\"D\",\"Value\":\"清洗.建立索引.分词\"}]",
      "id": "334414288",
      "paperid": "3211551",
      "hash": "ad5e4b35bd0a3fc1e9db98fdcd375e976785cf50",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " 某大数据业务人员对某些数据创建Hive表结构，其中某个数据为时间类型yyyyMMdd，那么可以使用以下哪一项作为字段类型？",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:46",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" varcahr\"},{\"Key\":\"B\",\"Value\":\" string\"},{\"Key\":\"C\",\"Value\":\" double\"},{\"Key\":\"D\",\"Value\":\" int\"}]",
      "id": "394096007",
      "paperid": "3211551",
      "hash": "e3dec72de0cde59bd7f3072b5832d129f7a9de46",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "GES能够处理海量数据的原因是（）。",
      "qtype": "1",
      "created_at": "2021-10-31 09:59:31",
      "analysis": "",
      "parentid": "0",
      "difficulty": "1",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[{\"Key\":\"A\",\"Value\":\"<p>基于HBase的分布式存储机制<\\/p><p><br><\\/p>\"},{\"Key\":\"B\",\"Value\":\"<p>图机制特性<\\/p><p><br><\\/p>\"},{\"Key\":\"C\",\"Value\":\"<p>基于Elasticsearch的索引机制<\\/p><p><br><\\/p>\"},{\"Key\":\"D\",\"Value\":\"<p>基于Spark的分布式内存计算技术<\\/p>\"}]",
      "id": "256731106",
      "paperid": "3211551",
      "hash": "d15a02a4787ac28e14aea3ffa0cc0eb1aa7e007f",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "下列关于 GaussDB 200 的数据类型转换说法正确的是()",
      "qtype": "1",
      "created_at": "2022-01-01 20:41:39",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "D",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"如果需要保留空字符串时，需要新建兼容性为 Postgres 的数据库。\"},{\"Key\":\"B\",\"Value\":\"在查询中，对常量不需要显式指定数据类型。\"},{\"Key\":\"C\",\"Value\":\"在 ORACLE 兼容模式下，在导入数据时，空字符串会自动过滤。\"},{\"Key\":\"D\",\"Value\":\"不同数据类型比较或转换时，使用强制类型转换，以防隐式类型转换结果与预期不符。\"}]",
      "id": "334414058",
      "paperid": "3211551",
      "hash": "4589e8b47aad520eb62eac17fbbb874eafbf58d1",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Flink的Checkpoint机制绘制的流应用快照不能被保存在以下哪个位置?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:22",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" Local\"},{\"Key\":\"B\",\"Value\":\" TaskManager的内存\"},{\"Key\":\"C\",\"Value\":\" JoblManager的内存\"},{\"Key\":\"D\",\"Value\":\" HDFS\"}]",
      "id": "394095460",
      "paperid": "3211551",
      "hash": "9ad9c8a037dde58aab29cf57471b0b287ad2cb86",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "哪个不是Structured Streaming 中 OutPut可以定义的存储方式?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" Update Mode\"},{\"Key\":\"B\",\"Value\":\" JDBC Mode\"},{\"Key\":\"C\",\"Value\":\" Complete Mode\"},{\"Key\":\"D\",\"Value\":\" Append Mode\"}]",
      "id": "394095163",
      "paperid": "3211551",
      "hash": "84e6376c194bb3ae1696517c492744062907901d",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " Hive是基于Hadoop的数据仓库软件，最大可以查询和管理（）级别的分布式数据。",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:22",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "C",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" TB\"},{\"Key\":\"B\",\"Value\":\" GB\"},{\"Key\":\"C\",\"Value\":\" PB\"},{\"Key\":\"D\",\"Value\":\" MB\"}]",
      "id": "394095473",
      "paperid": "3211551",
      "hash": "81ada16c117dccfa7deb779c7edc4e67d4200163",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "离线批处理方案的应用场景不包括?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:46",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 占用计算存储资源多\"},{\"Key\":\"B\",\"Value\":\" 快速高效，实时的数据处理\"},{\"Key\":\"C\",\"Value\":\" 数据处理格式多样\"},{\"Key\":\"D\",\"Value\":\" 处理大规模数据\"}]",
      "id": "394096079",
      "paperid": "3211551",
      "hash": "b7fcf615dcc01998e58de7102b6d675b7aa843da",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " 以下哪个不是大数据的数据计算引擎?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "C",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" Spark\"},{\"Key\":\"B\",\"Value\":\" MapReduce\"},{\"Key\":\"C\",\"Value\":\" Flume\"},{\"Key\":\"D\",\"Value\":\" Flink\"}]",
      "id": "394095157",
      "paperid": "3211551",
      "hash": "72ae02c3dbaac24060a935468230f9e7e1ef2049",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "某工程师正在开发EasticSearch应用，请问下列代码可以帮助他实现什么功能?<p><br></p><p><img src=\"https://up.zaixiankaoshi.com/docs/2a/4c/2a4cb7241a9acf691448e5d9551f7b76.png\" alt=\"2a4cb7241a9acf691448e5d9551f7b76.png\"></p>",
      "qtype": "1",
      "created_at": "2022-03-09 20:37:01",
      "analysis": "",
      "parentid": "0",
      "difficulty": "1",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[{\"Key\":\"A\",\"Value\":\"<p>删除素引<\\/p>\"},{\"Key\":\"B\",\"Value\":\"<p>创建素引<\\/p>\"},{\"Key\":\"C\",\"Value\":\"<p>维护索引<\\/p>\"},{\"Key\":\"D\",\"Value\":\"<p>更新素引<\\/p>\"}]",
      "id": "393704308",
      "paperid": "3211551",
      "hash": "565107dfb5cadd20683082ba8a8cab3d0ac7b8bb",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " 下列关于GaussDB 200的说法正确的是",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "D",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" RETURN用于返回存储过程调用结果\"},{\"Key\":\"B\",\"Value\":\" RETURN NEXT表示返回下一个。\"},{\"Key\":\"C\",\"Value\":\" RETURN QUERY用于近回集合。\"},{\"Key\":\"D\",\"Value\":\" 存储过程需要回值时使用 RETURN关键字\"}]",
      "id": "394095076",
      "paperid": "3211551",
      "hash": "8d0bde2d5c5d6dd677d5a539512ffc678f283ac1",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "在GaussDB 200中，关于Schema和 Database,下面说法正确的是()",
      "qtype": "1",
      "created_at": "2022-07-21 21:43:15",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "D",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[{\"Key\":\"A\",\"Value\":\"<p>二者都能实现资源隔离。<\\/p>\"},{\"Key\":\"B\",\"Value\":\"<p>Database之间无法直接访问，但通过权限授子可以访问数据。<\\/p>\"},{\"Key\":\"C\",\"Value\":\"<p>相比于Database, Schema的隔离更加的彻底。<\\/p>\"},{\"Key\":\"D\",\"Value\":\"<p>Schema和用户强相关的，通过权限控制语法可以实现不同用户对各Schema的权限。<\\/p>\"}]",
      "id": "606560585",
      "paperid": "3211551",
      "hash": "13d5eeb35802f101f62ca715ed85c0d577bcc954",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Redis 中 List列表是什么数据结构实现的?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 双向链表\"},{\"Key\":\"B\",\"Value\":\" 平衡二叉树\"},{\"Key\":\"C\",\"Value\":\" 红黑树\"},{\"Key\":\"D\",\"Value\":\" 循环链表\"}]",
      "id": "394095036",
      "paperid": "3211551",
      "hash": "14cb325442d6303789eca38f981b9fce3efbe3cd",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "当前传统关系型数据库主要面临的挑战是()",
      "qtype": "1",
      "created_at": "2022-01-01 20:41:39",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "D",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"数据量爆炸式增长，要求数据处理平台具备弹性扩展能力。\"},{\"Key\":\"B\",\"Value\":\"数据处理时效性需求提高，要求数据处理平台速度够快。\"},{\"Key\":\"C\",\"Value\":\"多类型数据融合，要求数据处理平台功能更加强大。\"},{\"Key\":\"D\",\"Value\":\"以上全都正确。\"}]",
      "id": "334414066",
      "paperid": "3211551",
      "hash": "36fdfc826209a4de9758634d9dfcbf2c17e648db",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " 某电商公司数据库高级工程师进行大数据分析，现在界面提示: \"0: jdbe:hive2://192.168.0.186:2181/>\"信息，那么他最有可能在进行什么场录的数据分析工作?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 实时检素场景\"},{\"Key\":\"B\",\"Value\":\" 离线批处理场景\"},{\"Key\":\"C\",\"Value\":\" 图搜索场景\"},{\"Key\":\"D\",\"Value\":\" 实时流开发场景\"}]",
      "id": "394095098",
      "paperid": "3211551",
      "hash": "defb7cff70e3e4e7580a9e66c2256f4db4c52c38",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "关于FusioninsightHD中 Loader作业描述正确的是?",
      "qtype": "1",
      "created_at": "2022-07-21 21:42:33",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" Loader,将作业提交到Yam执行后如果此时 Loader服务异常，则此作业执行失败\"},{\"Key\":\"B\",\"Value\":\" Loader将作业提交到Yam执行后如果某个Appert任务执行失败能够自动进行重试\"},{\"Key\":\"C\",\"Value\":\" Loadett作业执行失败后将会产生垃坝数据，需要用户手动清除\"},{\"Key\":\"D\",\"Value\":\" Loader将一个作业提交至Yam执行后该作业执行完成前不能再提交其他作业\"}]",
      "id": "606559406",
      "paperid": "3211551",
      "hash": "c804811bd84948cc74e1304ac91bf3b043d277c9",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "某电商网站想要实现热销商品的实时TopN排名，可以使用哪种技术实现?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:33",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "D",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" Elasticsearch的快速检索\"},{\"Key\":\"B\",\"Value\":\" HBase的rowkey索引\"},{\"Key\":\"C\",\"Value\":\" Hive的关联查询分析\"},{\"Key\":\"D\",\"Value\":\" Redis的排序计算\"}]",
      "id": "394095891",
      "paperid": "3211551",
      "hash": "871e846947c0c398f3bb1aa11a89b587614880cd",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "离线批处理工具不包含以下哪项?",
      "qtype": "1",
      "created_at": "2022-04-17 22:27:30",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "C",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" Spark\"},{\"Key\":\"B\",\"Value\":\" MapReduce\"},{\"Key\":\"C\",\"Value\":\" Storm\"},{\"Key\":\"D\",\"Value\":\" SQL \"}]",
      "id": "442011661",
      "paperid": "3211551",
      "hash": "996d875364b3f4247f3d32a8d2a4289422126856",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " 哪个产品适应于OLAP场景?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "D",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" PostgressQL\"},{\"Key\":\"B\",\"Value\":\" SQLServer o\"},{\"Key\":\"C\",\"Value\":\" MysQL\"},{\"Key\":\"D\",\"Value\":\" GaussDB 200\"}]",
      "id": "394095153",
      "paperid": "3211551",
      "hash": "110ab47d95dddc46343ccecc62dfeefa3892ed73",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "以下关于DataNode的描述不正确的是？",
      "qtype": "1",
      "created_at": "2022-01-01 20:41:39",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "C",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"DataNode管理数据块元数据\"},{\"Key\":\"B\",\"Value\":\"DataNode执行数据块的读\\/写操作。\"},{\"Key\":\"C\",\"Value\":\"DataNode的数量受数据规模影响。\"},{\"Key\":\"D\",\"Value\":\"DataNode是用来存储数据库。\"}]",
      "id": "334414312",
      "paperid": "3211551",
      "hash": "5cde8d0060f3aff301c6832db880f15edf90732f",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " 消息系统Kafka 如何保证高吞吐能力?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 多订阅者机制\"},{\"Key\":\"B\",\"Value\":\" Partition机制\"},{\"Key\":\"C\",\"Value\":\" 持久性机制\"},{\"Key\":\"D\",\"Value\":\" 冗余备份机制\"}]",
      "id": "394095125",
      "paperid": "3211551",
      "hash": "911ce31cdf843810acb66aa20ef8fed8eb47fb89",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "HBase 使用 get 方法读取数据时，下列哪个选项是需要的?",
      "qtype": "1",
      "created_at": "2022-01-01 20:41:39",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "C",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"Delete delete = new Delete (rowKey)\"},{\"Key\":\"B\",\"Value\":\"scan. setCaching ( 1000)\"},{\"Key\":\"C\",\"Value\":\"byte[] rowKey = Bytes. toBytes(\\\" 012005000201\\\")\"},{\"Key\":\"D\",\"Value\":\"List&lt;Put>] put S=new ArrayList&lt;Put> ()\"}]",
      "id": "334414186",
      "paperid": "3211551",
      "hash": "e4605cc328c96ddd29e44aac7b0dbbe4ab920838",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " Hive创建（）时，会将数据移动到数据仓库指向的路径;创建（），仅记录数据所在的路径，不对数据的位置做任何改变",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 内部表.外部表\"},{\"Key\":\"B\",\"Value\":\" 内部表.元数据\"},{\"Key\":\"C\",\"Value\":\" 原元数据.外部表\"},{\"Key\":\"D\",\"Value\":\" 外部表.托管表\"}]",
      "id": "394095203",
      "paperid": "3211551",
      "hash": "11624620bcb93210e6c949ebb6495747500aee0b",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "对 Gauss DB 200 描述不正确的是?（）",
      "qtype": "1",
      "created_at": "2022-01-01 20:41:39",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "C",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"并行架构\"},{\"Key\":\"B\",\"Value\":\"易运维，安全可靠\"},{\"Key\":\"C\",\"Value\":\"行列不能混存\"},{\"Key\":\"D\",\"Value\":\"节点多，易扩展\"}]",
      "id": "334414223",
      "paperid": "3211551",
      "hash": "afc1c40282f097c8281941e4a265c71f4604557c",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "以下选项中关于HDFS的文件块的描述不准确的是（） 。",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "C",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" HDFS文件块的大小在1.0版本时是64M，在2.0的时候是128M.\"},{\"Key\":\"B\",\"Value\":\" 文件块（片）被存在哪个集群；谁有权限查看、修改这个文件等信息放在元数据Metadata中。\"},{\"Key\":\"C\",\"Value\":\" 文件块越大寻址时间越短。\"},{\"Key\":\"D\",\"Value\":\" 文件块的大小设置原则：最大化寻址开销。\"}]",
      "id": "394095208",
      "paperid": "3211551",
      "hash": "2471641c00dbc17820afad2b127babc64342c1f7",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "对 ElasticSearch 检索流程描述正确的是?",
      "qtype": "1",
      "created_at": "2022-01-01 20:41:39",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[{\"Key\":\"A\",\"Value\":\"检索节点汇总结果发送给客户端\"},{\"Key\":\"B\",\"Value\":\"分片节点不需要汇总结果直接把结果发送给客户端\"},{\"Key\":\"C\",\"Value\":\"分片节点汇总结果发送给客户端\"},{\"Key\":\"D\",\"Value\":\"检索节点不需要汇总结果直接把结果发送给客户端\"}]",
      "id": "334414111",
      "paperid": "3211551",
      "hash": "8f9d5b0b149c50203ca3b54bdac13796d08be298",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "关于Spark 中SparkSQL描述不准确的是?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" SQL语句通过SparkSQL模块解析为DAG，交给SparkCore执行。\"},{\"Key\":\"B\",\"Value\":\" SparksSQL使用场景包括毫秒级实时查询。\"},{\"Key\":\"C\",\"Value\":\" 通过SparkSession提交SQL语句。任务像普通Spark应用一样提交到集群中分布式运行\"},{\"Key\":\"D\",\"Value\":\" SparksQL是Spark用来处理结构化数据的一个模块，可以在Spark应用中直接使用SQL语句对数据进行操作。\"}]",
      "id": "394095087",
      "paperid": "3211551",
      "hash": "577c44bf7423663ddb564c59ce1b349c75470224",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " Structured Streaming中以下哪项计划的执行顺序是正确的？",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 物理计划——逻辑计划——优化的逻辑计划\"},{\"Key\":\"B\",\"Value\":\" 逻辑计划——优化的逻辑计划——物理计划\"},{\"Key\":\"C\",\"Value\":\" 逻辑计划——物理计划——优化的逻辑计划\"},{\"Key\":\"D\",\"Value\":\" 优化的逻辑计划——逻辑计划——物理计划\"}]",
      "id": "394095027",
      "paperid": "3211551",
      "hash": "872952b435f16e2a733aad93b07974ca2c828261",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "某公司在进行大数据离线批处理平台的前期技术选型，以下哪个大数据组件不属于离线批处理业务所涉及到的组件？",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:46",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "C",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" HDFS\"},{\"Key\":\"B\",\"Value\":\" Spark\"},{\"Key\":\"C\",\"Value\":\" Storm\"},{\"Key\":\"D\",\"Value\":\" Hive\"}]",
      "id": "394096006",
      "paperid": "3211551",
      "hash": "5541c8f39db96229db59ba148f0f466bb783b1db",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " 下列哪个不是Explain的关键字（）?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "C",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" Tablescan\"},{\"Key\":\"B\",\"Value\":\" HashJoin\"},{\"Key\":\"C\",\"Value\":\" Filter\"},{\"Key\":\"D\",\"Value\":\" Seqscan\"}]",
      "id": "394095127",
      "paperid": "3211551",
      "hash": "fc27242c5e597f1551c8548ec5033d6a0a4034ef",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Redis中相对于AOF持久化，对RDB持久化描述正确的是 （）。",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 会丢失最后一次持久化以后的数据\"},{\"Key\":\"B\",\"Value\":\" 内存占用过多，持久化文件尺寸较大\"},{\"Key\":\"C\",\"Value\":\" 占用较多的磁盘I0开支\"},{\"Key\":\"D\",\"Value\":\" 恢复数度相对较慢，写入数据相对较快\"}]",
      "id": "394095221",
      "paperid": "3211551",
      "hash": "e31f503c902dc0b8d2972f117c4796632df79cdc",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "存储过程的调用有几种方式",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 3\"},{\"Key\":\"B\",\"Value\":\" 1\"},{\"Key\":\"C\",\"Value\":\" .4\"},{\"Key\":\"D\",\"Value\":\" 2\"}]",
      "id": "394095132",
      "paperid": "3211551",
      "hash": "b57389ad7ea58e6c6ae63b7a0cc17ccb0d54337d",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "当 ElasticSearch 集群有节点加入或退出时，集群数据会发生什么动作",
      "qtype": "1",
      "created_at": "2022-01-01 20:41:39",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"数据重载\"},{\"Key\":\"B\",\"Value\":\"数据重分布\"},{\"Key\":\"C\",\"Value\":\"数据更新\"},{\"Key\":\"D\",\"Value\":\"数据重建\"}]",
      "id": "334414079",
      "paperid": "3211551",
      "hash": "51ff6f7a5a74205083a9f183c3c2b1f135fdcad2",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Elasticsearch采用的搜索方式是（ ）。",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 正排素引\"},{\"Key\":\"B\",\"Value\":\" 倒排素引\"},{\"Key\":\"C\",\"Value\":\" 慢素引\"},{\"Key\":\"D\",\"Value\":\" 快速索引\"}]",
      "id": "394095143",
      "paperid": "3211551",
      "hash": "dd1874ced94732b0621d72e24b6e45e4893633bd",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "哪个不是 Elastic Search 生态圈中的技术?（）",
      "qtype": "1",
      "created_at": "2022-01-01 20:41:39",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "C",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"beats\"},{\"Key\":\"B\",\"Value\":\"Log stash\"},{\"Key\":\"C\",\"Value\":\"Flume\"},{\"Key\":\"D\",\"Value\":\"kibana\"}]",
      "id": "334414245",
      "paperid": "3211551",
      "hash": "30f71a6cc863378fdba54e9e93b2dae8888c7499",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "在SparkSQL中，（）使用了新的编码器，其编码器的作用是将VM的对象与表结构进行转换，允许操作序列化数据，可以提高内存利用率。",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "C",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" DataFrame\"},{\"Key\":\"B\",\"Value\":\" Table\"},{\"Key\":\"C\",\"Value\":\" DataSet\"},{\"Key\":\"D\",\"Value\":\" RDD\"}]",
      "id": "394095211",
      "paperid": "3211551",
      "hash": "9e7d284f54fbd53160125924a1a07d7db7edbdcf",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Redis 不适用于以下哪个应用场景?()",
      "qtype": "1",
      "created_at": "2022-01-01 20:41:39",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"获取 PB 级 Value 数据\"},{\"Key\":\"B\",\"Value\":\"获取 TOP N 操作\"},{\"Key\":\"C\",\"Value\":\"获取手机验证码\"},{\"Key\":\"D\",\"Value\":\"获取最新 N 个数据的操作\"}]",
      "id": "334414297",
      "paperid": "3211551",
      "hash": "d819574e39aa9d740a969c5fdba8043a142b0f67",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "某大数据业务人员在查询某张表的业务数据时，希望查询出来的数值结果保留两位小数，他应该使用哪个函数来实现？",
      "qtype": "1",
      "created_at": "2021-10-31 09:39:11",
      "analysis": "",
      "parentid": "0",
      "difficulty": "1",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[{\"Key\":\"A\",\"Value\":\"<p>trim<\\/p>\"},{\"Key\":\"B\",\"Value\":\"<p>&nbsp;round<\\/p>\"},{\"Key\":\"C\",\"Value\":\"<p>&nbsp;abs&nbsp;<\\/p>\"},{\"Key\":\"D\",\"Value\":\"<p>&nbsp;rand<\\/p>\"}]",
      "id": "256718735",
      "paperid": "3211551",
      "hash": "9a84e5fb18ce8dff21ad5a48d5dd198951cc8173",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Loader 页面是基于开源( )的图形化数据迁移管理工具。",
      "qtype": "1",
      "created_at": "2022-01-01 20:41:39",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "D",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"Hadoop\"},{\"Key\":\"B\",\"Value\":\"Hue\"},{\"Key\":\"C\",\"Value\":\"Kettle\"},{\"Key\":\"D\",\"Value\":\"Sqoop\"}]",
      "id": "334414043",
      "paperid": "3211551",
      "hash": "bf841a8832827f558ca74765511ac2a261af1c27",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "关于HBase建表语句，以下描述中错误的是哪一项?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:33",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 在华为云MRS提供的HBase shel‖客户端中建表时，需指定至少一个列族名称\"},{\"Key\":\"B\",\"Value\":\" 利用HBasef的）ava APIE时，需要用put语句完成建表\"},{\"Key\":\"C\",\"Value\":\" 在HBase shell客户端中可以通过create命令建表\"},{\"Key\":\"D\",\"Value\":\" 在建表时可以预先创建多个Region\"}]",
      "id": "394095863",
      "paperid": "3211551",
      "hash": "a965d702bcac779e7ffdf7e980ed041cbff7864f",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "当 Spark 发生 Shuffle 时，MapTask 的运 算结果会通过( )的形式把运算结果分发到对应的任务上去。",
      "qtype": "1",
      "created_at": "2022-01-01 20:41:39",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"序列化\"},{\"Key\":\"B\",\"Value\":\"键值对\"},{\"Key\":\"C\",\"Value\":\"二进制\"},{\"Key\":\"D\",\"Value\":\"RDD\"}]",
      "id": "334414026",
      "paperid": "3211551",
      "hash": "2849b4539c59f1800394336fe96ebd23250cffac",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Structured Streaming不能提供以下哪几种类型的保证?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[{\"Key\":\"A\",\"Value\":\"<p>More than once<\\/p>\"},{\"Key\":\"B\",\"Value\":\"<p>At most once<\\/p>\"},{\"Key\":\"C\",\"Value\":\"<p>Exactly once<\\/p>\"},{\"Key\":\"D\",\"Value\":\"<p>At least once<\\/p>\"}]",
      "id": "394095121",
      "paperid": "3211551",
      "hash": "818f2acdd6067cd813a1b0ab18a0e3613be1e4ac",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " 在Flume架构中，以下哪一种类型的Sink支持将数据写入到Solr中?",
      "qtype": "1",
      "created_at": "2022-02-19 18:35:30",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "D",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" thift sink\"},{\"Key\":\"B\",\"Value\":\" hdfs sink\"},{\"Key\":\"C\",\"Value\":\" file roll sink\"},{\"Key\":\"D\",\"Value\":\" MorphlineSolr sink\"}]",
      "id": "369558978",
      "paperid": "3211551",
      "hash": "a89b16832c80516e01f89e2004e253561a4f3fa9",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "某项目小组接到一个大数据实时分析项目，且对实时性要求很高。请问以下哪种大数据计算框架最合适?",
      "qtype": "1",
      "created_at": "2022-01-01 20:41:39",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"Flink\"},{\"Key\":\"B\",\"Value\":\"MapReduce\"},{\"Key\":\"C\",\"Value\":\"HBase\"},{\"Key\":\"D\",\"Value\":\"Spark\"}]",
      "id": "334414148",
      "paperid": "3211551",
      "hash": "f402767adda9fc482791ffecf4ac7f414ebbc6a0",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "下列关于GaussDB 200的局部聚簇技术说法正确的是",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "C",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 局部聚簇技术可以应用在 GaUssDB200的所有表中,\"},{\"Key\":\"B\",\"Value\":\" 局部聚簇在某些场景下可以提交检素效壑,所以在创建表时根据业务场旻应创建寥个PCK\"},{\"Key\":\"C\",\"Value\":\" PCK通过 min\\/max稀疏素引实现事实表快速过扫描\"},{\"Key\":\"D\",\"Value\":\" PCK对应的列尽量不要为空值。\"}]",
      "id": "394095078",
      "paperid": "3211551",
      "hash": "8fce55d6d241e15192321425959077242c957b53",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "对Gauss DB 200描述不正确的是?（）",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "C",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 并行架构\"},{\"Key\":\"B\",\"Value\":\" 易运维,安全可靠\"},{\"Key\":\"C\",\"Value\":\" 行列不能混存\"},{\"Key\":\"D\",\"Value\":\" 节点多,易扩展\"}]",
      "id": "394095166",
      "paperid": "3211551",
      "hash": "afc1c40282f097c8281941e4a265c71f4604557c",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "GaussDB 200的SQL自诊断在Moni tor模式下，可识别下列哪个lssue Pattern",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" HashJoin中大表做内装\"},{\"Key\":\"B\",\"Value\":\" 多列统计信息未收集\"},{\"Key\":\"C\",\"Value\":\" 大表等值关联NestLoop\"},{\"Key\":\"D\",\"Value\":\" 数据倾斜\"}]",
      "id": "394095188",
      "paperid": "3211551",
      "hash": "c371216029d912ad80b5e2155786388422df5e9b",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "1. HDFS创建目录过程中，通过调用FileSystem实例的（）方法查看该目录是否存在。",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:22",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "C",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" create\"},{\"Key\":\"B\",\"Value\":\" Mkdirs\"},{\"Key\":\"C\",\"Value\":\" exists\"},{\"Key\":\"D\",\"Value\":\" find\"}]",
      "id": "394095470",
      "paperid": "3211551",
      "hash": "fe20c71d317c926f26df15ec785ad07b8fc33692",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "以下对于离线批处理的概念理解错误的是哪—项?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:22",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 离线批处理对数据处理的时延要求不高。\"},{\"Key\":\"B\",\"Value\":\" 离线批处理占用的内存资源较多。\"},{\"Key\":\"C\",\"Value\":\" 离线批处理通常通过眠作业、Spark作业或者HQL作业实现。\"},{\"Key\":\"D\",\"Value\":\" 离线批处理针对的数据量较大。\"}]",
      "id": "394095434",
      "paperid": "3211551",
      "hash": "18b064599c5c33547c8387b005f56773a89432e8",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Gateway在 ElasticSearch中的含义是?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:46",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "D",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 网关\"},{\"Key\":\"B\",\"Value\":\" 素引的存储方式\"},{\"Key\":\"C\",\"Value\":\" rpc请求接\"},{\"Key\":\"D\",\"Value\":\" 索引快照的存储方式\"}]",
      "id": "394095987",
      "paperid": "3211551",
      "hash": "96c23ffd7e18c5c253f3eb6cc3952a3b6b308aad",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " 智能数据湖运营平台指的是以下哪个选项?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:22",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "D",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" VAS（video Analysis Service）\"},{\"Key\":\"B\",\"Value\":\" ModelArts\"},{\"Key\":\"C\",\"Value\":\" cSS\"},{\"Key\":\"D\",\"Value\":\" DAYU\"}]",
      "id": "394095461",
      "paperid": "3211551",
      "hash": "76299201a6448e7362d64b924d0cf253929f0bf0",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "以下哪项不属于数据存储组件?",
      "qtype": "1",
      "created_at": "2022-01-01 20:41:39",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"HBase\"},{\"Key\":\"B\",\"Value\":\"Storm\"},{\"Key\":\"C\",\"Value\":\"HDFS\"},{\"Key\":\"D\",\"Value\":\"MySQL\"}]",
      "id": "334414033",
      "paperid": "3211551",
      "hash": "e19260457dc57f33a71fe1d8a616ce5167e32adc",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "以下哪项属于F1ume的基本数据单位?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "D",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" Subject\"},{\"Key\":\"B\",\"Value\":\" Topic\"},{\"Key\":\"C\",\"Value\":\" Object\"},{\"Key\":\"D\",\"Value\":\" Event\"}]",
      "id": "394095056",
      "paperid": "3211551",
      "hash": "127798c6ebc18baf89716c6790ca6f4bc4f06166",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "下列对图数据库描述正确的是?Z",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 以图”数据结构存储和查询数据的教据库\"},{\"Key\":\"B\",\"Value\":\" 存储图片的数据库\"},{\"Key\":\"C\",\"Value\":\" 与关系型数据库美似的数据库\"},{\"Key\":\"D\",\"Value\":\" 数据仓库的一种\"}]",
      "id": "394095172",
      "paperid": "3211551",
      "hash": "4648e03a214fc84146c94b1589e8e44f6ccd3ca2",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "以下关于Saoop数据导入原理的描述中，错误的是哪—项?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "C",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" Sqoop会根据传入的num-mappers来确定划分几个区域。\"},{\"Key\":\"B\",\"Value\":\" Saoop根据不同的split-by参数值来进行切分，然后将切分出来的区域分配到不同map中。\"},{\"Key\":\"C\",\"Value\":\" num-mappers越大效率越高。\"},{\"Key\":\"D\",\"Value\":\" Saoop在import时，需要指定split-by参数。\"}]",
      "id": "394095207",
      "paperid": "3211551",
      "hash": "84da5c9d0b44d644c53b2232387ac6a98d4a10e0",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "以下关于EasticSearch缓存机制的理解不正确的是（ ）。",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:22",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" Query Cache:Shard级别的缓存，是对一个查询中包含的过滤器执行结果进行缓存。\"},{\"Key\":\"B\",\"Value\":\" Request Cache:Shard级别的缓存，是为了缓存“分片级”的本地结果集。\"},{\"Key\":\"C\",\"Value\":\" Fielddata Cache专门针对分词的字段在查询期间的数据结构的缓存。\"},{\"Key\":\"D\",\"Value\":\" 缓存主要分三种：Query Cache,Fiel ddata Cache,Request Cache。\"}]",
      "id": "394095463",
      "paperid": "3211551",
      "hash": "5917c6c005dc8b21ef0c9946495af73faeffdd21",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "有一张表 name，其中一个字段名为 chinese_name，类型为 char(4) ，另一个字段名为eng1ish_name， 类型为 varchar(5) 。那么执行如下语句“insert into name values('gaosi'， 'Gauss DB') ”会发生什么?（）",
      "qtype": "1",
      "created_at": "2022-01-01 20:41:39",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "C",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"存在记录(gaos，GaussDB) 。\"},{\"Key\":\"B\",\"Value\":\"存在记录(gaos，Gauss) 。\"},{\"Key\":\"C\",\"Value\":\"数据无法插入。\"},{\"Key\":\"D\",\"Value\":\"存在记录(gaosi，GaussDB)\"}]",
      "id": "334414207",
      "paperid": "3211551",
      "hash": "fe4c0b6a7b177eb14cfe446d8782cd0f67d89483",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "假设现在要做一个可以根据线索指导运维人员进行排障的功能，你建议选择下列哪个工具实现该功能?()",
      "qtype": "1",
      "created_at": "2022-01-01 20:41:39",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "D",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"Lucene\"},{\"Key\":\"B\",\"Value\":\"HBase\"},{\"Key\":\"C\",\"Value\":\"ElasticSearch\"},{\"Key\":\"D\",\"Value\":\"GraphBase\"}]",
      "id": "334414290",
      "paperid": "3211551",
      "hash": "7004afea7229f7e8f1351fe4883d4cc2d206a285",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "若要对图片进行检索，—般选择什么工具较好?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:22",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "C",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" MysQL\"},{\"Key\":\"B\",\"Value\":\" HDFS\"},{\"Key\":\"C\",\"Value\":\" ElasticSearch\"},{\"Key\":\"D\",\"Value\":\" Hive\"}]",
      "id": "394095449",
      "paperid": "3211551",
      "hash": "ea277f65fa72d621e47d0164659d888e8b089846",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "以下属于Hive的架构组件的是?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" HLog\"},{\"Key\":\"B\",\"Value\":\" Driver\"},{\"Key\":\"C\",\"Value\":\" Master\"},{\"Key\":\"D\",\"Value\":\" Name Node\"}]",
      "id": "394095151",
      "paperid": "3211551",
      "hash": "689a5d133e6a6c5c547e9b988a65e9cc66f30421",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "下列哪段代码是用于判断ElasticSearch索引是否存在?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" lic boolean is ExistsIndex（String indexName）（ Indi ces Exi stsResponse respo aDmin Cl i ent 0. prepare Exi sts（indexName）. get（\"},{\"Key\":\"B\",\"Value\":\" public boolean is ExistsIndex（String indexName）（ Indi cesExists Response response getAdmin ClientO. prepare Exi sts（indexName）: return esponse. isExistso true: false:\"},{\"Key\":\"C\",\"Value\":\" public boolean i sExistsIndex（String indexName）（ Indi cesExists Response response= getAdmin Client（ geto: return response is ExistsO? true false.\"},{\"Key\":\"D\",\"Value\":\" public boolean i sExistsIndex（String indexName）（ Indi cesExists Response response= getAdmi ncClientO. prepare Exists（indexName）, getO: return response. isExists0? true: false:\"}]",
      "id": "394095102",
      "paperid": "3211551",
      "hash": "86fb326531311398cb712921d5eb62a701d349a7",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "下面这条GaussDB 200的SQL语句”select name, count（1） from student group by name“可能涉及的算子有哪些?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" Filter\"},{\"Key\":\"B\",\"Value\":\" GroupAggregate\"},{\"Key\":\"C\",\"Value\":\" Streaming\"},{\"Key\":\"D\",\"Value\":\" HashAggregate\"}]",
      "id": "394095075",
      "paperid": "3211551",
      "hash": "464128ea5ecdbdbe3035d317e02a6d7beee9ed3d",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "下面这条GaussDB 200语句“call dbms_job.interval（1,'sysdate+ 1.0/24'）;\"的意思是",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:46",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 修改Job1的Interva为每隔24小时执行一次。\"},{\"Key\":\"B\",\"Value\":\" 修改Job1的Interval为每隔1小时执行一次。\"},{\"Key\":\"C\",\"Value\":\" 修改Job1的Interval为每隔1\\/24小时执行一次。\"},{\"Key\":\"D\",\"Value\":\" 修改Job1的Interval为每隔24分钟执行一次。\"}]",
      "id": "394096092",
      "paperid": "3211551",
      "hash": "0ab9bde58d7585a619bc086d5e9eeda98af600e2",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "GaussDB 200支持几种数据并行导入策略?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 3\"},{\"Key\":\"B\",\"Value\":\" 1\"},{\"Key\":\"C\",\"Value\":\" 2\"},{\"Key\":\"D\",\"Value\":\" 4\"}]",
      "id": "394095046",
      "paperid": "3211551",
      "hash": "8039c2f635b4069643b2e22d871e9f6a7dff7bd1",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "针对金融行业中实时风控场景的核心诉求描述错误的是（）.",
      "qtype": "1",
      "created_at": "2022-01-21 16:59:41",
      "analysis": "",
      "parentid": "0",
      "difficulty": "1",
      "uid": "1090076",
      "path": "",
      "answer": "C",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[{\"Key\":\"A\",\"Value\":\"<p>水平扩展：当系统处理能力出现瓶颈后，可通过节点的水平扩展提升处理性能。<\\/p>\"},{\"Key\":\"B\",\"Value\":\"<p>处理速度快：端到端处理需要达到秒级，流处理平台负责的数据采集和数据处理要在1秒内完成。<\\/p>\"},{\"Key\":\"C\",\"Value\":\"<p>可靠性高：网络、软件等故障发生时，允许数据丢失。<\\/p>\"},{\"Key\":\"D\",\"Value\":\"<p>吞吐量高：需在短时内接收并处理大量数据记录，吞吐量需要达到数十兆\\/秒\\/节点。<\\/p>\"}]",
      "id": "351082800",
      "paperid": "3211551",
      "hash": "e6f737349a51e92feee900fb4237c90b56a0b6f8",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Hive中的解释器（complier）、优化器（optimizer）、执行器（executor）组件用于HQL语句从词法分析、语法分析、编译、优化以及查询计划的生成。生成的查询计划存储在（）中，并在随后由（）调用执行。",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:22",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "D",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 内存、MapReduce\"},{\"Key\":\"B\",\"Value\":\" HBase、Yarn\"},{\"Key\":\"C\",\"Value\":\" HDFS、Tez\"},{\"Key\":\"D\",\"Value\":\" HDFS、Yarn\"}]",
      "id": "394095468",
      "paperid": "3211551",
      "hash": "461cc7d406b4bf7e6377cd7fccf214ede346896d",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "下列哪个选项对批量数据处理组件的描述是不正确的?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:22",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" Hive:传统SQL批处理引擎，用于处理SQL类批处理作业，使用广泛海量数据下表现稳定，但是处理速度较慢。\"},{\"Key\":\"B\",\"Value\":\" MapReduce:传统批处理引擎，用于处理非SQL类，尤其是数据挖掘和机器学习类批处理作业，使用广泛，海量数据下表现不稳定，但是处理速度较快。\"},{\"Key\":\"C\",\"Value\":\" SparkSQL：新型SQL批处理引擎，用于处理SQL类批处理作业，适合海量数据.处理速度高效。\"},{\"Key\":\"D\",\"Value\":\" Spark：新型批处理引擎，可以用于处理非SQL类，尤其是数据挖掘和机器学习类批处理作业，适合海量数据，处理速度高效。\"}]",
      "id": "394095471",
      "paperid": "3211551",
      "hash": "12e0852dc908e2150821bbfc640bda9cf25fb055",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "HBase不支持以下哪些SQL操作?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:46",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "C",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" Spark SQL\"},{\"Key\":\"B\",\"Value\":\" Hive SQL\"},{\"Key\":\"C\",\"Value\":\" MySQL\"},{\"Key\":\"D\",\"Value\":\" 、Phoenix SQL\"}]",
      "id": "394096010",
      "paperid": "3211551",
      "hash": "bf5c31a7582f2c3579946e132b6933ce666e7569",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "ElasticSearch可通过分片副本来优化性能，下列策略错误的是哪—项?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:22",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 分片数不超过节点数的3倍，用较少的分片获得更佳的性能\"},{\"Key\":\"B\",\"Value\":\" 副本数至少设置为3，保障数据的可靠性\"},{\"Key\":\"C\",\"Value\":\" 副本数建议设置为1，过多的副本需要更多存储空间\"},{\"Key\":\"D\",\"Value\":\" 分片最大容量不要超过ElasticSearch推荐的最大JVM堆空间32G\"}]",
      "id": "394095448",
      "paperid": "3211551",
      "hash": "ee892ae11f4dd98bb9a40828ba24ba65a398eba2",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "HDFS基本系统架构中，副本配置通常存储（）份。",
      "qtype": "1",
      "created_at": "2022-01-21 16:34:05",
      "analysis": "",
      "parentid": "0",
      "difficulty": "1",
      "uid": "1090076",
      "path": "",
      "answer": "C",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[{\"Key\":\"A\",\"Value\":\"<p>1<\\/p>\"},{\"Key\":\"B\",\"Value\":\"<p>2<\\/p>\"},{\"Key\":\"C\",\"Value\":\"<p>3<\\/p>\"},{\"Key\":\"D\",\"Value\":\"<p>4<\\/p>\"}]",
      "id": "351058137",
      "paperid": "3211551",
      "hash": "d8533f305397c763cdf49572f7a7dfcd936213e1",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "以下关于常见数据库描述正确的是?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "C",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" HBase基于 ZooKeeper, Hadoop,适合非结构化数据存储,是高可靠性高性能,面向行,可伸缩的分布式存储系\"},{\"Key\":\"B\",\"Value\":\" Oracle:关系型数据库,行式存储,支持SQL,中量级数据分析存储不可分布式,开源软件。\"},{\"Key\":\"C\",\"Value\":\" Redis:开源key- value数据库,读写性能极高,数据类型丰富,可以与 Storm结合进行实时查询分析\"},{\"Key\":\"D\",\"Value\":\" Mysql关系型数据库,列式存储,支持SQL,轻量级数据分析存储,仅有商业版本。\"}]",
      "id": "394095170",
      "paperid": "3211551",
      "hash": "373a33d007ebfd76fa953590f531b1a331c3c6f7",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Kafka Cluster Mirroring工具可以实现以下哪些功能?",
      "qtype": "1",
      "created_at": "2022-07-21 21:40:36",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" Kafka跨集群数据同步方案\"},{\"Key\":\"B\",\"Value\":\" Kafkas单集群内数据备份\"},{\"Key\":\"C\",\"Value\":\" Kafka但集群内数据恢复\"},{\"Key\":\"D\",\"Value\":\" 以上全不正确\"}]",
      "id": "606556128",
      "paperid": "3211551",
      "hash": "c5e70a7ba839210b57f1813b450a53ea40235ea6",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Spark 的核心概念不包括?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[{\"Key\":\"A\",\"Value\":\"<p>RDD<\\/p>\"},{\"Key\":\"B\",\"Value\":\"<p>hlog <\\/p>\"},{\"Key\":\"C\",\"Value\":\"<p>宽套依赖<\\/p>\"},{\"Key\":\"D\",\"Value\":\"<p>Shuffle<\\/p>\"}]",
      "id": "394095158",
      "paperid": "3211551",
      "hash": "1f632d1022ef1801a0a66fe49f2bc1cf9c97bb0e",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "某公司计划上线新系统，数据库工程师使用Hive数据仓库进行数据分析，现在界面提示: \"o:jdbc:hive2://192.168.0.186:2181/>\"信息，现已完成数据库的创建工作，那么他将如何继续开始数据库的使用?",
      "qtype": "1",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" use database\"},{\"Key\":\"B\",\"Value\":\" start database\"},{\"Key\":\"C\",\"Value\":\" restart database\"},{\"Key\":\"D\",\"Value\":\" continue database\"}]",
      "id": "394095099",
      "paperid": "3211551",
      "hash": "3332af0f4fdcc3c449c552772b47796fe0943003",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "以下关于Hive内置函数描述正确的是（ ）。",
      "qtype": "1",
      "created_at": "2021-12-26 10:33:41",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "D",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"desc functions upper：查看系统自带的函数\"},{\"Key\":\"B\",\"Value\":\" to_date()：获取当前日期\"},{\"Key\":\"C\",\"Value\":\"substr()：求字符串长度\"},{\"Key\":\"D\",\"Value\":\"trim()：去除空字符串\"}]",
      "id": "326684116",
      "paperid": "3211551",
      "hash": "e71a974971292239f4c52b05116a5e6e906afd54",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "公安行业中实时检索不适用于以下哪个场景?",
      "qtype": "1",
      "created_at": "2022-01-01 20:41:39",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "C",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"实时布控\"},{\"Key\":\"B\",\"Value\":\"快速信息汇集\"},{\"Key\":\"C\",\"Value\":\"评估嫌疑人犯罪概率\"},{\"Key\":\"D\",\"Value\":\"车辆信息查询\"}]",
      "id": "334414042",
      "paperid": "3211551",
      "hash": "c035224d2baf5fc7018242d4794c2f96a63a0543",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "在Apache Hadoop中，关于HDFS 的回收站机制，描述正确的是?（）",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ABCD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 回收站里的文件可以快速恢复。\"},{\"Key\":\"B\",\"Value\":\" 可以设置一个时间阀值,当回收姑里文件的存放时间超过这个阀值或是回收站被清空时,文件才会被彻底删除,并且释放占用的数据块。\"},{\"Key\":\"C\",\"Value\":\" 删除文件时,不会真正的册除,其实是放入回收站。\"},{\"Key\":\"D\",\"Value\":\" 回收站默认是关闭的。\"}]",
      "id": "394095169",
      "paperid": "3211551",
      "hash": "147153a53d9af9233dc36445855937ee3daf4eb4",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "HBase的Filter过滤器有什么作用?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:22",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "BD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 过滤region\"},{\"Key\":\"B\",\"Value\":\" 过滤列值\"},{\"Key\":\"C\",\"Value\":\" 过滤列名\"},{\"Key\":\"D\",\"Value\":\" 过滤rowkey\"}]",
      "id": "394095445",
      "paperid": "3211551",
      "hash": "42e7fc0e5f5ff3c706bd2241984dfe603f04b9ec",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "以下对 HDFS中提供文件读写的类描述正确的是?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:46",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ACD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" FSDataOutputStream是与DataNode交互的接口类。\"},{\"Key\":\"B\",\"Value\":\" FSDataOutputStream是HOFS API中提供读取文件的类，通过FileSystem的close方法获取读取数据流。\"},{\"Key\":\"C\",\"Value\":\" FSDataOutputStream通过FileSystem的create和append方法获取写入数据流。\"},{\"Key\":\"D\",\"Value\":\" FSDataOutputStream是HDFSAPI中提供文件写入文件的类。\"}]",
      "id": "394095994",
      "paperid": "3211551",
      "hash": "750ecf9f5c371aee76b2e3048ddfda9ae3544424",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "ZooKeeper在HBase中主要起什么作用?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "AD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 管理元数据\"},{\"Key\":\"B\",\"Value\":\" 存储表结构数据\"},{\"Key\":\"C\",\"Value\":\" 存储用户表数据\"},{\"Key\":\"D\",\"Value\":\" 主备切换\"}]",
      "id": "394095008",
      "paperid": "3211551",
      "hash": "9c0203e78651bc4da0e8544c72adf49ab6992e79",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Structured Streaming 中 OutPut定义的存储方式包含以下哪几种?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "BCD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" Modify Mode\"},{\"Key\":\"B\",\"Value\":\" Append Mode\"},{\"Key\":\"C\",\"Value\":\" Update Mode.\"},{\"Key\":\"D\",\"Value\":\" Complete Mode\"}]",
      "id": "394095195",
      "paperid": "3211551",
      "hash": "88389cae8451febf6c85cb75a103b34140b2b724",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Flink 中的计算时间包含以下哪几种?  /",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "BCD",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[{\"Key\":\"A\",\"Value\":\"<p>Delay Time<\\/p>\"},{\"Key\":\"B\",\"Value\":\"<p>Processing Time<\\/p>\"},{\"Key\":\"C\",\"Value\":\"<p>Event Time<\\/p>\"},{\"Key\":\"D\",\"Value\":\"<p>Ingestion Time<\\/p>\"}]",
      "id": "394095178",
      "paperid": "3211551",
      "hash": "9f3d0ff35c1d99475a6794d6c5fd7e99ad36b924",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "数据仓库数据分层的优点包括?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:46",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ABC",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 减少重复开发\"},{\"Key\":\"B\",\"Value\":\" 把复杂问题简单化\"},{\"Key\":\"C\",\"Value\":\" 隔离原始数据\"},{\"Key\":\"D\",\"Value\":\" 减少数据仓库存储空间\"}]",
      "id": "394096081",
      "paperid": "3211551",
      "hash": "00e17350508dd07e44d848f43edf7eff24d360e8",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Redis应用开发在之激动业务目标时需要考虑以下哪些因素?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:46",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ABD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 数据量\"},{\"Key\":\"B\",\"Value\":\" 读写性能\"},{\"Key\":\"C\",\"Value\":\" 数据质量\"},{\"Key\":\"D\",\"Value\":\" 持久化\"}]",
      "id": "394096091",
      "paperid": "3211551",
      "hash": "4fd5d15056bca8e4688f259e5ae2fb2bea054947",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "HBase 读写用户表数据时需要下列哪些角色参与?",
      "qtype": "2",
      "created_at": "2022-01-01 20:41:39",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ABD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"RegionServer\"},{\"Key\":\"B\",\"Value\":\"HMaster\"},{\"Key\":\"C\",\"Value\":\"ZooKeeper\"},{\"Key\":\"D\",\"Value\":\"Region\"}]",
      "id": "334414185",
      "paperid": "3211551",
      "hash": "60ebc16c847e988e5aa723128b848af5b5f42e14",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "关于表扫描算子的说法正确的是（?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:46",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ABC",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 对于点查或者范围扫描等过滤本量数据的查询，如果使用SeqScan全表扫描会比较快。\"},{\"Key\":\"B\",\"Value\":\" 表的数目比较少的时候，使用Seqscan效率更高。\"},{\"Key\":\"C\",\"Value\":\" SOL的执行计划第一步就是从表扫描算子开始的。\"},{\"Key\":\"D\",\"Value\":\" SeqScan是指顺序扫描表的所有信息。\"}]",
      "id": "394096001",
      "paperid": "3211551",
      "hash": "32a1639c0686b2a1352bd98677f162b5cf40117e",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "数据仓库分层的优点包括以下哪些选项？",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:33",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ACD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 减少重复开发量\"},{\"Key\":\"B\",\"Value\":\" 提高资源协调能力\"},{\"Key\":\"C\",\"Value\":\" 隔离原始数据\"},{\"Key\":\"D\",\"Value\":\" 简化复杂问题\"}]",
      "id": "394095850",
      "paperid": "3211551",
      "hash": "c93617ea428ee0071dc9c2308c13a5c4ab492a0f",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "有关实时检索引擎中各组件的联系与定位，以下描述中正确的有哪些项?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:33",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ABCD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" HBaseoElasticSearch的组合满足了大部分的用户实时检索诉求\"},{\"Key\":\"B\",\"Value\":\" ElasticSearch存储数据性价比低,但是其能够满足场景中多级索引的实时查询需求,同时还能够对文档分词建立索引\"},{\"Key\":\"C\",\"Value\":\" 与HBase相比, ElasticSearch在海量数据的情景下存储性能不如HBase,故选择HBase作为海量数据存储的基石\"},{\"Key\":\"D\",\"Value\":\" 图数据库可以完美的解决复杂多级关系查询分析,选用GES来解决图数据的实时查询需求\"}]",
      "id": "394095862",
      "paperid": "3211551",
      "hash": "07f4c85e3122f8da8e1b1920e127193d56b00ecd",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "大数据技术的“三驾马车”具体指以下哪些?（）",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ABC",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 大数据分布式计算框架 MapReduce\"},{\"Key\":\"B\",\"Value\":\" 分布式文件系统GFS\"},{\"Key\":\"C\",\"Value\":\" 数据库系统 Big Table\"},{\"Key\":\"D\",\"Value\":\" 数据容器 Docker\"}]",
      "id": "394095167",
      "paperid": "3211551",
      "hash": "b8a064c195b8953c27af1925a172e46e6e26c8a1",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "SparkSQL使用场景丰富，可以处理的数据源包括?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:46",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ABCD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" Json\"},{\"Key\":\"B\",\"Value\":\" Hive\"},{\"Key\":\"C\",\"Value\":\" 文本文件\"},{\"Key\":\"D\",\"Value\":\" RDD\"}]",
      "id": "394096077",
      "paperid": "3211551",
      "hash": "b60039c51437be83e627ff87d54ee4cb64536c66",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " 以下选项对GraphBase概念描述正确的是?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ACD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" Vertex Labe1:节点的标签，用于表示现实世界中的实体类型\"},{\"Key\":\"B\",\"Value\":\" Edge:边，用于表示关系度\"},{\"Key\":\"C\",\"Value\":\" Vertex:节点\\/顶点，用于表示现实世界中的实体对象\"},{\"Key\":\"D\",\"Value\":\" Edge Label.边的标签，用于表示现实世界中的关系类型\"}]",
      "id": "394095058",
      "paperid": "3211551",
      "hash": "d827a6d8dd0604fedfb01fd08175441d060385b1",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "  GraphBase具有哪些特点?",
      "qtype": "2",
      "created_at": "2022-02-19 18:35:30",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "BCD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 兼容SQL语法,方便易用\"},{\"Key\":\"B\",\"Value\":\" 提供多实例部署,可横向扩展\"},{\"Key\":\"C\",\"Value\":\" 提供灵活的图元数据更新,修改\"},{\"Key\":\"D\",\"Value\":\" 提供易用的Rest接口,方便数据的查询分析\"}]",
      "id": "369558944",
      "paperid": "3211551",
      "hash": "63ba84a9e22d3c2da1a72878a4f43b107274f0e9",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "针对以下场景描述，可以用于大数据实时检索技术完成的有（）。",
      "qtype": "2",
      "created_at": "2022-01-21 16:30:40",
      "analysis": "",
      "parentid": "0",
      "difficulty": "1",
      "uid": "1090076",
      "path": "",
      "answer": "AB",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[{\"Key\":\"A\",\"Value\":\"<p>要求1秒内响应，高并发（100以上请求）<\\/p><p>查询条件简单（80%查询是主键查询，其他是简单条件组合查询）<\\/p>\"},{\"Key\":\"B\",\"Value\":\"<p>根据ID（身份证，车牌号等）进行查询<\\/p><p>可用于实时布控，车辆轨迹绘制，快速信息汇集<\\/p>\"},{\"Key\":\"C\",\"Value\":\"<p>主要根据ID（手机号码）、时间段进行用户话费清单、流量清单查询<\\/p>\"},{\"Key\":\"D\",\"Value\":\"<p>可用于事后查询交易凭证，追溯交易，以及查询客户信用记录，帮助客户快速借款等<\\/p>\"}]",
      "id": "351055009",
      "paperid": "3211551",
      "hash": "4aa866c95e5e97431d4e88704bece091ad0518fa",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " HBase中包含哪些基本的概念?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:46",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ABCD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" Row Key\"},{\"Key\":\"B\",\"Value\":\" table\"},{\"Key\":\"C\",\"Value\":\" namespace\"},{\"Key\":\"D\",\"Value\":\" Column Family\"}]",
      "id": "394096046",
      "paperid": "3211551",
      "hash": "5cf3c7be9116807879c9cdfef0365299fbe63186",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " ElasticSearch在部署时，对Linux的设置有哪些优化方法?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ACD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 关闭缓存swap\"},{\"Key\":\"B\",\"Value\":\" 堆内存设置为：Min\"},{\"Key\":\"C\",\"Value\":\" 线程池+队列大小根据业务需要做调整\"},{\"Key\":\"D\",\"Value\":\" 设置最大文件句柄数\"}]",
      "id": "394095110",
      "paperid": "3211551",
      "hash": "4c8f5a2ae227595fc8a7f0c12a027a8e977adb74",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "一家搜索引整公司需要7*24不间断提供海量用户的实时查询请求，这最有可能使用到以下哪些大数据开发组件的组合?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:22",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "CD",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[{\"Key\":\"A\",\"Value\":\"<p>MapReduce<\\/p>\"},{\"Key\":\"B\",\"Value\":\"<p>ElasticSearch<\\/p>\"},{\"Key\":\"C\",\"Value\":\"<p>Hive<\\/p>\"},{\"Key\":\"D\",\"Value\":\"<p>HBase<\\/p>\"}]",
      "id": "394095431",
      "paperid": "3211551",
      "hash": "a6887b2956d90908ea133b2047379f4ead832536",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " Flume中拦截器包含以下哪些?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ABCD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" Search and Replace Interceptor\"},{\"Key\":\"B\",\"Value\":\" Regex Filtering Interceptor\"},{\"Key\":\"C\",\"Value\":\" Timestamp Interceptor\"},{\"Key\":\"D\",\"Value\":\" Host Interceptor\"}]",
      "id": "394095124",
      "paperid": "3211551",
      "hash": "48b6996751193bbda63333c03df5ccff4fc8428e",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Gs_dump和gs_dumpa11的异同点是（",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:46",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ACD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 二者都支持纯文本格式数据的导出。\"},{\"Key\":\"B\",\"Value\":\" ds_dump只支持纯文本格式的数据导出，dsdumpall支持多种数据格式的数据导出。\"},{\"Key\":\"C\",\"Value\":\" 二者都支持公共全局对象的数据导出。\"},{\"Key\":\"D\",\"Value\":\" ds_dump 针对的是单个数据库，ds_dumpall 针对的是所有数据库。\"}]",
      "id": "394096072",
      "paperid": "3211551",
      "hash": "a48b10ba6604624ddcf929f07195c9a87ad132f7",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "所谓的大数据技术融合主要指哪些方面?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ABCD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 数据融合\"},{\"Key\":\"B\",\"Value\":\" 算力融合\"},{\"Key\":\"C\",\"Value\":\" 计算融合\"},{\"Key\":\"D\",\"Value\":\" 批-流融合\"}]",
      "id": "394095219",
      "paperid": "3211551",
      "hash": "031ffa4e8242e28ea05d62eab05fd8441b84b06e",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " 某大数据业务人员因误操作，导致某条Hive的Insert语句执行了多次，使得数据出现了重复的现象，为了避免下次再次出现这种问题。以下哪些操作是可取的?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ABCD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 添加Hive表的唯一索引，保证数据不重复。\"},{\"Key\":\"B\",\"Value\":\" 改造SQL语句，在插入前添加清空操作如truncate\"},{\"Key\":\"C\",\"Value\":\" 改造SQL语句，添加关键字Overwrite使得数据以覆盖的方式写入。\"},{\"Key\":\"D\",\"Value\":\" 添加权限，使得业务人员只能执行单次插入。\"}]",
      "id": "394095016",
      "paperid": "3211551",
      "hash": "679e7ea53fd80c3f872c501f12d13cc691e4727b",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "HDFS里包含哪些实例?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:46",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "AC",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" NameNode\"},{\"Key\":\"B\",\"Value\":\" TaskManager\"},{\"Key\":\"C\",\"Value\":\" DataNode\"},{\"Key\":\"D\",\"Value\":\" JobManager\"}]",
      "id": "394096053",
      "paperid": "3211551",
      "hash": "e8b26ca29363b0f1602b3154d00bbcb5a41b3f8c",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " 下面选项哪些是HBase数据查询过滤器Filter的比较器?",
      "qtype": "2",
      "created_at": "2022-02-19 18:35:30",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ABCD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" BinaryComparator\"},{\"Key\":\"B\",\"Value\":\" BinaryProfixComparator\"},{\"Key\":\"C\",\"Value\":\" RegexStringComparator\"},{\"Key\":\"D\",\"Value\":\" SubStringComparator\"}]",
      "id": "369558966",
      "paperid": "3211551",
      "hash": "6634b204963859e480829e4b45f967633f55f0a5",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "  Flink提供的窗口分配器，包含以下哪些项?",
      "qtype": "2",
      "created_at": "2022-02-19 18:35:30",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ABCD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 全局窗口\"},{\"Key\":\"B\",\"Value\":\" 滑动窗口\"},{\"Key\":\"C\",\"Value\":\" 会话窗口\"},{\"Key\":\"D\",\"Value\":\" 滚动窗口\"}]",
      "id": "369558941",
      "paperid": "3211551",
      "hash": "37632d1e6cd85fc61a8ca4f637e74d397a70853b",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Kafka中删除消息的阈值有哪几种？",
      "qtype": "2",
      "created_at": "2022-01-01 20:41:39",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "AC",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"分区总日志大小\"},{\"Key\":\"B\",\"Value\":\"数据使用的频率\"},{\"Key\":\"C\",\"Value\":\"数据产生的时间\"},{\"Key\":\"D\",\"Value\":\"硬盘总空间大小\"}]",
      "id": "334414319",
      "paperid": "3211551",
      "hash": "0d49f9a08345b395c5f13c08cea01d860be85bb3",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "对HBase Bloom Filter 描述不正确的是?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:33",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ABD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 用于优化随机写的场景\"},{\"Key\":\"B\",\"Value\":\" 用于优化Scan场景\"},{\"Key\":\"C\",\"Value\":\" 误判率由哈希函数个数k位数组大小m数据量n共同确定\"},{\"Key\":\"D\",\"Value\":\" 判断结果一定正确\"}]",
      "id": "394095842",
      "paperid": "3211551",
      "hash": "98b07a7d58810483a5de245f93d2483818e6d032",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "HBase读数据时需要读取哪几部分数据?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:33",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "BC",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" Hloc\"},{\"Key\":\"B\",\"Value\":\" Mem Store\"},{\"Key\":\"C\",\"Value\":\" Hfile\"},{\"Key\":\"D\",\"Value\":\" HDFS\"}]",
      "id": "394095845",
      "paperid": "3211551",
      "hash": "967512fb68e186015854c6f4b00de72bcb5190a1",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "  下列哪些措施可以显著提升ElasticSearch 的性能",
      "qtype": "2",
      "created_at": "2022-02-19 18:35:30",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "BCD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 减少EsMaster\"},{\"Key\":\"B\",\"Value\":\" 修改副本数量\"},{\"Key\":\"C\",\"Value\":\" 增加EsMaster\"},{\"Key\":\"D\",\"Value\":\" 禁用swap\"}]",
      "id": "369558963",
      "paperid": "3211551",
      "hash": "812ba3f249f539d71ad42de254d1ee47c376e783",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "大数据计算框架Flink的支持以下哪些资源调度方式?",
      "qtype": "2",
      "created_at": "2022-07-21 21:42:17",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ACD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" Mesos\"},{\"Key\":\"B\",\"Value\":\" Docker\"},{\"Key\":\"C\",\"Value\":\" YARN\"},{\"Key\":\"D\",\"Value\":\" Standalone\"}]",
      "id": "606559328",
      "paperid": "3211551",
      "hash": "ab609c303352eaec84801acc01fc2e7966f670de",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "实时检索的解决方案中有哪些组件?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "AC",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" HBase\"},{\"Key\":\"B\",\"Value\":\" Hadoop\"},{\"Key\":\"C\",\"Value\":\" ElasticSearch\"},{\"Key\":\"D\",\"Value\":\" Hive\"}]",
      "id": "394095010",
      "paperid": "3211551",
      "hash": "5e33ab0a964f9c8aaba3c436375a6fc574521356",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Elastic Search的核心概念包含哪些?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:33",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ABCD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" Mapping\"},{\"Key\":\"B\",\"Value\":\" Document\"},{\"Key\":\"C\",\"Value\":\" Type\"},{\"Key\":\"D\",\"Value\":\" Index\"}]",
      "id": "394095846",
      "paperid": "3211551",
      "hash": "5bf59cf39d010b59a51835e17137e6e949fe325e",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "下列关于 GaussDB 200 的说法正确的是() ?",
      "qtype": "2",
      "created_at": "2022-01-01 20:41:39",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "BD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"对作业执行的内存估算是依赖行数来估算的。\"},{\"Key\":\"B\",\"Value\":\"GaussDB 200 支持内存自适应，因此开发人员不用过多关注内存的分配问题。\"},{\"Key\":\"C\",\"Value\":\"内存自适应适用于所有作业。\"},{\"Key\":\"D\",\"Value\":\"当作业执行期间内存不足时，会等待其他作业完成内存释放，重新执行作业。\"}]",
      "id": "334414145",
      "paperid": "3211551",
      "hash": "848ce69cc709d2a16e9b1d3371bf50d057ce839a",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Flink有哪些状态储存方式？",
      "qtype": "2",
      "created_at": "2022-04-18 10:27:20",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ACD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" MemoryStateBackend\"},{\"Key\":\"B\",\"Value\":\" Mysq1StateBackend\"},{\"Key\":\"C\",\"Value\":\" FsStateBackend\"},{\"Key\":\"D\",\"Value\":\" RocksDBStateBackend\"}]",
      "id": "442335831",
      "paperid": "3211551",
      "hash": "54e59502893f195f134a123560778a9e5a00b4da",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "以下哪些场景可以使用HBase作为存储系统？",
      "qtype": "2",
      "created_at": "2021-12-29 09:42:28",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "AC",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"Row-Key查询\"},{\"Key\":\"B\",\"Value\":\"满足ACID特性\"},{\"Key\":\"C\",\"Value\":\"海量数据存储\"},{\"Key\":\"D\",\"Value\":\"大文件（TB）\"}]",
      "id": "330824062",
      "paperid": "3211551",
      "hash": "701820fb17fbf5509ae3e1dcfe2cfcf41fa95373",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "在哪些场景下不能使用HBase 作为存储系统（）?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:46",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "AD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 需要ACID特性\"},{\"Key\":\"B\",\"Value\":\" 海量数据存储\"},{\"Key\":\"C\",\"Value\":\" 主键查询\"},{\"Key\":\"D\",\"Value\":\" 大文件，视频等\"}]",
      "id": "394096058",
      "paperid": "3211551",
      "hash": "eea4bdd10b1840e3eb8a1ddf0e0a0885603ab207",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "对于GaussDB 200而言，字段的设计应该注意以下哪些事项（）?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ABC",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 在满足业务精度的情况下，NUKREIC的优先级比浮点数高。\"},{\"Key\":\"B\",\"Value\":\" 尽量使用符合实际业务描述的字段。\"},{\"Key\":\"C\",\"Value\":\" 尽量使用高效率的字段类型\"},{\"Key\":\"D\",\"Value\":\" 考虑数据美观，尽量使用同一种数据类型，比如Text.\"}]",
      "id": "394095081",
      "paperid": "3211551",
      "hash": "75af943597488dd1c90f58073824514180653fd7",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "哪些方式能够操作 HBase的数据?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:46",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ABCD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 客户端命令\"},{\"Key\":\"B\",\"Value\":\" Phoenix SQL\"},{\"Key\":\"C\",\"Value\":\" Java API\"},{\"Key\":\"D\",\"Value\":\" HivesQL\"}]",
      "id": "394096057",
      "paperid": "3211551",
      "hash": "77e9a330a8e69142185c48624a7b8ba7931cec2e",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " Hive的自定义函数包括?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:33",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ACD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" UDAF\"},{\"Key\":\"B\",\"Value\":\" UDCE\"},{\"Key\":\"C\",\"Value\":\" UDTF\"},{\"Key\":\"D\",\"Value\":\" UDE\"}]",
      "id": "394095844",
      "paperid": "3211551",
      "hash": "b1e417ea77da7ec88d433972ad7b38a8679f0394",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "某大数据业务人员因误操作，导致删除了部分HDFS的业务数据。为了避免再次出现，如何从技术角度出发去规避这个问题?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "BCD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 禁止HDFS的删除操作。\"},{\"Key\":\"B\",\"Value\":\" 开启HDFS的回收站机制，及时恢复数据。\"},{\"Key\":\"C\",\"Value\":\" 平时注重安全信息的普及，多加宣传。\"},{\"Key\":\"D\",\"Value\":\" 对业务人员进行权限划分，避免非法或敏感操作，如删除等。\"}]",
      "id": "394095095",
      "paperid": "3211551",
      "hash": "fb4953c90f4a4afb6c8603ca844b28833c7001de",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "在 GaussDB 200 中，关于 Schema 和 Database,下而说法正确的是()/",
      "qtype": "2",
      "created_at": "2022-01-01 18:46:51",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "BD",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[{\"Key\":\"A\",\"Value\":\"<p>二者都能实现资源隔离。<\\/p>\"},{\"Key\":\"B\",\"Value\":\"Database 之间无法直接访问，但通过权限授予可以访问数据。\"},{\"Key\":\"C\",\"Value\":\"相比于 Database, Schema 的隔离更加的彻底。\"},{\"Key\":\"D\",\"Value\":\"Schema 和用户强相关的，通过权限控制语法可以实现不同用户对各 Schema 的权限。\"}]",
      "id": "334329435",
      "paperid": "3211551",
      "hash": "ceca5687821e758172367bdf1d07af4f8f49945c",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "HBase中HMaster主要负责（）。",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:46",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ABD",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[{\"Key\":\"A\",\"Value\":\"<p>表的增册删改查<\\/p>\"},{\"Key\":\"B\",\"Value\":\"<p>Regionservert负载均衡<\\/p>\"},{\"Key\":\"C\",\"Value\":\"<p>用户数据读写<\\/p>\"},{\"Key\":\"D\",\"Value\":\"<p>Region分布调整<\\/p>\"}]",
      "id": "394096023",
      "paperid": "3211551",
      "hash": "ef1b19fbb20657b9a9d13861790c2cfc56b6d5ff",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "在 GaussDB 200 的存储过程中，NULL 代表的意思是() ?",
      "qtype": "2",
      "created_at": "2022-01-01 20:41:39",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ABD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"可以表示缺省值。\"},{\"Key\":\"B\",\"Value\":\"可以表示字段值为空。\"},{\"Key\":\"C\",\"Value\":\"可以表示布尔值。\"},{\"Key\":\"D\",\"Value\":\"可以表示空语句\"}]",
      "id": "334414196",
      "paperid": "3211551",
      "hash": "917daad834e90b712fd93d2e05d54582e15c091e",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "关于GaussDB 200的约束，说法正确的是（?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ACD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 唯一约束是指字段的值唯一，行列表都支持。\"},{\"Key\":\"B\",\"Value\":\" PCK也是一种约束，行列都支持。\"},{\"Key\":\"C\",\"Value\":\" NULL约束也是一种约束，行列表都支持。\"},{\"Key\":\"D\",\"Value\":\" 主键约束是指主键的值是唯一的，只支持行存表。\"}]",
      "id": "394095128",
      "paperid": "3211551",
      "hash": "f5e9127a5826bdb000b8a6b017c61f8c641f1881",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "加的组合满足了大部分的用户实时查询诉求?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:46",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "BC",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" MapReduce\"},{\"Key\":\"B\",\"Value\":\" HBase\"},{\"Key\":\"C\",\"Value\":\" ElasticSearch\"},{\"Key\":\"D\",\"Value\":\" Hive\"}]",
      "id": "394096054",
      "paperid": "3211551",
      "hash": "343b253ce7b89e9247f93b236673d986fda810d8",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "以下哪些算子是窄依赖?  /",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ACD",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[{\"Key\":\"A\",\"Value\":\"<p>filter<\\/p>\"},{\"Key\":\"B\",\"Value\":\"<p>group&nbsp; By<\\/p>\"},{\"Key\":\"C\",\"Value\":\"<p>union<\\/p>\"},{\"Key\":\"D\",\"Value\":\"<p>map<\\/p>\"}]",
      "id": "394095015",
      "paperid": "3211551",
      "hash": "b4555b3275851e04a713520a7b51bf1c9f3c1f6e",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Spark的应用场景有哪些",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:46",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ABCD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 迭代计算\"},{\"Key\":\"B\",\"Value\":\" 数据挖掘\"},{\"Key\":\"C\",\"Value\":\" 流式处理\"},{\"Key\":\"D\",\"Value\":\" 查询分析\"}]",
      "id": "394096038",
      "paperid": "3211551",
      "hash": "ac94a6c7eab9d70e61b71e8c1efa4e6c8216f180",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "下列哪些情况下SOL自诊断可以识别，并上报告警信息?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:46",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ABCD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 数据值斜。\"},{\"Key\":\"B\",\"Value\":\" SQL语句不下推。\"},{\"Key\":\"C\",\"Value\":\" 大表Broadcast.\"},{\"Key\":\"D\",\"Value\":\" HashJoin中大表做内表。\"}]",
      "id": "394096000",
      "paperid": "3211551",
      "hash": "e744cbfe43a7e79671b6f80572330a55eb5fe139",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Flume中的source工作方式可以分为以下哪几种？",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:46",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "BC",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 中断\"},{\"Key\":\"B\",\"Value\":\" 轮询\"},{\"Key\":\"C\",\"Value\":\" 驱动\"},{\"Key\":\"D\",\"Value\":\" 广播\"}]",
      "id": "394096031",
      "paperid": "3211551",
      "hash": "bd997d929c286ed34e1a5f1181983d36374ff044",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "HBase 适用于下列哪些应用场景?",
      "qtype": "2",
      "created_at": "2022-01-01 20:41:39",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ABC",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"图片数据存储\"},{\"Key\":\"B\",\"Value\":\"银行交易系统\"},{\"Key\":\"C\",\"Value\":\"商品数据存储\"},{\"Key\":\"D\",\"Value\":\"消息中间件\"}]",
      "id": "334414099",
      "paperid": "3211551",
      "hash": "3442fe3bf646cb212bfdabed1fad543b127585e8",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "按照应用类型，Flink窗口可以划分为以下哪几种?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ACD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 事件窗口\"},{\"Key\":\"B\",\"Value\":\" 容量窗口\"},{\"Key\":\"C\",\"Value\":\" 滚动窗口\"},{\"Key\":\"D\",\"Value\":\" 时间窗口\"}]",
      "id": "394095107",
      "paperid": "3211551",
      "hash": "8e0c2fea929133f8963d37eb3837fc20fc396882",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "以下关于Fink的窗口描述正确的是（ ）。",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ABCD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 会话窗口是将数据聚合到会话窗口中，由非活跃的间隙分隔开。\"},{\"Key\":\"B\",\"Value\":\" 我们可以每30秒计算一次最近一分钟用户购买的商品总数，这个就是时间滑动窗口的应用方式\"},{\"Key\":\"C\",\"Value\":\" 窗口可以是时间驱动的也可以是数据驱动的。\"},{\"Key\":\"D\",\"Value\":\" Flink窗口按窗口行为划分：Tumbling Window.Sliding Window.Session Window。\"}]",
      "id": "394095135",
      "paperid": "3211551",
      "hash": "ee1fe91c375dc177aaf5388e0e3f894546a25c3e",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "下面哪几项属于Redis中set类型的命令?/",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "AB",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[{\"Key\":\"A\",\"Value\":\"<p>sunion<\\/p>\"},{\"Key\":\"B\",\"Value\":\"<p>scard<\\/p>\"},{\"Key\":\"C\",\"Value\":\"<p>zcount<\\/p>\"},{\"Key\":\"D\",\"Value\":\"<p>Irange<\\/p>\"}]",
      "id": "394095224",
      "paperid": "3211551",
      "hash": "502d2800e6b16ccc1574c899ff4802322b71f468",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "关于实时流数据处理，通常的处理要求包括以下哪些选项?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "BCD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 处理之后的数据量依然巨大，达到TB级甚至PB级的数据量\"},{\"Key\":\"B\",\"Value\":\" 数据需要尽快的得到处理\"},{\"Key\":\"C\",\"Value\":\" 能处理源源不断的数据\"},{\"Key\":\"D\",\"Value\":\" 处理的结果能够尽快地展现\"}]",
      "id": "394095133",
      "paperid": "3211551",
      "hash": "16e9f1d1ce55865207e05746853712b03a942e22",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "以下哪些选项是 Kafka 的特点?",
      "qtype": "2",
      "created_at": "2022-01-01 20:41:39",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ACD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"高吞吐\"},{\"Key\":\"B\",\"Value\":\"支持消息随机读取\"},{\"Key\":\"C\",\"Value\":\"分布式\"},{\"Key\":\"D\",\"Value\":\"消息持久化\"}]",
      "id": "334414075",
      "paperid": "3211551",
      "hash": "60bf308c30208e7d009d05e3bf6a6c1ee0edc213",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "大数据计算框架Spark 中除了RDD,还有哪些数据类型?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "CD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" DataType\"},{\"Key\":\"B\",\"Value\":\" DataSchema\"},{\"Key\":\"C\",\"Value\":\" DataSet\"},{\"Key\":\"D\",\"Value\":\" DataFrame\"}]",
      "id": "394095055",
      "paperid": "3211551",
      "hash": "5ec737724012a45cd463ee130a7a64a09d189668",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "以下哪些是 HDFS的核心组件?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:46",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ABC",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" Client\"},{\"Key\":\"B\",\"Value\":\" NameNode\"},{\"Key\":\"C\",\"Value\":\" DataNode\"},{\"Key\":\"D\",\"Value\":\" Product\"}]",
      "id": "394096047",
      "paperid": "3211551",
      "hash": "24795bf11b35539c7fee0cd632c2fd415e1f9d97",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "关于HDFS中Name Node 的作用描述的正确的是?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:46",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ABC",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 管理HDFS的名称空间（NameSpace ）\"},{\"Key\":\"B\",\"Value\":\" 配置副本策略通常为3份\"},{\"Key\":\"C\",\"Value\":\" 处理客户端读写请求\"},{\"Key\":\"D\",\"Value\":\" 执行数据块的读\\/写操作\"}]",
      "id": "394096078",
      "paperid": "3211551",
      "hash": "d5c9619a410b3d21d322b778522faab92b5cd88a",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "—般在什么时候会采用数据分区?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ABCD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 需要执行大量的热点数据查询作的时候\"},{\"Key\":\"B\",\"Value\":\" 需要执行大量的数据删除撰作的时候\"},{\"Key\":\"C\",\"Value\":\" 当表中数据量比较多（千万级别以上）的时候\"},{\"Key\":\"D\",\"Value\":\" 需要执行大量的数据更新提作的时候\"}]",
      "id": "394095150",
      "paperid": "3211551",
      "hash": "d7d2ae3ef892f2fbe65093899a23926b897b8ecb",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "在GaussDB 200中，关于Schema和 Database,下面说法正确的是（）/",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "AB",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[{\"Key\":\"A\",\"Value\":\"<p>二者都能实现资源隔离。<\\/p>\"},{\"Key\":\"B\",\"Value\":\"<p>Database之间无法直接访问，但通过权限授子可以访问数据。<\\/p>\"},{\"Key\":\"C\",\"Value\":\"<p>相比于Database,Schema的隔离更加的彻底。<\\/p>\"},{\"Key\":\"D\",\"Value\":\"<p>Schema和用户强相关的，通过权限控制语法可以实现不同用户对各Schema的权限。<\\/p>\"}]",
      "id": "394095131",
      "paperid": "3211551",
      "hash": "7f5eff91b38d01c11f5772c34b79b6e40c4e7a5b",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "下列选项对 ElasticSearch replicas 的描述，正确的是",
      "qtype": "2",
      "created_at": "2022-01-01 20:41:39",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ABD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"代表素引副本\"},{\"Key\":\"B\",\"Value\":\"提高系统容传性\"},{\"Key\":\"C\",\"Value\":\"压缩素引大小\"},{\"Key\":\"D\",\"Value\":\"提高检素效率\"}]",
      "id": "334414081",
      "paperid": "3211551",
      "hash": "6c3c828bc11baaca83d3207ec4870d5f0728e802",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "以下 Hive数据仓库数据表分层的描述，准确的是?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ABCD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" ADS层，为各种统计报表提供数据，做分析处理同步到RDS数据库里边。\"},{\"Key\":\"B\",\"Value\":\" DWD层结构和粒度与原始表保持一致，简单清洗，数据明细详情，去除空值，脏数据，超过极限范围的明细解析。\"},{\"Key\":\"C\",\"Value\":\" ODS层，通常表述原始数据存储表，Hive 接收到原始的数据通常是杂乱无章的，但是又具有安全隐私考虑，通常应用侧是不能看到的\"},{\"Key\":\"D\",\"Value\":\" DWS层，以DWD为基础，进行轻度汇总。\"}]",
      "id": "394095085",
      "paperid": "3211551",
      "hash": "3339f619815afdc4b41aaba249cc9bcb69f83efe",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "GuassDB 200的基本功能包含哪些?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:46",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ABC",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 标准SQL支持\"},{\"Key\":\"B\",\"Value\":\" 提供安装部署工具、集群启停工具、集群状态监控工具、升级和扩容工具\"},{\"Key\":\"C\",\"Value\":\" 支持表空间，支持集群在线扩容功能\"},{\"Key\":\"D\",\"Value\":\" 支持标准JDBC4.0的特性但不支持ODBC\"}]",
      "id": "394096041",
      "paperid": "3211551",
      "hash": "657367cc7d5004a2e509a2231942f343b3a56216",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Flink支持的Source有以下哪些选项？",
      "qtype": "2",
      "created_at": "2022-01-21 16:54:31",
      "analysis": "",
      "parentid": "0",
      "difficulty": "1",
      "uid": "1090076",
      "path": "",
      "answer": "ABCD",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[{\"Key\":\"A\",\"Value\":\"<p>自定义数据读取<\\/p>\"},{\"Key\":\"B\",\"Value\":\"<p>从集合中读取数据<\\/p>\"},{\"Key\":\"C\",\"Value\":\"<p>从文件中读取数据<\\/p>\"},{\"Key\":\"D\",\"Value\":\"<p>从消息队列中读取数据<\\/p>\"}]",
      "id": "351076197",
      "paperid": "3211551",
      "hash": "2ab1938a04c347339fe883bda07972d23d318a4e",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Redis的AOF持久化中，写命令同步的时机有以下哪几项?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:22",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "BCD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" appendfsync none\"},{\"Key\":\"B\",\"Value\":\" appendfsync everysec\"},{\"Key\":\"C\",\"Value\":\" appendfsync no\"},{\"Key\":\"D\",\"Value\":\" appendfsync always\"}]",
      "id": "394095457",
      "paperid": "3211551",
      "hash": "15766d7f3bd500537cab45cb9a54339d2e2bf3b7",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Flink窗口按分割标准划分为以下哪几种?",
      "qtype": "2",
      "created_at": "2022-04-17 22:26:22",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "BC",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 容量窗口\"},{\"Key\":\"B\",\"Value\":\" 时间窗口\"},{\"Key\":\"C\",\"Value\":\" 事件窗口\"},{\"Key\":\"D\",\"Value\":\" 滚动窗口\"}]",
      "id": "442011253",
      "paperid": "3211551",
      "hash": "28f7d02161acd5e6da01dd522ccfcd4381bdb6d9",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "以下哪些数据库的引擎适合做数据仓库?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ABD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" Exadata\"},{\"Key\":\"B\",\"Value\":\" Teradata\"},{\"Key\":\"C\",\"Value\":\" Redis\"},{\"Key\":\"D\",\"Value\":\" Oracle\"}]",
      "id": "394095100",
      "paperid": "3211551",
      "hash": "d0e836c629c55943c319bd95a9b357b3c2a26f48",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " Flink计算时间不包含以下哪几种时间语义?",
      "qtype": "2",
      "created_at": "2022-02-19 18:35:30",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "AB",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" Delay Time(延迟时间)\"},{\"Key\":\"B\",\"Value\":\" Start Time(开始时间)\"},{\"Key\":\"C\",\"Value\":\" Processing Time(处理时间)\"},{\"Key\":\"D\",\"Value\":\" Event Time(事件时间)\"}]",
      "id": "369558940",
      "paperid": "3211551",
      "hash": "dd5a927480c669efb9675f0f723ba5983a3dbdfe",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Flume 可以从以下哪些数据源上采集数据?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:46",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ABCD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 实时日志\"},{\"Key\":\"B\",\"Value\":\" Syslog\"},{\"Key\":\"C\",\"Value\":\" Kafka\"},{\"Key\":\"D\",\"Value\":\" 本地文件\"}]",
      "id": "394096069",
      "paperid": "3211551",
      "hash": "0bc18e2e30bdff7039a15c7fb903c9b3b23644e7",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "以下关于Loader的描述中，正确的有哪几项？",
      "qtype": "2",
      "created_at": "2021-12-29 09:42:28",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ACD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"提供可视化向导式的作业配置管理界面。\"},{\"Key\":\"B\",\"Value\":\"是基于开源Flume研发，做了大量优化和扩展。\"},{\"Key\":\"C\",\"Value\":\"提供定时调度任务，周期性执行Loader作业。\"},{\"Key\":\"D\",\"Value\":\"在界面中可指定多种不同的数据源、配置数据的清洗和转换步骤、配置集群存储系统。\"}]",
      "id": "330824046",
      "paperid": "3211551",
      "hash": "44611f3f3e4532c483ada0e93e831b5f1334c1fa",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "以下关于Transformation的说法正确的是?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:46",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ABCD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 它的返回值还是一个RDD\"},{\"Key\":\"B\",\"Value\":\" 是RDD的算子类型\"},{\"Key\":\"C\",\"Value\":\" 属于懒操作\"},{\"Key\":\"D\",\"Value\":\" mapfunc）属于Transformation\"}]",
      "id": "394096039",
      "paperid": "3211551",
      "hash": "632299a3b7e6156618838291fb3d9076b6ba0098",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "ElasticSearcht位包含以下哪些方法？",
      "qtype": "2",
      "created_at": "2022-01-21 16:48:41",
      "analysis": "",
      "parentid": "0",
      "difficulty": "1",
      "uid": "1090076",
      "path": "",
      "answer": "ABCD",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[{\"Key\":\"A\",\"Value\":\"<p>实时搜索<\\/p>\"},{\"Key\":\"B\",\"Value\":\"<p>非主键查询<\\/p>\"},{\"Key\":\"C\",\"Value\":\"<p>主键查询<\\/p>\"},{\"Key\":\"D\",\"Value\":\"<p>文档检索<\\/p>\"}]",
      "id": "351071493",
      "paperid": "3211551",
      "hash": "2956ddcef7b094b1a64a63855d97094906b333ba",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "关于 GaussDB 200. 下列说法正确的是() ?",
      "qtype": "2",
      "created_at": "2022-01-01 20:41:39",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "AD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"支持并行架构，行列混存。\"},{\"Key\":\"B\",\"Value\":\"部署的服务器都必须是华为定制的。\"},{\"Key\":\"C\",\"Value\":\"支持多节点，但扩展性差.\"},{\"Key\":\"D\",\"Value\":\"支持 master\\/slave 架构，可靠性强。\"}]",
      "id": "334414059",
      "paperid": "3211551",
      "hash": "18bdf866dee3bd35e5943c0fa5ae5475a04bf715",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Hive数据存储规模包括哪些成分?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:46",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ABCD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 分区\"},{\"Key\":\"B\",\"Value\":\" 表\"},{\"Key\":\"C\",\"Value\":\" 数据库\"},{\"Key\":\"D\",\"Value\":\" 桶\"}]",
      "id": "394096084",
      "paperid": "3211551",
      "hash": "54c5c87eeb8b25683f755ed8b37d4a4f12076311",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Structured Streaming支持的数据源包括?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:33",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ABCD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" HDFS\"},{\"Key\":\"B\",\"Value\":\" Kafka\"},{\"Key\":\"C\",\"Value\":\" Socket\"},{\"Key\":\"D\",\"Value\":\" Rate Stream\"}]",
      "id": "394095841",
      "paperid": "3211551",
      "hash": "c3d717131c9b039c51c4156bd4b1b1c3696628b7",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "以下关于 Transformation 的说法正确的是?（）",
      "qtype": "2",
      "created_at": "2022-01-01 20:41:39",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ABCD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"它的返回值还是一个 RDD\"},{\"Key\":\"B\",\"Value\":\"是 RDD 的算子类型\"},{\"Key\":\"C\",\"Value\":\"属于懒操作\"},{\"Key\":\"D\",\"Value\":\"map(func) 属于 Transformation\"}]",
      "id": "334414260",
      "paperid": "3211551",
      "hash": "632299a3b7e6156618838291fb3d9076b6ba0098",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Structured Streaming中通过什么机制，解决数据的无序和滞后问题？",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "CD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" 留连接\"},{\"Key\":\"B\",\"Value\":\" 持续查询\"},{\"Key\":\"C\",\"Value\":\" Wartermark机制\"},{\"Key\":\"D\",\"Value\":\" 事件时间\"}]",
      "id": "394095003",
      "paperid": "3211551",
      "hash": "cb065ad05b4e000317a06c97a79c9604d95ad321",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "大数据计算框架Flink的支持哪些资源调度方式?",
      "qtype": "2",
      "created_at": "2022-03-10 08:30:46",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ABCD",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\" Docker\"},{\"Key\":\"B\",\"Value\":\" YARN\"},{\"Key\":\"C\",\"Value\":\" Standalone\"},{\"Key\":\"D\",\"Value\":\" Mesos\"}]",
      "id": "394096070",
      "paperid": "3211551",
      "hash": "da8e1b16ca48e6eadfed0274701a731088c54dd8",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " Hive是大数据SQL批处理引擎，用于处理SQL类批处理作业，但是处理速度较慢。",
      "qtype": "3",
      "created_at": "2022-03-10 08:30:11",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394095328",
      "paperid": "3211551",
      "hash": "24026dee5c9666a41929e0ae175139cdaffd7915",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "在信用卡反欺诈场景中，可以通过实时分析的规则拦截欺诈行为。",
      "qtype": "3",
      "created_at": "2022-03-10 08:29:04",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394093173",
      "paperid": "3211551",
      "hash": "1d0ca8cf2074cd09e053435389679d66b86d7577",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " GraphBase既支持分布式部署也支持单机部署。",
      "qtype": "3",
      "created_at": "2022-03-10 08:30:11",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394095299",
      "paperid": "3211551",
      "hash": "347a0ddc919e056ea9b8b32c436c2efdee214f6b",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "每个Topic 都由一个或者多个Partitions构成，Partition数量决定了每个Consumer group中并发消费者的最大数量。",
      "qtype": "3",
      "created_at": "2021-12-26 10:33:41",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "326684164",
      "paperid": "3211551",
      "hash": "0a86bebcfd23266dc2911d3b2013c1cee8d483ed",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " GaussDB 200支持索引，为了查询的高效，应对每一个查询字段设置索引。",
      "qtype": "3",
      "created_at": "2022-03-10 08:30:11",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394095377",
      "paperid": "3211551",
      "hash": "2c830d50981e18b8726783121658417b77abd08d",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " 离线批处理通常通过MR作业、Spark作业或者HQL作业实现。",
      "qtype": "3",
      "created_at": "2022-03-10 08:30:11",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394095323",
      "paperid": "3211551",
      "hash": "92e532bc3abb0ebcae4c7113f00b9e631b40d009",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " 技术选型时应该采用最新的技术不需要考虑技术的稳定性。",
      "qtype": "3",
      "created_at": "2022-03-10 08:30:11",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394095326",
      "paperid": "3211551",
      "hash": "5b1a955bb5d9df991ac8ebea565032015885d48d",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "  应用开发需要进行需求分析，包括需求调研和市场调研。",
      "qtype": "3",
      "created_at": "2022-03-10 08:30:11",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394095325",
      "paperid": "3211551",
      "hash": "caaa62bf3e2eecf38408ff98bd30cd64fb564221",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Flume可以在系统中定制各类数据发送方,用于数据收集同时提供简单的数据处理,并将简单处理的数据写入各种数据接收方,如文本、HDFS、Kafka和HBase.",
      "qtype": "3",
      "created_at": "2022-02-19 18:37:50",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "369559531",
      "paperid": "3211551",
      "hash": "f2cebf187ac3673924264921d65c57e2ad6845d6",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Elasticsearch 默认是先把索引存放到内存中，当内存满了时再持久化到本地硬盘。",
      "qtype": "3",
      "created_at": "2022-01-01 19:01:53",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "334336048",
      "paperid": "3211551",
      "hash": "3efef9f9ed4a73b3573c0058fe811ca6464f2f74",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Kafka中的Broker在收到新消息后会立即存入磁盘。",
      "qtype": "3",
      "created_at": "2021-12-29 09:42:28",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "330824090",
      "paperid": "3211551",
      "hash": "1ec37142b0095c40333a4b9c9447172c8607ad54",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " Flink处理数据是无状态的，处理一个事件与之前的事件无关 。",
      "qtype": "3",
      "created_at": "2022-03-10 08:30:11",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394095352",
      "paperid": "3211551",
      "hash": "226b1d43d811620ff12c470b7103546e84b73cf3",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " 每个查询会被Hive转化为多个阶段，当有些阶段关联性较大时，可以并行化执行，诚少整个任务的执行时间。",
      "qtype": "3",
      "created_at": "2022-03-10 08:30:11",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394095370",
      "paperid": "3211551",
      "hash": "9914dafd908aaa8f9eabbdbf982387b80351a3b4",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "  高频交易，市场舆情分析，信贷风险分析等这些金融领域的研究内容均可以利用大数据技术进行分析。",
      "qtype": "3",
      "created_at": "2022-03-10 08:30:11",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394095368",
      "paperid": "3211551",
      "hash": "b1625a53a25e8dfdbb1c2b3d861c5fcda9702d89",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "  SparkSQL可以进行实时查询。",
      "qtype": "3",
      "created_at": "2022-03-10 08:30:11",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394095332",
      "paperid": "3211551",
      "hash": "5554925d0aef9a60d8cc5ee09045992295fda129",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "GES创建索引必须在创建schema之后，创建点边之前，否则数据查询不到。",
      "qtype": "3",
      "created_at": "2022-03-10 08:29:04",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394093187",
      "paperid": "3211551",
      "hash": "2413615a03befaa2f9d4ccd46d9c97d12ccfbd76",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "  GaussDB 200数据导出操作不支持导出数据到HDFS文件系统。",
      "qtype": "3",
      "created_at": "2022-03-10 08:30:11",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394095387",
      "paperid": "3211551",
      "hash": "9ac168cebf3d5aeedd4b6d1806f376e4fd67afe6",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " 某公司大数据业务存在多种计算任务，包括使用CPU，GPU等多种异构计算芯片，为了保证资源的合理利用调度，可以依据华为云Stack架构，构建——站式平合，资源统——管理、按需分配。",
      "qtype": "3",
      "created_at": "2022-03-10 08:30:11",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394095367",
      "paperid": "3211551",
      "hash": "9990522430340ed6a9bf2681711430e729d3ec3a",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " Producer通过Push的方式将消息发送到Broker 。",
      "qtype": "3",
      "created_at": "2022-03-10 08:30:11",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394095348",
      "paperid": "3211551",
      "hash": "0557263e7d6f34a1d0b2d190b5c7be1bf8ee1e1b",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " Flink 是 Apache社区孵化的项目。",
      "qtype": "3",
      "created_at": "2022-02-19 18:37:50",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "369559528",
      "paperid": "3211551",
      "hash": "14df299fa5cad4029979cbdac84d7e9e4e9a1092",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "  在DWS服务中，通过GDS并行导入数据时，需要明确DWS的集群IP地址。",
      "qtype": "3",
      "created_at": "2022-03-10 08:30:11",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394095291",
      "paperid": "3211551",
      "hash": "8ad2646ca62774d0f96021c1114e78ba7195f20d",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " Redis每个数据库对外都是以一个从0开始的递增数字命名，支持自定义。",
      "qtype": "3",
      "created_at": "2022-03-10 08:29:04",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394093182",
      "paperid": "3211551",
      "hash": "4d8dfabe6d1c4b30256faa89b64090875cc5330d",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Redis Server 收到非归属本节点的 KEY 操作，会将请求转发到正确的节点上。",
      "qtype": "3",
      "created_at": "2022-01-01 18:52:00",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "334331666",
      "paperid": "3211551",
      "hash": "a3c709f5c11fe8909de373720e79e3f6e5eead9f",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " Kafka可以同时解决在线应用消息和离线应用日志的数据处理问题。",
      "qtype": "3",
      "created_at": "2022-03-10 08:30:11",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394095385",
      "paperid": "3211551",
      "hash": "b71078d4fdec5893f1f24213ae06ac74fafd08e8",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " 大数据离线批处理支持SQL类作业和自定义作业。",
      "qtype": "3",
      "created_at": "2022-03-10 08:30:11",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394095390",
      "paperid": "3211551",
      "hash": "94399b3ef37546e477d066092a7f680c352268d6",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " 实时数据处理的的关键意义在于能够更快地提供数据洞察。",
      "qtype": "3",
      "created_at": "2022-03-10 08:30:11",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394095320",
      "paperid": "3211551",
      "hash": "3ac55557c1e1fd673d34b7b18c94263031ae114a",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Flink中无界流的数据都可以被排序，所以并不需要有序读取。",
      "qtype": "3",
      "created_at": "2022-03-10 08:29:04",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394093179",
      "paperid": "3211551",
      "hash": "d4e866c76591134d855e610c2d2d5c02686bf869",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "实时流处理系统中，要求数据权限和资源隔离，多种流处理应用之间要进行资源控制和隔离，防止发生资源争抢。",
      "qtype": "3",
      "created_at": "2022-03-10 08:29:04",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394093176",
      "paperid": "3211551",
      "hash": "f647c8c5206b85a1bbbfaec85a9915f3073e419c",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " SQL on Anywhere的意思是 GaussDB 200的SQL可以运行在任何地方的数据库。",
      "qtype": "3",
      "created_at": "2022-03-10 08:30:11",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394095375",
      "paperid": "3211551",
      "hash": "9481e1f384c613282957d7a5d74836c3c820469a",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " Sqoop主要用来做实时流处理。",
      "qtype": "3",
      "created_at": "2022-03-10 08:30:11",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394095333",
      "paperid": "3211551",
      "hash": "ae94fb16ce7607c743f17d4ba2c54d3bc9910b42",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "HBase 支持 Rowkey 查询和二级索引查询。",
      "qtype": "3",
      "created_at": "2022-01-01 20:47:19",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "334422113",
      "paperid": "3211551",
      "hash": "8bdbb2220f1da7f5d7d658d64487dcd8c573344f",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " HBase是—种分布式数据库，不依赖HDFS也可以运行。",
      "qtype": "3",
      "created_at": "2022-03-10 08:30:11",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394095321",
      "paperid": "3211551",
      "hash": "87010a85ced444ab53e78da555584bf04f3940e7",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "  数据湖需要高性能、Schema校验、事务型更新等能力，同时支持多个开源计算引擎生态。",
      "qtype": "3",
      "created_at": "2022-03-10 08:30:11",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394095369",
      "paperid": "3211551",
      "hash": "e0a1298d6b77a297f9ed2065729c11ce7c2be56b",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " 批处理优先推荐使用Spark或Spark SQL模式，也可以使用MapReduce 或Hive模式。两种批处理模式可以同时使用。（）",
      "qtype": "3",
      "created_at": "2022-03-10 08:30:11",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394095380",
      "paperid": "3211551",
      "hash": "7e9530aca1398fc3949102734a6bef1877ad6cb6",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "任何完整的大数据平台，一般包括以下的几个过程，数据采集- >数据存储>数据处理->数据展现(可视化，报表和监控)。其中， 数据采集是所有数据系统必不可少的个环节， 随着大数据越来越被重视，数据采集的挑战也变的尤为突出。",
      "qtype": "3",
      "created_at": "2022-01-01 18:58:26",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "334334792",
      "paperid": "3211551",
      "hash": "2896079d27e36a558a5a6c7ce1c2bb4d5d522099",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " 实时流处理架构可用于公安监控业务、金融反欺诈业务或者其他实时业务。",
      "qtype": "3",
      "created_at": "2022-03-10 08:29:04",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394093192",
      "paperid": "3211551",
      "hash": "e51c3d2d15a1dbf471844ce1a6fcb51e1af8f501",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " 本实验对数据处理过程中，进行了数据分层处理。",
      "qtype": "3",
      "created_at": "2022-03-10 08:30:11",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394095371",
      "paperid": "3211551",
      "hash": "29d2a299d2935bf31a00cdb31f1b10f93fb2fec6",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " 实时检索的金融场景应用中，可以查询交易凭证，追溯交易，以及查询客户信用记录，帮助客户快速借款。",
      "qtype": "3",
      "created_at": "2022-03-10 08:30:11",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394095356",
      "paperid": "3211551",
      "hash": "b242bf133daaeb8284277a38be0edbc0c4f6eeeb",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "GES的Edge都是单向边，如果需要双向边，则通过两条相反方向的单向边组成。",
      "qtype": "3",
      "created_at": "2021-12-29 09:42:28",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "330824060",
      "paperid": "3211551",
      "hash": "b722f39f3e04ccee121faecbae3bbceebe44b881",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "  Sqoop进行数据导出时，也会进行数据文件切片，与MapReduce切片类似，可以通过修改参数block块大小进行切片数量优化。",
      "qtype": "3",
      "created_at": "2022-03-10 08:30:11",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394095340",
      "paperid": "3211551",
      "hash": "5de0a093711560d8aed1d93d443e033d6710df7e",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Redis中List是一个有序的字符串列表，列表内部实现是使用双向链表(linked list)实现的。",
      "qtype": "3",
      "created_at": "2022-02-19 18:37:50",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "369559539",
      "paperid": "3211551",
      "hash": "8371ba7c01db21a09910c73c5777294a6bc4e342",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Cloudera 是 Hadoop 商业版的发布公司。",
      "qtype": "3",
      "created_at": "2022-01-01 19:01:17",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "334335728",
      "paperid": "3211551",
      "hash": "346312451bcc6062eb361a75ef6b83ca3a7b5847",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "离线批处理对数据处理的时延要求不高，但是处理的数据量较大，占用的计算存储资源较多，不建议选用Spark作业实现。",
      "qtype": "3",
      "created_at": "2022-01-21 16:35:32",
      "analysis": "",
      "parentid": "0",
      "difficulty": "1",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "351060366",
      "paperid": "3211551",
      "hash": "f508a3482b58dcae581f7e204076f460ce6374ed",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " HBase支持完整的事务机制。",
      "qtype": "3",
      "created_at": "2022-03-10 08:30:11",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394095357",
      "paperid": "3211551",
      "hash": "df9adca0797c9b2d2baf62cd9759118b150276af",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "为了考虑性能最优化,建议将所有集群中LdapServer都与KrbServer部署在相同节点上。 ",
      "qtype": "3",
      "created_at": "2022-07-21 21:42:49",
      "analysis": "",
      "parentid": "0",
      "difficulty": "1",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "606559905",
      "paperid": "3211551",
      "hash": "67061bbcdf6a3fb785721f7fc5cd591d6dc5408c",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " GaussDB 200通过Extensi on Connector可以跨集群访问Orac1e数据库.MySQL数据库.Spark和其他GaussDB集群.",
      "qtype": "3",
      "created_at": "2022-03-10 08:30:11",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394095290",
      "paperid": "3211551",
      "hash": "69b908f537eb19626438f37e6039b154b8b3b082",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "离线批量的作业形式:可以通过例如 HOL 和 SparkSQL 的命令，也可以通过 API 编写代码，打包提交运行。",
      "qtype": "3",
      "created_at": "2022-01-01 20:47:19",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "334422108",
      "paperid": "3211551",
      "hash": "a03001933396e1f504765c237c1bf2f830783ee7",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " Hive在删除表的时候，内部表的元数据和实际数据不会被一起删除。",
      "qtype": "3",
      "created_at": "2022-03-10 08:30:11",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394095329",
      "paperid": "3211551",
      "hash": "aff5de377ed64b64dbca6166bb855d728537305b",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "HDFS 中的 DataNode 用于存储实际的数据，将自己管理的数据块上报给 C1ient,运行多个实例。",
      "qtype": "3",
      "created_at": "2022-01-01 20:47:19",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "334422123",
      "paperid": "3211551",
      "hash": "f69416df89cf2656b5781a35d0d047c38e2d5be5",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "  实时流处理系统中，当系统处理能力出现瓶颈后，可通过节点的水平扩展提升处理性能。",
      "qtype": "3",
      "created_at": "2022-03-10 08:30:11",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394095364",
      "paperid": "3211551",
      "hash": "b8b2606cf4f6dd9fff001f869c1667481532ebf3",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "HBase的scan方法读取数据时返回的数据保存在Result对象中。",
      "qtype": "3",
      "created_at": "2022-02-19 18:37:50",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "369559536",
      "paperid": "3211551",
      "hash": "14b8c913d322d7cf3e3639ad7eb16f6e23c004d6",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Gremlin支持同步提交和异步提交。",
      "qtype": "3",
      "created_at": "2021-12-26 10:33:41",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "326684140",
      "paperid": "3211551",
      "hash": "76b70070bfc4f7c8e6e4e82c8a9ed3af177f5757",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "ElasticSoarch 中，只要一-个 shard 请求成功即可向用户返回 Success 消息。",
      "qtype": "3",
      "created_at": "2022-01-01 20:47:19",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "334422099",
      "paperid": "3211551",
      "hash": "944e3b063d42f7e8840e3d17512fea155b27b9e9",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Redis 默认支持 14 个数据库。",
      "qtype": "3",
      "created_at": "2022-01-01 20:47:19",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "334422135",
      "paperid": "3211551",
      "hash": "69fc1cbb883b95a4ab598a85e9cbbc14585089e1",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "  ElasticSearch作为全文检索的引擎，其功能强大，也可以作为NoSQL数据库使用，能满足海量数据存储的需要，也满足主键和多级索引的实时查询。",
      "qtype": "3",
      "created_at": "2022-03-10 08:30:11",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394095297",
      "paperid": "3211551",
      "hash": "7a9db872da96efca9e01dd923f5848c7f9bf5bd2",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " 本实验的数据源包含网站日志数据和数据库业务数据。",
      "qtype": "3",
      "created_at": "2022-03-10 08:30:11",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394095337",
      "paperid": "3211551",
      "hash": "1aee930964af68ccefd195b86d28dae330278d19",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " 实时流处理计算框架中实时性最好的是Structured Streaming,",
      "qtype": "3",
      "created_at": "2022-03-10 08:30:11",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394095382",
      "paperid": "3211551",
      "hash": "b1cc9869f15e8fb962d0abd22010d13ed47d6362",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "实时布控场景中，数据实时采集可以通过警务数据共享交换平台与边界平台，实时获取出行/住宿/通讯/视频数据。",
      "qtype": "3",
      "created_at": "2021-12-26 10:33:41",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "326684150",
      "paperid": "3211551",
      "hash": "c67b4562d233d369c8938fe6aef489cb157ef006",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "因不同的数据类型存储的空间大小不一样，所以在选择数据类型时，只需考虑数据类型损耗的存储空间大小。",
      "qtype": "3",
      "created_at": "2022-01-01 20:47:19",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "334422101",
      "paperid": "3211551",
      "hash": "0c42e2d23d724668911345c0a074b28839a6e9f6",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "某大数据业务人员希望确保某份关键数据在Hive中不会因为drop操作导致数据删除。他可以采用内部表的方式来实现，drop操作时只会删除元数据而不会删除表数据。",
      "qtype": "3",
      "created_at": "2022-03-10 08:29:04",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394093189",
      "paperid": "3211551",
      "hash": "849b79b42c135d83d6810b7c4916d76a4adc83cb",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Flume的Source可以不用和channel关联，直接连接到sink.",
      "qtype": "3",
      "created_at": "2022-03-10 08:29:04",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394093175",
      "paperid": "3211551",
      "hash": "a831d4c329c36bfa5518856267224609c563b045",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " Gauss DB 200在内部使用行标识符（CT ID）记录数据在表中的逻辑位置。",
      "qtype": "3",
      "created_at": "2022-03-10 08:30:11",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394095315",
      "paperid": "3211551",
      "hash": "f923df1c103069db78bdeba5a98c154613d00a6e",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " ElasticSearch 倒排索引是通过关键词查询对应的文档编号，再通过文档编号找文档。",
      "qtype": "3",
      "created_at": "2022-03-10 08:30:11",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394095301",
      "paperid": "3211551",
      "hash": "faf939c74acdc32cd9ad33f05b4af85f9611236b",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "MRS的安全模式一般是用于生产环境。",
      "qtype": "3",
      "created_at": "2022-03-10 08:29:04",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394093190",
      "paperid": "3211551",
      "hash": "49a57ca76b0f93f90f7c597fe5c89c94f1f9600e",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " 大数据是指利用常用软件工具捕获、管理和处理数据所耗时间超过可容忍时间的数据集。",
      "qtype": "3",
      "created_at": "2022-03-10 08:30:11",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394095319",
      "paperid": "3211551",
      "hash": "2bff88bea3f1d8204b10316729649abe3ae26ef0",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "BloomFilter可以被用来快速的判断一条数据在一个大的数据集合中是否存在。",
      "qtype": "3",
      "created_at": "2021-10-31 09:48:31",
      "analysis": "",
      "parentid": "0",
      "difficulty": "1",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "256723781",
      "paperid": "3211551",
      "hash": "2fbb7058f8fb28752a96f945c4e3c8b2f5f10b0c",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " GaussDB 200支持数据的并行导入导出，所以为了充分利用GaussDB 200的分布式数据库的性能，每一次的数据导入导出都用并行的方式进行。（）",
      "qtype": "3",
      "created_at": "2022-03-10 08:30:11",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394095378",
      "paperid": "3211551",
      "hash": "4cef3fea84990a3e7b81be86766af222ef2501de",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Spark 是基于内存的，处理数据时产生的中间产物(计算结果)是存放在内存中，减少了对磁盘的 I1/0 操作， 大大的提升了数据的处理速度。",
      "qtype": "3",
      "created_at": "2022-01-01 20:47:19",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "334422088",
      "paperid": "3211551",
      "hash": "07fb8cbda8149d95b99dfd360d700d0dfb5bb8c7",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "列创建propertykey的代码正确吗?PropertyKey propertyKey = new PropertyKey （） ;PropertyKey.setDataType （DataType.String） ;PropertyKey.setName （\"name\"） ;Api.addPropertyKey （propertyKey） ;",
      "qtype": "3",
      "created_at": "2022-03-10 08:29:04",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394093169",
      "paperid": "3211551",
      "hash": "b585c970030453f8dfc1cf4cc92d30ee30675e98",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Kettle 中有两种脚本文件 transformation (转换 ktr 结尾)和 job (任务 kjb 结尾)",
      "qtype": "3",
      "created_at": "2022-01-01 20:47:19",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "334422087",
      "paperid": "3211551",
      "hash": "883b9b47135ff00926c31e818638443828eaf9b4",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Redis命令区分大小写。",
      "qtype": "3",
      "created_at": "2022-03-10 08:29:04",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394093164",
      "paperid": "3211551",
      "hash": "3e26a6c1950daf001deda319ec6a1e4269a3417f",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " 实时流处理对时延的要求不高。",
      "qtype": "3",
      "created_at": "2022-03-10 08:30:11",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394095324",
      "paperid": "3211551",
      "hash": "5d62f085fca8913f95b820027c4d6485890e4f45",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Flink处理数据可以是有状态的，处理一个事件取决于之前所有事件的累积效果。",
      "qtype": "3",
      "created_at": "2022-02-19 18:37:50",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "369559529",
      "paperid": "3211551",
      "hash": "710ca5b3270d59c67eb769271c2ccb57db67be68",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "MapReduce某任务失败时可通过重试机制重新计算该任务。 ",
      "qtype": "3",
      "created_at": "2022-07-21 21:40:55",
      "analysis": "",
      "parentid": "0",
      "difficulty": "1",
      "uid": "1090076",
      "path": "",
      "answer": "A",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "606556220",
      "paperid": "3211551",
      "hash": "fec3cddd82a21439dea8734b73f4481548e974b6",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "逻辑集群可以使用全部物理集群的资源()",
      "qtype": "3",
      "created_at": "2022-01-01 20:47:19",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "334422169",
      "paperid": "3211551",
      "hash": "e969d8f5569658fd22c708055d9b6dcc84835e6e",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " Flink仅支持基于时间窗口操作。",
      "qtype": "3",
      "created_at": "2022-03-10 08:30:11",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394095318",
      "paperid": "3211551",
      "hash": "be5594537a0518dcb415285598ea30d0930fabb0",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "  实时检索查询只能查询结构化数据。",
      "qtype": "3",
      "created_at": "2022-03-10 08:30:11",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394095312",
      "paperid": "3211551",
      "hash": "d18f8c2907323db0e9dec1b7c46018b43d4d1f01",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "某电商公司的一位数据分析师在使用Hive进行数据分析时，不慎删除了一个外部表，那么元数据和业务数据将一起都被删除，并且数据不可恢复。",
      "qtype": "3",
      "created_at": "2022-03-10 08:29:04",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394093186",
      "paperid": "3211551",
      "hash": "d97b38e681fb006793fd3f5c1d403116f7cf56e3",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "针对不同的数据来源，需要先分析其数据特征，例如一般网站产生的日志特点是数据量大，价值密度高，数据的业务种类多且涵盖之前的数据。",
      "qtype": "3",
      "created_at": "2022-01-01 20:47:19",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "334422109",
      "paperid": "3211551",
      "hash": "a1208cf53bb39ed1360d9e2a7525d63ebe53ac94",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " 基于Foreign Table 的连接可以连接任何同构和异构数据库。",
      "qtype": "3",
      "created_at": "2022-03-10 08:30:11",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "B",
      "extra": "",
      "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]",
      "id": "394095376",
      "paperid": "3211551",
      "hash": "e6e44d6d06b14ace04c4ac37791602ea2b49fbe0",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "HBase不需要完全拥有传统关系型数据库所具备的（ ）特性。 ",
      "qtype": "4",
      "created_at": "2022-03-09 21:22:10",
      "analysis": "",
      "parentid": "0",
      "difficulty": "1",
      "uid": "1090076",
      "path": "",
      "answer": "ACID",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[]",
      "id": "393804501",
      "paperid": "3211551",
      "hash": "4817a7d8aa06cea356b57f174e5abc3f78630525",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "HBase提供2种类型的缓存结构：MemStore和（  ）",
      "qtype": "4",
      "created_at": "2022-01-21 16:42:50",
      "analysis": "",
      "parentid": "0",
      "difficulty": "1",
      "uid": "1090076",
      "path": "",
      "answer": "Blockcache",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[]",
      "id": "351064163",
      "paperid": "3211551",
      "hash": "e89f413afc6de04e145dce4ee4e766632394ef92",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "HBase建表时预先设置多个Region，数据会按照(    )对应Region分区情况，在集群内做数据的负载均衡。",
      "qtype": "4",
      "created_at": "2021-10-31 10:04:39",
      "analysis": "",
      "parentid": "0",
      "difficulty": "1",
      "uid": "1090076",
      "path": "",
      "answer": "RowKey",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[]",
      "id": "256734572",
      "paperid": "3211551",
      "hash": "031cc107de74c78e0895db41035d07c65ebbf050",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " ()(请填写英文)命令可以清空当前数据库的数据。 ",
      "qtype": "4",
      "created_at": "2022-02-19 18:39:56",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "flushall",
      "extra": "",
      "options": "[]",
      "id": "369559919",
      "paperid": "3211551",
      "hash": "9de718ea6aa67f87837a247a1814d8c3249030e7",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " Flume的Channel有多种类型，其中（ ）在机器宕机时可能丢失数据。 ",
      "qtype": "4",
      "created_at": "2022-03-10 08:30:46",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "MemoryChannel",
      "extra": "",
      "options": "[]",
      "id": "394096008",
      "paperid": "3211551",
      "hash": "697553c4d4f14257c2a588f7cd59e4beacd9aa80",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "GES中用（）表示边的类型，用于表示现实世界中的关系类型。",
      "qtype": "4",
      "created_at": "2022-03-09 20:42:57",
      "analysis": "",
      "parentid": "0",
      "difficulty": "1",
      "uid": "1090076",
      "path": "",
      "answer": "EdgeLabel",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[]",
      "id": "393715753",
      "paperid": "3211551",
      "hash": "02d72f29d5d339ba6387ce8f2bdc6961c4b8b912",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "HBase通过()快速判断用户数据不存在。",
      "qtype": "4",
      "created_at": "2022-02-19 18:39:56",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "exist",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[]",
      "id": "369559922",
      "paperid": "3211551",
      "hash": "1a7f34d8a76e802eff58585dfa39ba7956f7b5d3",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "在ElasticSearch中，通过Key寻找Value，即从关键点出发，然后再通过关键点找到信息中满足搜索条件的特定信息。这描述的是 （）（请填写中文）索引机制。 ",
      "qtype": "4",
      "created_at": "2022-03-10 08:30:33",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "正排",
      "extra": "",
      "options": "[]",
      "id": "394095859",
      "paperid": "3211551",
      "hash": "f9c444e5c96e997626cca693c6b5511e06f81f84",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "DAYU基于数据湖实现图数据库与图分析算法融合，支撑丰富多样的 （ ）（请填写中文）应用。 ",
      "qtype": "4",
      "created_at": "2022-03-10 08:30:46",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "图分析",
      "extra": "",
      "options": "[]",
      "id": "394096035",
      "paperid": "3211551",
      "hash": "2ddc658cc258810c343ce137c067d52e6b1182a8",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": " Hive自定义函数中的 ()（请填写英文缩写）用于接收单个数据行，并产生多个数据行作为输出。 ",
      "qtype": "4",
      "created_at": "2022-02-19 18:39:56",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "UDTF",
      "extra": "",
      "options": "[]",
      "id": "369559924",
      "paperid": "3211551",
      "hash": "d2a5db78538eb9559599e8a897e88fffc5d31985",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Spark通过Stage进行任务划分，而Stage的划分主要依赖（ ）机制。",
      "qtype": "4",
      "created_at": "2021-12-29 09:42:28",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "shuffle",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[]",
      "id": "330824049",
      "paperid": "3211551",
      "hash": "0e9eee9b964e7d1f3c13b85811a25ff875f9460a",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Kafka由  （）及Topic构成",
      "qtype": "4",
      "created_at": "2022-02-19 18:39:56",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "Partition",
      "extra": "",
      "options": "[]",
      "id": "369559925",
      "paperid": "3211551",
      "hash": "9c8572f832b78aa9dce18400ac1da4e3fa0ca4e7",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "在Hive中，使用函数名为（）的函数去除空字符串。",
      "qtype": "4",
      "created_at": "2022-01-21 16:39:49",
      "analysis": "",
      "parentid": "0",
      "difficulty": "1",
      "uid": "1090076",
      "path": "",
      "answer": "trim",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[]",
      "id": "351061678",
      "paperid": "3211551",
      "hash": "211cf619b5880d9aaa87b78379b8f9b7b30d22ed",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "为了使得Kafka的吞吐率可以线性提高，物理上把Topic分成一个或多个（）。                                ",
      "qtype": "4",
      "created_at": "2022-03-09 20:39:15",
      "analysis": "",
      "parentid": "0",
      "difficulty": "1",
      "uid": "1090076",
      "path": "",
      "answer": "Partition",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[]",
      "id": "393707724",
      "paperid": "3211551",
      "hash": "e4609488f9f202e841315e0efbf6f751994bf727",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "创建Loader 作业中,可以在（）步骤中设置过滤器类型? ",
      "qtype": "4",
      "created_at": "2022-02-19 18:39:56",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "输入设置",
      "extra": "",
      "options": "[]",
      "id": "369559927",
      "paperid": "3211551",
      "hash": "9ff97c53a226ac28eb2bc54ab3e1384c41cdd036",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "（  ）以Catalyst逻辑执行计划表示，并且数据以编码的二进制形式存储",
      "qtype": "4",
      "created_at": "2022-01-21 16:32:44",
      "analysis": "",
      "parentid": "0",
      "difficulty": "1",
      "uid": "1090076",
      "path": "",
      "answer": "spark",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[]",
      "id": "351057084",
      "paperid": "3211551",
      "hash": "37829787f7a09ca715b4327ad5a5333d0aaa0ff7",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Flume提供从固定目录下采集日志信息到HDFS.（  ）和Kafka的能力",
      "qtype": "4",
      "created_at": "2022-01-21 16:58:04",
      "analysis": "",
      "parentid": "0",
      "difficulty": "1",
      "uid": "1090076",
      "path": "",
      "answer": "数据库",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[]",
      "id": "351081970",
      "paperid": "3211551",
      "hash": "d6c88c6951e5673bb5bed41223ec6406e4efb4eb",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Loader通过组件（  ）来实现认证以及作业权限管理。",
      "qtype": "4",
      "created_at": "2021-12-26 10:33:41",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "kerberos",
      "extra": "",
      "options": "[]",
      "id": "326684129",
      "paperid": "3211551",
      "hash": "85e93c96d64f27fe2701f95e83943571ddbf45a7",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "() (请填写英文)是Flume数据传输的基本单元。/",
      "qtype": "4",
      "created_at": "2022-02-19 18:39:56",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "event",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[]",
      "id": "369559918",
      "paperid": "3211551",
      "hash": "6c2181de4fdf2f5cf4f041c2fb860d4dd4d9570b",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "HBase中Scan查询结果的多行数据保存在（ ）对象中，每行数据以Result对象形式存储。 ",
      "qtype": "4",
      "created_at": "2022-03-10 08:30:46",
      "analysis": "",
      "parentid": "0",
      "difficulty": "2",
      "uid": "1090076",
      "path": "",
      "answer": "ResultScanner",
      "extra": "",
      "options": "[]",
      "id": "394095981",
      "paperid": "3211551",
      "hash": "7f731d31d7045da501d8b7b0a1a21150656f7d3d",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "华为VUE考试须知：<p>1.考试随机抽取 60 题，满分 1000 分，考 600 即可通过；</p><p>2.题库全部掌握后再预约考试，考前一天预约离自己最近的考点即可;</p><p>3.考试题型为单选和多选、判断、填空、拖图，题目不会告知单选还是多选，你可以通过选项判断：单选选项前面是“圆圈”，多选选项前是“方框”；</p><p>4.考试题目和选项均随机乱序；</p><p>5.证件：身份证+（学生证 工作证 信用卡 社保卡护照）其中一个共等2个证件</p><p>6.提前10分钟到达考场 （如遇到特殊情况，迟到可以和考场联系）</p><p><br></p><p>中兴VUE考试须知：</p><p><br></p><p>1.考试随机抽取 60 题，满分 100 分，考 60 即可通过；（部分考试80分通过：例如中兴服务规范）</p><p>2.题库全部掌握后再预约考试，考前一天预约离自己最近的考点即可;</p><p>3.考试题型为单选、判断、和多选，各20题；</p><p>4.考试题目顺序是单选、多选、判断；选项均随机乱序；</p><p>5.证件：身份证</p><p>6.提前10分钟到达考场 （如遇到特殊情况，迟到可以和考场联系）</p><p><br></p><p><br></p>",
      "qtype": "5",
      "created_at": "2022-03-06 20:31:32",
      "analysis": "",
      "parentid": "0",
      "difficulty": "1",
      "uid": "1090076",
      "path": "",
      "answer": "<p>同上</p>",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[]",
      "id": "388824601",
      "paperid": "3211551",
      "hash": "2f31bc3210dd541f96200b5313561f0f38200078",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Spark运行前需要读取任务参数，包含配置文件、动态参数、代码配置等，请连接将他们的优先级进行匹配。",
      "qtype": "5",
      "created_at": "2021-12-22 10:00:42",
      "analysis": "",
      "parentid": "0",
      "difficulty": "1",
      "uid": "1090076",
      "path": "",
      "answer": "<p><img src=\"https://up.zaixiankaoshi.com/docs/23/71/2371b19670310ccfd309fc64f0b78c69.png\" alt=\"2371b19670310ccfd309fc64f0b78c69.png\"></p>",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[]",
      "id": "320605626",
      "paperid": "3211551",
      "hash": "ac3478d69a3c81fa62e60f5c3696165a4e5e6ac4",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "Katka创建Topic时如何将分区放置到不同的Broker中，请选择正确的顺序。<p><br></p><p><img src=\"https://up.zaixiankaoshi.com/docs/85/2e/852ed19a4f9d6ea8e96f5ee133d5b3c1.png\" alt=\"852ed19a4f9d6ea8e96f5ee133d5b3c1.png\"></p>",
      "qtype": "5",
      "created_at": "2021-12-22 10:03:16",
      "analysis": "",
      "parentid": "0",
      "difficulty": "1",
      "uid": "1090076",
      "path": "",
      "answer": "<p>同上</p>",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[]",
      "id": "320614276",
      "paperid": "3211551",
      "hash": "2f31bc3210dd541f96200b5313561f0f38200078",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "下列是ElasticSearch批量索引流程，请选择正确的顺序。",
      "qtype": "5",
      "created_at": "2021-12-29 09:48:04",
      "analysis": "",
      "parentid": "0",
      "difficulty": "1",
      "uid": "1090076",
      "path": "",
      "answer": "<p><img src=\"https://up.zaixiankaoshi.com/docs/0f/22/0f2269bf0d6453125a928b5a6eb85d62.png\" alt=\"0f2269bf0d6453125a928b5a6eb85d62.png\"></p>",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[]",
      "id": "330832554",
      "paperid": "3211551",
      "hash": "ac3478d69a3c81fa62e60f5c3696165a4e5e6ac4",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    },
    {
      "chapter": "0",
      "question": "HDFS数据读取流程包括下面几步，请选择正确的顺序",
      "qtype": "5",
      "created_at": "2022-02-19 18:41:36",
      "analysis": "",
      "parentid": "0",
      "difficulty": "1",
      "uid": "1090076",
      "path": "",
      "answer": "<p>客户端调用FileSystem 实例的open方法，获得这个文件对应的输入流。---------1</p><p>通过RPC远程调用NameNode获得、NameNode中此文件对应的数据块的保存位置--------2</p><p>获得此输入流之后，客户端调用read方法读取数据。输入流选择最近的DataNode建立连接并读取数据。----------3</p><p>如果已达到数据块末端。那么关闭与这个DataNode的连接，然后重新查找下—个数据块。直到数据全部读完。-----------4</p><p>客户端调用close关闭输入流。--------------5</p>",
      "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}",
      "options": "[]",
      "id": "369561076",
      "paperid": "3211551",
      "hash": "fddd097acec6a55b7f2bb031c543b662d9533f9f",
      "note": "",
      "note_id": "0",
      "self_analysis": "",
      "ptype": "4"
    }
  ],
  "time": "1661177714",
  "encrypt": "VY2rgrsMJ2Azq3Wd9jcp9T=="
}