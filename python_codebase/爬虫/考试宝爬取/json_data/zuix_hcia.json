{"code": "200", "data": [{"id": "293776117", "hash": "e70060d158fcab7e767c3a013184be1fe5845424", "uid": "1090076", "paperid": "3631725", "question": " 在有N个节点Fusioninsight HD集群中部署HBase时,推荐部署__个HMaster进程,__个RegionServer进程。", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 3,N\"},{\"Key\":\"B\",\"Value\":\" N,N\"},{\"Key\":\"C\",\"Value\":\" 2,N\"},{\"Key\":\"D\",\"Value\":\" 2,2\"}]", "answer": "C", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776071", "hash": "e29e4319b4a163e7b8f75c5f43f8cacb14afa57a", "uid": "1090076", "paperid": "3631725", "question": "以下哪一项不属于创建Loader作业时必选项?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 名称\"},{\"Key\":\"B\",\"Value\":\" 连接\"},{\"Key\":\"C\",\"Value\":\" 类型\"},{\"Key\":\"D\",\"Value\":\" 优先级\"}]", "answer": "D", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775860", "hash": "1d9681932509857571af3c4adde093c31c37a3cb", "uid": "1090076", "paperid": "3631725", "question": " 以下关于大数据和传统数据库故据的特点描述不正确的是?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 大数据是对 “池塘中的鱼” 进行数据处理,目标明确;传统数据库的数据处理,是通过某些 “鱼” 判断其他种类的” 鱼” 是否存在\"},{\"Key\":\"B\",\"Value\":\" 大数据处理的数据类型很多,包括结构化、非结构化和半培构化的数据;传统故据库的故据类型较为单一,常以结构化数据为主\"},{\"Key\":\"C\",\"Value\":\" 在大数据中,并没有统一的数据工具,即\\\"No size fits all\\\";在传统数据库中,在某种特定业务场景下,常常一个工具就能解决某个问题,即 “One size fits all\\\"\"},{\"Key\":\"D\",\"Value\":\" 大数据的数据规模很大,一般以TB、PB作为数据处理单位;传统数据库中数据规模一般较小,常以MB作为数据处理单位\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776104", "hash": "32d0c64041e75d197c8a603923d7c086799e75f5", "uid": "1090076", "paperid": "3631725", "question": "下图为Spark&amp;MapReduce的性能对比数据,可以得出结论,与MapReduce计算相比,Spark用____的资源,获得____倍性能?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 1\\/8,3\"},{\"Key\":\"B\",\"Value\":\" 1\\/10,3\"},{\"Key\":\"C\",\"Value\":\" 1\\/10,4\"},{\"Key\":\"D\",\"Value\":\" 1\\/8,4\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776171", "hash": "ef90a4d9b7869006655e9bb23694bc4af11b1243", "uid": "1090076", "paperid": "3631725", "question": " Hive不适用于以下哪个场景?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 实时的在线数据分析\"},{\"Key\":\"B\",\"Value\":\" 非实时分析,例如日志分析,统计分析\"},{\"Key\":\"C\",\"Value\":\" 数据挖掘,例如用户行为分析,兴趣分区,区域展示\"},{\"Key\":\"D\",\"Value\":\" 数据汇总,例如每天、每周用户点击数,点击排行\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776031", "hash": "f221d10fccf9aef2d3af117a917a16407f137509", "uid": "1090076", "paperid": "3631725", "question": "在Zookeeper和YARN的协同工作中,当Active ResourceManager产生故障时 ,Standby ResourceManager会从以下哪个目录中获取Application相关信息?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" warehouse\"},{\"Key\":\"B\",\"Value\":\" Meta store\"},{\"Key\":\"C\",\"Value\":\" State store\"},{\"Key\":\"D\",\"Value\":\" Storage\"}]", "answer": "C", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775942", "hash": "6164e587c061461e8d18242157b4268e306a3697", "uid": "1090076", "paperid": "3631725", "question": "Hadoop中MapReduce组件擅长处理哪种场景的计算任务?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 迭代计算\"},{\"Key\":\"B\",\"Value\":\" 离线计算\"},{\"Key\":\"C\",\"Value\":\" 实时交互计算\"},{\"Key\":\"D\",\"Value\":\" 流式计算\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775920", "hash": "bdf7b36dd7d04f7284accd158caff97071ad3957", "uid": "1090076", "paperid": "3631725", "question": " Fusioninsight Manager对服务的配置功能说法不正确的是?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 服务级别的配置可対所有实例生效\"},{\"Key\":\"B\",\"Value\":\" 实例级别的配置只针对本实例生效\"},{\"Key\":\"C\",\"Value\":\" 实例级别的配置对其他实例也生效\"},{\"Key\":\"D\",\"Value\":\" 配置保存好需要重启服务才能生效\"}]", "answer": "C", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776173", "hash": "3f5fdd26817af22f172b9086447695b18dbf8f2c", "uid": "1090076", "paperid": "3631725", "question": " HBase命令中下列哪个选项性能最差", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" put\"},{\"Key\":\"B\",\"Value\":\" get\"},{\"Key\":\"C\",\"Value\":\" list\"},{\"Key\":\"D\",\"Value\":\" Scan\"}]", "answer": "C", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775932", "hash": "422f5d0a69746a278962cff6b7365062bb6c32e3", "uid": "1090076", "paperid": "3631725", "question": "Fusioninsight Manager用户权限管理不支持哪个配置?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 给用户配置角色\"},{\"Key\":\"B\",\"Value\":\" 给角色配置权限\"},{\"Key\":\"C\",\"Value\":\" 给用户组配置角色\"},{\"Key\":\"D\",\"Value\":\" 给用户组配置权限\"}]", "answer": "D", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775956", "hash": "102d7642d7356ec47a91deb83722d9b512eea1c0", "uid": "1090076", "paperid": "3631725", "question": "Hadoop中哪个模块负责HDFS的数据存储?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" NameNode\"},{\"Key\":\"B\",\"Value\":\" Data Node\"},{\"Key\":\"C\",\"Value\":\" ZooKeeper\"},{\"Key\":\"D\",\"Value\":\" JobTraoker\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776075", "hash": "0b16e3eeb5d6324208884fd7e63bc6a45c85b002", "uid": "1090076", "paperid": "3631725", "question": " Fusioninsight HD的HBase中保存一张用户信息表meg_table,Rowkey为用户id,其中一列为用户昵称,现在按先后顺序往这列写入三个KeyValue: 001:Li,001:Mary,001:Lily,请问scan' meg_table', (VERSION=>2)会返回哪几条数据?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 001:Lily\"},{\"Key\":\"B\",\"Value\":\" 001:Li\"},{\"Key\":\"C\",\"Value\":\" 001:Mary,001:Lily\"},{\"Key\":\"D\",\"Value\":\" 001:Li,001:Mary,00l:Lily\"}]", "answer": "D", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776063", "hash": "be9baa1ec35076e109336d3f73c83e1b7ed5bbd7", "uid": "1090076", "paperid": "3631725", "question": "为了提高kafka的容错性,kafka支持partition的复制策略,以下关于Leader partition和Follower partition的描述错误的是?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 一个kafka集群各个节点间不可能互为leader和 flower\"},{\"Key\":\"B\",\"Value\":\" 如果leader失效,那么将会有其他Follower来接管(成为新的leader)\"},{\"Key\":\"C\",\"Value\":\" 由于leader Server承载了全部的请求压力,因此从集群的整体考虑,kafka会将leader均衡的分散在每个实例上,来确保整体的性能稳定\"},{\"Key\":\"D\",\"Value\":\" Kafka针对partition的复制需要选出一个leader,由该leader负责partition的读写操作,其他的副本节点只是负责数据的同步\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775979", "hash": "d7d65e3e039cc60c26d02a84453ff27c59f80a57", "uid": "1090076", "paperid": "3631725", "question": "以下关于Kafka partition偏移量的描述不正确的是?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 消费者通过(offset、partition、topic)跟踪记录\"},{\"Key\":\"B\",\"Value\":\" 唯一标记一条消息\"},{\"Key\":\"C\",\"Value\":\" offset是一个String型字符串\"},{\"Key\":\"D\",\"Value\":\" 每条消息在文件中的位置称为offset(偏移量)\"}]", "answer": "C", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776150", "hash": "b25352dd42a63a1ebe6d461e9507610a933c19de", "uid": "1090076", "paperid": "3631725", "question": "Hive中的这条命令“ALTER TABLEemployee1ADDcolumns(columnlstring);”是什 么含义?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 删除表\"},{\"Key\":\"B\",\"Value\":\" 增加列\"},{\"Key\":\"C\",\"Value\":\" 创建表\"},{\"Key\":\"D\",\"Value\":\" 修改文件格式\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776037", "hash": "e4b86c00d0144b256c97b4258269093d5317f9f4", "uid": "1090076", "paperid": "3631725", "question": "关于DataSet,下列说法不正确的是?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" DataSet是一个由特定域的对象组成的强类型集合\"},{\"Key\":\"B\",\"Value\":\" DataSet不需要反串行化就可执行大部分操作\"},{\"Key\":\"C\",\"Value\":\" DataSet执行sort、filter、shuffle等操作需要进行反串行化\"},{\"Key\":\"D\",\"Value\":\" DataSet与RDD高度类似,性能比RDD好\"}]", "answer": "C", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776178", "hash": "83742a4f2211fed46e72a0b96f8d6b34dbf53d04", "uid": "1090076", "paperid": "3631725", "question": " 在Kafka HA中,当Partition对应的L eader宕机时,需要从Follower中选举出新Leader ,具体由以下哪个角色执行?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" Follower\"},{\"Key\":\"B\",\"Value\":\" Controller\"},{\"Key\":\"C\",\"Value\":\" Broker\"},{\"Key\":\"D\",\"Value\":\" Leader\"}]", "answer": "C", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775901", "hash": "b1de5a02eb3df66720808600a3ff6fea5ab99069", "uid": "1090076", "paperid": "3631725", "question": "HBase的最小处理单元是Region,User Region和Region Server之间的路由信息是保存在哪里的?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"<p>Zookeeper<\\/p>\"},{\"Key\":\"B\",\"Value\":\"<p>HDFS<\\/p>\"},{\"Key\":\"C\",\"Value\":\"<p>Master<\\/p>\"},{\"Key\":\"D\",\"Value\":\"<p>meta表<\\/p>\"}]", "answer": "D", "analysis": "", "path": "", "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775875", "hash": "320f6d7ad23f825ff78b3909727d768af191717c", "uid": "1090076", "paperid": "3631725", "question": " 现有server.channels=ch1,设置Channel类型为File Channel,下列配置正确的是?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" server.channels.ch1.type = file\"},{\"Key\":\"B\",\"Value\":\" server.channels.ch1.type = memory\"},{\"Key\":\"C\",\"Value\":\" server.channels.type = memory\"},{\"Key\":\"D\",\"Value\":\" server.channels.type = file\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775906", "hash": "8be330183bf90e402b8d70b59da6e4ec4ae8adac", "uid": "1090076", "paperid": "3631725", "question": "Fusioninsight HD的Streaming对于Zookeeper弱依赖,即使Zookeeper故障Streaming可以正常提供服务。", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 正确\"},{\"Key\":\"B\",\"Value\":\" 错误\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775984", "hash": "129b6fb5831aa761d42a7a639a77255a0e9a16f1", "uid": "1090076", "paperid": "3631725", "question": "某用户需要搭建一个350节点的FusionlnsightHD集群,哪种规划方案最佳?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 管理节点、控制节点、数据节点合一部署,二层组网\"},{\"Key\":\"B\",\"Value\":\" 管理节点、控制节点合一部署、数据节点独立部署,二层组网\"},{\"Key\":\"C\",\"Value\":\" 管理节点、控制节点、数据节点都独立部署,三层组网\"},{\"Key\":\"D\",\"Value\":\" 管理节点、数据节点合一部署,控制节点独立部署,二层组网\"}]", "answer": "C", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "475293797", "hash": "45de6d4ff83b24dbb3781bfd6155d909895d7237", "uid": "1090076", "paperid": "3631725", "question": "以下描述哪些不是传统数据处理的瓶颈？", "chapter": "0", "difficulty": "1", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"<p>流数据的实时写入<\\/p>\"},{\"Key\":\"B\",\"Value\":\"<p>海量数据的高存储成本<\\/p>\"},{\"Key\":\"C\",\"Value\":\"<p>缺乏流式数据处理能力<\\/p>\"},{\"Key\":\"D\",\"Value\":\"<p>数据批量处理性能不足<\\/p>\"}]", "answer": "A", "analysis": "", "path": "", "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}", "created_at": "2022-05-14 07:42:54", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775830", "hash": "c59441eee630800b5fe16ac8d2d05773b198908d", "uid": "1090076", "paperid": "3631725", "question": "下面哪一个是ElasticSearch的节点?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" EsNode\"},{\"Key\":\"B\",\"Value\":\" Index\"},{\"Key\":\"C\",\"Value\":\" EsMaster\"},{\"Key\":\"D\",\"Value\":\" Cluster\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776140", "hash": "d573b9a160b432d73ea84852ff0b284f0bb257e9", "uid": "1090076", "paperid": "3631725", "question": " 以下关于ZooKeeper关键特性中的原子性说 法正确的是", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 客户端发送的更新会按照他们被发送的顺序进行 应用\"},{\"Key\":\"B\",\"Value\":\" 更新只能全部完成或失败,不会部分完成\"},{\"Key\":\"C\",\"Value\":\" 一条消息被一个server接收,将被所有server接 收\"},{\"Key\":\"D\",\"Value\":\" 集群中无论哪台服务器,对外展示的均是同一视图\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775969", "hash": "e2cde5bae408d0d284411f9f6023ac379b56ae3e", "uid": "1090076", "paperid": "3631725", "question": " Hadoop平台中HBase的Region是由哪个服务进程来管理?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" HMaster\"},{\"Key\":\"B\",\"Value\":\" DataNode\"},{\"Key\":\"C\",\"Value\":\" RegionServer\"},{\"Key\":\"D\",\"Value\":\" Zookeeper\"}]", "answer": "C", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776182", "hash": "7422d75b50ebe91821fcfab95bc13370f92d55a8", "uid": "1090076", "paperid": "3631725", "question": "在DGC平台架构下提供提供企业级的元数据管理。数据资产管理可视,支持钻取、溯源等。通过数据地图,实现数据资产的数据血缘和数据全景可视,提供数据智能搜索和运营监控的模块是哪个?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 数据开发\"},{\"Key\":\"B\",\"Value\":\" 数据资产管理\"},{\"Key\":\"C\",\"Value\":\" 规范设计\"},{\"Key\":\"D\",\"Value\":\" 数据集成\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775913", "hash": "30c590d14bb533a19e1370d8d684856d821f27df", "uid": "1090076", "paperid": "3631725", "question": " 华为Fusioninsight HD系统中关于HDFS的DataNode的说法正确的是?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 不会检査数据的有效性\"},{\"Key\":\"B\",\"Value\":\" 周期性地将本节点的Block相关信息发送给NameNode\"},{\"Key\":\"C\",\"Value\":\" 不同的DataNode存储的Block一定是不同的\"},{\"Key\":\"D\",\"Value\":\" —个DataNode上的Block可以是相同的\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775987", "hash": "8748b9502e167725262751b6cf7af531beab9177", "uid": "1090076", "paperid": "3631725", "question": "YARN中设置队列QueueA的最大使用资源量,需要配置哪个参数?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" yarn.scheduler.capacity.root.QueueA.user-limit-factor\"},{\"Key\":\"B\",\"Value\":\" yarn.scheduler.capacity.root.QueueA.minimum-user-limit-percent\"},{\"Key\":\"C\",\"Value\":\" yarn.scheduler.capacity.root.QueueA.state\"},{\"Key\":\"D\",\"Value\":\" yarn.scheduler.capacity.root.QueueA.maximum-capacity\"}]", "answer": "D", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775976", "hash": "53af3c61e800e1d773ca53a61259d61ac3fcc7cd", "uid": "1090076", "paperid": "3631725", "question": " SoIrCloud模式是集群模式,在此模式下Solr服务器强依赖于以下哪个服务?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" HBase\"},{\"Key\":\"B\",\"Value\":\" HDFS\"},{\"Key\":\"C\",\"Value\":\" ZooKeeper\"},{\"Key\":\"D\",\"Value\":\" YARN\"}]", "answer": "C", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "475294033", "hash": "af8683c63ab4975a3bae9d060a4496a2bd819e02", "uid": "1090076", "paperid": "3631725", "question": "Zookeeper客户端获取节点数据的命令，以下哪个是正确的？", "chapter": "0", "difficulty": "1", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"<p>&nbsp;1s \\/node <\\/p>\"},{\"Key\":\"B\",\"Value\":\"<p>&nbsp;set \\/node data <\\/p>\"},{\"Key\":\"C\",\"Value\":\"<p>&nbsp;show \\/node <\\/p>\"},{\"Key\":\"D\",\"Value\":\"<p>&nbsp;get \\/node<\\/p>\"}]", "answer": "D", "analysis": "", "path": "", "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}", "created_at": "2022-05-14 07:44:06", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776004", "hash": "d17f9f73cfbc8810b88672e416a702a2b86a910d", "uid": "1090076", "paperid": "3631725", "question": "安装Fusioninsight HD 安装流程正确的是", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 安装Manager->执行preinstall->LLD工具进行配置->安装集群->安装后检査->安装后配置\"},{\"Key\":\"B\",\"Value\":\" LLD工具进行配置->执行preinstall->安装Managers->安装集群->安装后检査->安装后配置\"},{\"Key\":\"C\",\"Value\":\" 安装Manager->LLD工具进行配置->执行preinstall->安装集群->安装后检通->安装后配置\"},{\"Key\":\"D\",\"Value\":\" LLD工具进行配置->执行preinstalls->安装集群->安装Manager->安装后检查->安装后配置\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776055", "hash": "36ff8870efd17e9112382a66b8f170de04c3c712", "uid": "1090076", "paperid": "3631725", "question": " 以下关于Fusioninsight Manager界面Hive日志收集的描述,哪个选项不正确?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 可指定特定用户进行日志收集,例如仅下载UserA 用户产生的日志。\"},{\"Key\":\"B\",\"Value\":\" 可指定时间段进行日志收集,比如只收集2016-1-1到2016-1-10的日志。\"},{\"Key\":\"C\",\"Value\":\" 可指定实例进行日志收集,比如指定收集metstore的日志。\"},{\"Key\":\"D\",\"Value\":\" 可指定节点IP进行日志收集,例如仅下裁某个IP的日志。\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776027", "hash": "d8b84314ac18618f1787404c2586557b239cd633", "uid": "1090076", "paperid": "3631725", "question": "下列选项中,关于Zookeeper可靠性含义说法正确的是?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 可靠性通过主备部署实现\"},{\"Key\":\"B\",\"Value\":\" 可靠性是指更新只能成功或者失败,没有中间状态\"},{\"Key\":\"C\",\"Value\":\" 可靠性是指无论哪个Server对外展示的均是同一个视图\"},{\"Key\":\"D\",\"Value\":\" 可靠性是指一条消息被一个Server接收,它将被所有Server接受\"}]", "answer": "D", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776113", "hash": "8cad7a06bbe2dcba915a56937a27cf65d432de3d", "uid": "1090076", "paperid": "3631725", "question": " 华为Fusioninsight HD是国内首家符合国家金融等圾保护的大数据平台,其安全性现在以下哪些方面?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 系统安全\"},{\"Key\":\"B\",\"Value\":\" 权限认证\"},{\"Key\":\"C\",\"Value\":\" 数据安全\"},{\"Key\":\"D\",\"Value\":\" 以上全部正确\"}]", "answer": "D", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775955", "hash": "45ca982fd773bb35582ac61dfb17d5900ecee914", "uid": "1090076", "paperid": "3631725", "question": "Fusionlnsight HD集群规划中,管理节点&amp;控制节点&amp;数据节点合一部署方案适合什么样的场景?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 30节点以下\"},{\"Key\":\"B\",\"Value\":\" 100节点以上\"},{\"Key\":\"C\",\"Value\":\" 100-200节点\"},{\"Key\":\"D\",\"Value\":\" 200节点以上\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775863", "hash": "e41771336ab7770dc838bcce7789c953ad1c76a5", "uid": "1090076", "paperid": "3631725", "question": " 以下关于Hive特性的描述不正确的是?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 灵活方便的ETL\"},{\"Key\":\"B\",\"Value\":\" 仅支持MapReduce计算引擎\"},{\"Key\":\"C\",\"Value\":\" 可直接访问HDFS文件以及HBase\"},{\"Key\":\"D\",\"Value\":\" 易用易编程\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776012", "hash": "62a886620a80d6713573941bb302a7f5adff7d9e", "uid": "1090076", "paperid": "3631725", "question": "下列选项中适合MapReduce的场景有?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 离线计算\"},{\"Key\":\"B\",\"Value\":\" 实时交互计算\"},{\"Key\":\"C\",\"Value\":\" 迭代计算\"},{\"Key\":\"D\",\"Value\":\" 流式计算\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775944", "hash": "4bb67c1a28e8f3fdf4ac72a27986f14bc9c05051", "uid": "1090076", "paperid": "3631725", "question": "某银行规划的Fusioninsight HD集群有90个节点,如果控制节点规划了3个,那集群中数据节点推荐规划(  )个。", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 87\"},{\"Key\":\"B\",\"Value\":\" 85\"},{\"Key\":\"C\",\"Value\":\" 90\"},{\"Key\":\"D\",\"Value\":\" 86\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775862", "hash": "7bc5ac1bdd635ef3294265b66aa353e5d852f3a2", "uid": "1090076", "paperid": "3631725", "question": " MRS的Loader在创建作业时,连接器的作用是?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 配置作业与外部数据源连接方式\"},{\"Key\":\"B\",\"Value\":\" 配置作业与内部数据源连接方式\"},{\"Key\":\"C\",\"Value\":\" 提供优化参数,提高数据导入导出性能\"},{\"Key\":\"D\",\"Value\":\" 确定有转换步骤\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775997", "hash": "8e4111de6977cc954f47a5a90d29f5e9d3359d6c", "uid": "1090076", "paperid": "3631725", "question": " FusionlnsightHD使用HBase客户端批量写入10条数据,某个Regionserver节点上包含该表的2个Region,分别A和B,10条数据中有两条属于A,4条属于B,清问写入这10条数据需要向该 Regionserver发送几次RPC请求?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 1\"},{\"Key\":\"B\",\"Value\":\" 2\"},{\"Key\":\"C\",\"Value\":\" 3\"},{\"Key\":\"D\",\"Value\":\" 4\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "475296232", "hash": "61078fec71c5cc47bc3a97baa4f9bce2ad2c79e8", "uid": "1090076", "paperid": "3631725", "question": "HBase表设计中，列族和RowKey是 表设计的重要内容。下列哪个选项不适合做RowKey？", "chapter": "0", "difficulty": "1", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"<p>手机号<\\/p>\"},{\"Key\":\"B\",\"Value\":\"<p>用户名<\\/p>\"},{\"Key\":\"C\",\"Value\":\"<p>用户ID<\\/p>\"},{\"Key\":\"D\",\"Value\":\"<p>身份证号<\\/p>\"}]", "answer": "B", "analysis": "", "path": "", "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}", "created_at": "2022-05-14 07:48:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776159", "hash": "367253a11d02e0e11167f22b738002c354abb600", "uid": "1090076", "paperid": "3631725", "question": "kafka-clustermirroring工具可以实现以下那 些功能?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" kafka集群数据同步方案\"},{\"Key\":\"B\",\"Value\":\" kafka单集群内数据备份\"},{\"Key\":\"C\",\"Value\":\" kafka单集群内数据恢复\"},{\"Key\":\"D\",\"Value\":\" 以全部不对\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775993", "hash": "e7e702aed2859b216362679c44bffbae0f53d3a6", "uid": "1090076", "paperid": "3631725", "question": "Streaming主要通过Zookeeper提供的以下哪项服务实现事件侦听?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 分布式侦机制\"},{\"Key\":\"B\",\"Value\":\" ACK\"},{\"Key\":\"C\",\"Value\":\" Watcher\"},{\"Key\":\"D\",\"Value\":\" Checkpoint\"}]", "answer": "C", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776144", "hash": "027efec5acf22febc4fb6a7b2394f0b9a016a0b5", "uid": "1090076", "paperid": "3631725", "question": " Hive是基于hadoop的数据仓库软件,可以查 询和管理PB级别的分布式数据。以下关于Hive特性 的描述不正确的是?()", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 仅支持MapReduce计算引擎\"},{\"Key\":\"B\",\"Value\":\" 易用易编程\"},{\"Key\":\"C\",\"Value\":\" 可直接访问HDFS文件以及HBase\"},{\"Key\":\"D\",\"Value\":\" 灵活方便的ETL(extract\\/transform\\/load)\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775900", "hash": "56d76c2e2de3a21634fabf3f8a9270d4ca341cfb", "uid": "1090076", "paperid": "3631725", "question": "HBase中一个Region进行Split操作时,将一个HFile文件真正分开到两个Region的过程发生在以下什么阶段?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" Split过程中\"},{\"Key\":\"B\",\"Value\":\" Flush过程中\"},{\"Key\":\"C\",\"Value\":\" Compaction过程中\"},{\"Key\":\"D\",\"Value\":\" HFile分开过程中\"}]", "answer": "C", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776047", "hash": "74a0c1710a239c6212af1299d5abbf04f6ba6406", "uid": "1090076", "paperid": "3631725", "question": " Fusioninsight HD系统审计日志不可以记录下面哪些操作()", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 删除服务实例\"},{\"Key\":\"B\",\"Value\":\" 启停服务实例\"},{\"Key\":\"C\",\"Value\":\" 手动消除告营\"},{\"Key\":\"D\",\"Value\":\" 査询历史监控\"}]", "answer": "D", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776007", "hash": "ce842f9319c7bfc6770bbe0e39c7292ea803f38c", "uid": "1090076", "paperid": "3631725", "question": "HBase中数据存储的文件格式是什么?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" HFile\"},{\"Key\":\"B\",\"Value\":\" HLog\"},{\"Key\":\"C\",\"Value\":\" TextFile\"},{\"Key\":\"D\",\"Value\":\" SequenceFile\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775943", "hash": "526f571fbe1f3845a2fb2d106c29dffcd4597fe4", "uid": "1090076", "paperid": "3631725", "question": "Fusioninsight HD Manager界面Hive日志收集,那个选项不正确?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 可指定实例进行日志收集, 比如指定单独收集MetaStore的日志\"},{\"Key\":\"B\",\"Value\":\" 可指定时间段进行日志收集,比如只收集2016-1-1到2016-140的日志\"},{\"Key\":\"C\",\"Value\":\" 可指定节点IP进行日志收集,例如仅下载某个IP的日志\"},{\"Key\":\"D\",\"Value\":\" 可指定特定用户进行日志收集,例如仅下载userA用户产生的日志\"}]", "answer": "D", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775902", "hash": "6f3321061c0cbd46a9bbc2ea0b0082284c9ad8d6", "uid": "1090076", "paperid": "3631725", "question": " Fusioninsight HD产品中,关于Kafka的说法不正确的是?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" Kafka强依赖于Zookeeper\"},{\"Key\":\"B\",\"Value\":\" Kafka部署的实例个数不得小于2\"},{\"Key\":\"C\",\"Value\":\" Kafka的服务端可以产生消息\"},{\"Key\":\"D\",\"Value\":\" Consumer作为Kafka的客户端角色进行消息的消费\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775933", "hash": "7e57b8570423137381ef25a62ba9224c68ce72aa", "uid": "1090076", "paperid": "3631725", "question": "HDFS的NameNode节点主备状态管理及元数据文件合并分别由哪两个角色负责?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" ZKFC和备NameNode\"},{\"Key\":\"B\",\"Value\":\" 主NameNode和备NameNode\"},{\"Key\":\"C\",\"Value\":\" ZKFC和主NameNode\"},{\"Key\":\"D\",\"Value\":\" 主NameNode和JournalNode\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776010", "hash": "0451eadbaf4ff5898afe8c169d1666397c729a1d", "uid": "1090076", "paperid": "3631725", "question": "假设每个用户最低资源保障设置为YARN.scheduler.capacity.root.QueueA. minimum-<br class=\"markdown_return\">User-limit-percent=25,则以上说法错误的是", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 第4个用户提交任务时,每个用户最多获得25%的资源\"},{\"Key\":\"B\",\"Value\":\" 第2个用户提交任务时,每个用户最多获得50%的资源\"},{\"Key\":\"C\",\"Value\":\" 第3个用户提交任务时,每个用户最多获得33.33%的资源\"},{\"Key\":\"D\",\"Value\":\" 第5个用户提交任务时,每个用户最多获得20%的资源\"}]", "answer": "D", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776092", "hash": "e5baf6d4452db9a7272d5a51e6bd229f61bcd993", "uid": "1090076", "paperid": "3631725", "question": "为了保障流应用的快照存储的可靠性,快照主要存储在哪里?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" JobManager的内存中\"},{\"Key\":\"B\",\"Value\":\" 可靠性高的单机数据库中\"},{\"Key\":\"C\",\"Value\":\" 本地文件系统中\"},{\"Key\":\"D\",\"Value\":\" HDFS中\"}]", "answer": "D", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776134", "hash": "76ccb832fc4fc1d1ce556c2464a5b3fcebc32e38", "uid": "1090076", "paperid": "3631725", "question": "创建Loader作业时,可以在以下哪个步骤中设置Map数?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 输出\"},{\"Key\":\"B\",\"Value\":\" 输入设置\"},{\"Key\":\"C\",\"Value\":\" 转换\"},{\"Key\":\"D\",\"Value\":\" 基本信息\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775994", "hash": "f1998f13178ecb5cedc12a76b375ea7b6d29da7e", "uid": "1090076", "paperid": "3631725", "question": "Flink中的__接口用于流数据处理,__接口用于批处理?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" Datastream API,DataSet API\"},{\"Key\":\"B\",\"Value\":\" Data batch API,DataStream API\"},{\"Key\":\"C\",\"Value\":\" Stream API,Batch API\"},{\"Key\":\"D\",\"Value\":\" Batch API,Stream API\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776102", "hash": "fd13c169fb83cbba80b056b02e49184d632b9c46", "uid": "1090076", "paperid": "3631725", "question": "关于Hive与传统数据仓库的对比,以下描述错误的是?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" Hive元数据存储独立于数据存储之外,从而解耦合元数据和数据,灵活性高,而传统数据仓库数据应用单一,灵活性低\"},{\"Key\":\"B\",\"Value\":\" Hive基于HDFS存储,理论上存储量可无限扩展,而传统数据仓库存储量会有上限\"},{\"Key\":\"C\",\"Value\":\" 由于Hive的数据存储在HDFS中,所以可以保证数据的高容错,高可靠\"},{\"Key\":\"D\",\"Value\":\" 由于Hive基于大数据平台,所以查询效率比传统数据仓库快\"}]", "answer": "D", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776040", "hash": "d9766a5b7999341c653ba60f406ca5b6128e3e7d", "uid": "1090076", "paperid": "3631725", "question": " 在WebHCat架构中,用户能够通过安全的HTTPS协议执行以下哪些操作", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 执行Hive DDL操作\"},{\"Key\":\"B\",\"Value\":\" 运行MapReduce任务\"},{\"Key\":\"C\",\"Value\":\" 运行Hive HQL任务\"},{\"Key\":\"D\",\"Value\":\" 以上全部正确\"}]", "answer": "D", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775895", "hash": "759b2b42e2497ecf8ccee888d69e609a4f401055", "uid": "1090076", "paperid": "3631725", "question": "HBase元数据Meta Region路由信息保存在哪里?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" Root表\"},{\"Key\":\"B\",\"Value\":\" Zookeeper\"},{\"Key\":\"C\",\"Value\":\" HMaster\"},{\"Key\":\"D\",\"Value\":\" Meta表\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776163", "hash": "f158c08d14691c41bd20ba03bd469695fffb0204", "uid": "1090076", "paperid": "3631725", "question": "哪个不是Flume的channel类型", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" Memory Channel\"},{\"Key\":\"B\",\"Value\":\" File Channel\"},{\"Key\":\"C\",\"Value\":\" JDBC Channel\"},{\"Key\":\"D\",\"Value\":\" HDFS Channel\"}]", "answer": "D", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776048", "hash": "11efe73bd8334f0959c92b57eb31487a2fb48b59", "uid": "1090076", "paperid": "3631725", "question": "在YARN的任务调度流程中,下列哪个是 ApplicationMaster负责的任务?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 申请和领取资源\"},{\"Key\":\"B\",\"Value\":\" 为任务设置好运行环境\"},{\"Key\":\"C\",\"Value\":\" 分配 Container\"},{\"Key\":\"D\",\"Value\":\" 启动Map或Reduce任务\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776026", "hash": "c46b09986278a70213b80f5aa23c0e04916997f8", "uid": "1090076", "paperid": "3631725", "question": " HBase的BloomFilter是用来过滤数据的。", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 正确\"},{\"Key\":\"B\",\"Value\":\" 错误\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775991", "hash": "5e3d43a5859374c09c698779cf3d2240db82f895", "uid": "1090076", "paperid": "3631725", "question": "FusionlnsightHD系统中HDFS的Block默认保存几份?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 3\"},{\"Key\":\"B\",\"Value\":\" 2\"},{\"Key\":\"C\",\"Value\":\" 1\"},{\"Key\":\"D\",\"Value\":\" 不确定\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776039", "hash": "6224a362c53d47b326e473e217409ccf907ba4f8", "uid": "1090076", "paperid": "3631725", "question": " Flink的数据转换操作在以下哪个环节中完成?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" soure\"},{\"Key\":\"B\",\"Value\":\" Transformation\"},{\"Key\":\"C\",\"Value\":\" Sink\"},{\"Key\":\"D\",\"Value\":\" Channel\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775929", "hash": "33bcad39567dbebe0f57e83982198594a2cdb5bc", "uid": "1090076", "paperid": "3631725", "question": " 下面关于ZKFC的说法错误的是?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" ZKFC (ZKFailoverController)作为一个Zookeeper集群的客户端,用来监控NameNode的状态信息\"},{\"Key\":\"B\",\"Value\":\" ZKFC进程需要在NameNode的节点和Zookeeper的Leader节点中部署\"},{\"Key\":\"C\",\"Value\":\" Standby NameNode通过Zookeeper感知Active NameNode的状态,一旦Active NameNode宕机,Standby NameNode就会执行升主操作\"},{\"Key\":\"D\",\"Value\":\" HDFS NameNode的ZKFC连接到Zookeeper,把主机名等信息保存到Zookeeper中\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775910", "hash": "290e1f3f71286a2b298d336330c8b57bd53e64fc", "uid": "1090076", "paperid": "3631725", "question": "YARN服务中,如果要给队列QuqueA设置容量为30%,应该配置哪个参数?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" YARN.scheduler.capacity.root.QueueA.user-limit-factor\"},{\"Key\":\"B\",\"Value\":\" YARN.scheduler.capacity.root.QueueA.minimum-user-limit-percent\"},{\"Key\":\"C\",\"Value\":\" YARN.scheduler.capacity.root.QueueA.capacity\"},{\"Key\":\"D\",\"Value\":\" YARN.scheduler.capacity.root.QueueA.state\"}]", "answer": "C", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775934", "hash": "859b35db2d552321c496c64eb31c41334eccc75a", "uid": "1090076", "paperid": "3631725", "question": " Fusioninsight HD HBase默认使用什么作为其底层文件存储系统?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" HDFS\"},{\"Key\":\"B\",\"Value\":\" Hadoop\"},{\"Key\":\"C\",\"Value\":\" Memory\"},{\"Key\":\"D\",\"Value\":\" MapReduce\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776094", "hash": "2e1e9fc22bc18eac4bb95bf2280aac1294317a4c", "uid": "1090076", "paperid": "3631725", "question": "在Fusioninsight产品中,关于kafka的topic以下描述不正确的是?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" Topic的partition数量可以创建时配置\"},{\"Key\":\"B\",\"Value\":\" 每个topic只能被分成一个partition区\"},{\"Key\":\"C\",\"Value\":\" 每条发布到kafka的消息都有一个类别,这个类别被称为topic也可以理解为一个存储消息的队列\"},{\"Key\":\"D\",\"Value\":\" 每个partition在存储层面对应一个log文件,log文件中记录了所有的消息数据\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "444989142", "hash": "d9f71920448ee3ca78557f2d2bc1e2a80a6dbdfc", "uid": "1090076", "paperid": "3631725", "question": "Fusionlnsight HD系统中如果修改了服务配置项，不进行服务重启，该服务的配置状态是什么状态?（）", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" SYNCHRONIZEDO\"},{\"Key\":\"B\",\"Value\":\" EXPIREDO\"},{\"Key\":\"C\",\"Value\":\" .CONFIGURINGO\"},{\"Key\":\"D\",\"Value\":\" UNKNOWN\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 09:42:32", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776019", "hash": "ac9854370d344b19cfa6b24f3a464a73df04e65c", "uid": "1090076", "paperid": "3631725", "question": "YRAN的基于标签调度,是对下列选项中的哪个进行标签化?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" APPMaster\"},{\"Key\":\"B\",\"Value\":\" ResourceManager\"},{\"Key\":\"C\",\"Value\":\" Container\"},{\"Key\":\"D\",\"Value\":\" NodeManager\"}]", "answer": "D", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775912", "hash": "de80631705415d22ae1b5712c585d78ecb8f8104", "uid": "1090076", "paperid": "3631725", "question": "査看Kafka的某Topic的partition详细信息时,使用如下哪个命令?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" bin\\/kafka-topic.sh -create\"},{\"Key\":\"B\",\"Value\":\" bin\\/kafka-topic.sh -list\"},{\"Key\":\"C\",\"Value\":\" bin\\/kafka-topic.sh -describe\"},{\"Key\":\"D\",\"Value\":\" bin\\/kafka-topic.sh -delete\"}]", "answer": "C", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775834", "hash": "e0566c2170ef62fc1427272de9e8ba628b464dc3", "uid": "1090076", "paperid": "3631725", "question": " 下列哪个不是Flink支持的状态存储()?", "chapter": "0", "difficulty": "2", "qtype": "1", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" FsStateBackend\"},{\"Key\":\"B\",\"Value\":\" RocksDBStateBackend\"},{\"Key\":\"C\",\"Value\":\" MemoryStateBackend\"},{\"Key\":\"D\",\"Value\":\" FileStateBackend\"}]", "answer": "D", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776108", "hash": "ee3338679ba09c483a89f02b387ee2fead2809d4", "uid": "1090076", "paperid": "3631725", "question": "在Streaming的处理节点Bolt中,可以完成以下哪些操作", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 连接运算\"},{\"Key\":\"B\",\"Value\":\" 连接数据库\"},{\"Key\":\"C\",\"Value\":\" 过滤(filter)\"},{\"Key\":\"D\",\"Value\":\" 业务处理\"}]", "answer": "ABCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776020", "hash": "896b75a441dc35ad5a9e4732e733a2c877ca2189", "uid": "1090076", "paperid": "3631725", "question": " MapReduce过程中,以下属于shuffle机制的是?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" partition\"},{\"Key\":\"B\",\"Value\":\" sort\\/merge\"},{\"Key\":\"C\",\"Value\":\" copy\"},{\"Key\":\"D\",\"Value\":\" combine\"}]", "answer": "BC", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293830874", "hash": "a6acfc39fd3a8b292a61e98f81e645282cf1d727", "uid": "1090076", "paperid": "3631725", "question": "\"SELECT aa.salary,bb.address FROM employee aa JoiN SELECT adress FROM employee info where provine= ‘zhejiang’) bb ON aa.nanme=bb.name\" 包含哪些类型的操作?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 创建表\"},{\"Key\":\"B\",\"Value\":\" 导入数据\"},{\"Key\":\"C\",\"Value\":\" 子査询\"},{\"Key\":\"D\",\"Value\":\" JOIN査洵\"}]", "answer": "ABCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 12:10:55", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775963", "hash": "70bee77a77964c4030a6726f5740de52912cad45", "uid": "1090076", "paperid": "3631725", "question": "Fusioninsight家族包含下列哪些子产品", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" Fusioninsight Miner\"},{\"Key\":\"B\",\"Value\":\" Fusioninsight Farmer\"},{\"Key\":\"C\",\"Value\":\" Fusioninsight HD\"},{\"Key\":\"D\",\"Value\":\" GaussDB 200\"}]", "answer": "ABCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775951", "hash": "f95eefe38444816b0162b59e3663258914b1ff97", "uid": "1090076", "paperid": "3631725", "question": "Fusioninsight HD Loader可以将HDFS数据导出到以下哪些目标端?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" SFTP服务器\"},{\"Key\":\"B\",\"Value\":\" FTP服务器\"},{\"Key\":\"C\",\"Value\":\" Oracle数据库\"},{\"Key\":\"D\",\"Value\":\" DB2数据库\"}]", "answer": "ABCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775889", "hash": "5b7c665025d95dfcec9328d9bacfd246363cb90d", "uid": "1090076", "paperid": "3631725", "question": " Flume进程级联时,以下哪些sink类型用于接收上一跳Flume发送过来的消息?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" Avro sink\"},{\"Key\":\"B\",\"Value\":\" Thrift sink\"},{\"Key\":\"C\",\"Value\":\" Hive sink\"},{\"Key\":\"D\",\"Value\":\" Null sink\"}]", "answer": "AB", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775946", "hash": "49318308e98cfa4ad791705256c8a872df0768bf", "uid": "1090076", "paperid": "3631725", "question": " Fusionlnsight HD集群升级,以下描述正确的有?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 升级过程中不可以手工操作主备OMS倒换\"},{\"Key\":\"B\",\"Value\":\" 集群内所有主机的root账户密码保持一致\"},{\"Key\":\"C\",\"Value\":\" 保持网络畅通. 避免因网络问题导致升级异常\"},{\"Key\":\"D\",\"Value\":\" 观察期不能做扩容\"}]", "answer": "ABCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775996", "hash": "9ff707089e02be2d5dd887760dd004b94116ff46", "uid": "1090076", "paperid": "3631725", "question": "从生命周期来看,数据主要经历哪几个阶段?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 数据采集\"},{\"Key\":\"B\",\"Value\":\" 数据存储\"},{\"Key\":\"C\",\"Value\":\" 数据管理\"},{\"Key\":\"D\",\"Value\":\" 数据分析\"},{\"Key\":\"E\",\"Value\":\" 数据呈现\"}]", "answer": "ABCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775909", "hash": "ee7739ae125c394aa9158f05889fedc61c09f7a5", "uid": "1090076", "paperid": "3631725", "question": " Loader提供了哪些方式或接口实现作业管理?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" WEB UI\"},{\"Key\":\"B\",\"Value\":\" Linux命令令行\"},{\"Key\":\"C\",\"Value\":\" REST接口\"},{\"Key\":\"D\",\"Value\":\" Java API\"}]", "answer": "ABCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775962", "hash": "30c571de2be56d520e5d2ec207f63968a31743e0", "uid": "1090076", "paperid": "3631725", "question": "华为大数据产品Fusioninsight HD中的Streaming具有哪些关键特性?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 灵活性\"},{\"Key\":\"B\",\"Value\":\" 可伸缩性\"},{\"Key\":\"C\",\"Value\":\" 容灾能力\"},{\"Key\":\"D\",\"Value\":\" 消息可靠性\"}]", "answer": "ABCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "475300829", "hash": "38e158032ad65ac2e286de7fb789757f79f3ffe3", "uid": "1090076", "paperid": "3631725", "question": "LdapServer是由目录数据库和一套访问协议组成的系统，以下关于LdapServer目录服务系统的描述错误的是哪个？", "chapter": "0", "difficulty": "1", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"<p>LdapServer是基于LDAP标准协议的一种具体开源实现<\\/p>\"},{\"Key\":\"B\",\"Value\":\"<p>LdapServer基于OpenLDAP开源技术实现<\\/p>\"},{\"Key\":\"C\",\"Value\":\"<p>LdapServer以Berkeley DB作为默认的后端数据库<\\/p>\"},{\"Key\":\"D\",\"Value\":\"<p>LDAP提供了动态数据的快速查询方式<\\/p>\"}]", "answer": "ABCD", "analysis": "", "path": "", "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}", "created_at": "2022-05-14 07:56:01", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776041", "hash": "a1a4444649404176ebbb26a8cb2beb0273d0aa06", "uid": "1090076", "paperid": "3631725", "question": " Fusioninsight HD系统中使用Streaming客户端shell命令提交了拓扑之后,使用Strom UI查看发现该拓扑长时间没有处理数据,可能原因有?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" Supervisor是在topology中接收数据然后执行处理的组件\"},{\"Key\":\"B\",\"Value\":\" 拓扑业务存在逻辑错误,提交之后无法正常运行\"},{\"Key\":\"C\",\"Value\":\" 拓扑过于复杂或者并发太大,导致worker启动时间太长,超过Supervisor的等待时间\"},{\"Key\":\"D\",\"Value\":\" Supervisor的slots资源衲耗尽,拓扑提交上去之后分不到slot去启动worker进程\"}]", "answer": "BCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775958", "hash": "523d92009711faef9d21628ed06d49ac67b2ad89", "uid": "1090076", "paperid": "3631725", "question": "Flink的兼容性体现在以下哪些方面?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 能够与Hadoop原有的mappers和reducers混合使用\"},{\"Key\":\"B\",\"Value\":\" YARN能够作为Flink集群的资源调度管理器\"},{\"Key\":\"C\",\"Value\":\" 能够使用Hadoop的格式化输入和输出\"},{\"Key\":\"D\",\"Value\":\" 能够从本地获取数据\"}]", "answer": "ABCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776001", "hash": "a8843bd4c89d4a324aa3581cd99b991df82525a3", "uid": "1090076", "paperid": "3631725", "question": "在华为Fusioninsight HD中,下面哪些组件是Flink强依赖的?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" Kafka\"},{\"Key\":\"B\",\"Value\":\" HDFS\"},{\"Key\":\"C\",\"Value\":\" YARN\"},{\"Key\":\"D\",\"Value\":\" Zookeeper\"}]", "answer": "BCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "475294393", "hash": "445854d866c29613c288c94d61a9f6bf7d34bb8a", "uid": "1090076", "paperid": "3631725", "question": "下列关于Hive基本操作命令的解释正确的是那个？", "chapter": "0", "difficulty": "1", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"<p>alter table T1 rename to T2：\\/\\/将表T11命名为T2<\\/p>\"},{\"Key\":\"B\",\"Value\":\"<p>remove table T1 where id = 1：\\/\\/删除表中符合条件&quot;id =1&quot;的数据。<\\/p>\"},{\"Key\":\"C\",\"Value\":\"<p>&nbsp;drop table if exists T1：\\/\\/删除表T1<\\/p>\"},{\"Key\":\"D\",\"Value\":\"<p>create table if not exists T1 like T2：\\/\\/拷贝T2表，包括表里的数据，并命名为T1<\\/p>\"}]", "answer": "ABD", "analysis": "", "path": "", "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}", "created_at": "2022-05-14 07:46:47", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775857", "hash": "21e16805595bc8a524320b93369f6e230e4e2686", "uid": "1090076", "paperid": "3631725", "question": "华为大数据解决方案中,LadpServer作为目录服务系统,能够实现对大数据平台的账号进行集中管理,以下对于LdapServer表述正确的是", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" LdapServer支持TCP\\/IP协议。\"},{\"Key\":\"B\",\"Value\":\" LdapServer是基于LDAP标准协议的一种具体开源实现。\"},{\"Key\":\"C\",\"Value\":\" LdapServer以Berkelay DB作为默认的后端数据库。\"},{\"Key\":\"D\",\"Value\":\" LdapServer基于OpenLDAP开源技术实现.\"}]", "answer": "ABCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776165", "hash": "8053381ce1dcfe29d769cd0bacfec461dd3554c2", "uid": "1090076", "paperid": "3631725", "question": "在Fusioninsight HD中,以下哪一项不属于Hive的流控特性", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 支持对已建立的总连接数做阈值控制\"},{\"Key\":\"B\",\"Value\":\" 支持对毎个用户已经建立的连接数做阈值控制\"},{\"Key\":\"C\",\"Value\":\" 支持对某个特定用户已建立的连接数做阈值控制\"},{\"Key\":\"D\",\"Value\":\" 支持对单位时间内所建立的连接数做阈值控制\"}]", "answer": "ABD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776139", "hash": "7f643d563601a280359515993352096b9cf75738", "uid": "1090076", "paperid": "3631725", "question": " 在FusionlnsightHD中,Flink主要与以下哪 些组件进行交互", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" zookeeper\"},{\"Key\":\"B\",\"Value\":\" HDFS\"},{\"Key\":\"C\",\"Value\":\" Kafka\"},{\"Key\":\"D\",\"Value\":\" Yarn\"}]", "answer": "ABCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776067", "hash": "36955402f593252aee6fd754bb73ec2be2ed0271", "uid": "1090076", "paperid": "3631725", "question": "在华为大数据解决方案中,hadoop层包含以下哪些组件?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" Miner\"},{\"Key\":\"B\",\"Value\":\" Spark\"},{\"Key\":\"C\",\"Value\":\" Hive\"},{\"Key\":\"D\",\"Value\":\" Flink\"}]", "answer": "BCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "444989144", "hash": "de70591b2428c9432eff7d42b47551f72952af1c", "uid": "1090076", "paperid": "3631725", "question": "系统认证管理系统的结构包含以下哪些部分", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 统一身份认证服务器\"},{\"Key\":\"B\",\"Value\":\" 统一认证管理模块\"},{\"Key\":\"C\",\"Value\":\" 身份信息存储服务器\"},{\"Key\":\"D\",\"Value\":\" 统一会话管理模块\"}]", "answer": "ABC", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 09:42:32", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775874", "hash": "30223af6990da64a018fad7a0aace73dd8713307", "uid": "1090076", "paperid": "3631725", "question": " 对于容量调度器的任务选择,以下说法正确的是?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 最大队列层级优先\"},{\"Key\":\"B\",\"Value\":\" 最小队列层级优先\"},{\"Key\":\"C\",\"Value\":\" 资源回收请求队列优先\"},{\"Key\":\"D\",\"Value\":\" 资源利用量最低的队列优先\"}]", "answer": "BCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775931", "hash": "3376f9d758f5a1554ed41c7ae37b70eed8ae51fd", "uid": "1090076", "paperid": "3631725", "question": "HBase的主要特点有哪些?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 高可靠性\"},{\"Key\":\"B\",\"Value\":\" 高性能\"},{\"Key\":\"C\",\"Value\":\" 面向列\"},{\"Key\":\"D\",\"Value\":\" 可伸缩\"}]", "answer": "ABCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775854", "hash": "655e2023b998369925451d0995a1c1a695e434e9", "uid": "1090076", "paperid": "3631725", "question": " 在大数据时代,企业所面临的挑战有以下哪些?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 企业各部门间数据分散,相同数据在各部门内部存储格式不一致。\"},{\"Key\":\"B\",\"Value\":\" 数据结构多样化。\"},{\"Key\":\"C\",\"Value\":\" 竞争对手的技术进步。\"},{\"Key\":\"D\",\"Value\":\" 散据存在噪音、缺失、存储类型不规范等问题,需要进行大量的数据预处理工作.\"}]", "answer": "ABCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776079", "hash": "6400fc43fdc1962bc272dc78be3c32959dccd604", "uid": "1090076", "paperid": "3631725", "question": "Flume适用于以下哪些场景的数据收集?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" Thrift,Avro,Syslog,Kafka等数据源上收集数据\"},{\"Key\":\"B\",\"Value\":\" 本地文件数据采集\"},{\"Key\":\"C\",\"Value\":\" 应用系统产生的日志采集\"},{\"Key\":\"D\",\"Value\":\" 大量数据的实时数据采集\"}]", "answer": "ABC", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775869", "hash": "5f10ba414d2978d4a75030d119fd978607e6aec7", "uid": "1090076", "paperid": "3631725", "question": "华为Fusioninsight HD行业成功案例都有哪些?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 数字政府\"},{\"Key\":\"B\",\"Value\":\" 智慧园区\"},{\"Key\":\"C\",\"Value\":\" 智能交通\"},{\"Key\":\"D\",\"Value\":\" 金融\"}]", "answer": "ABCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776056", "hash": "6840dd6c7b0bb02facf8ca24f541dfdfb36d4392", "uid": "1090076", "paperid": "3631725", "question": "根据数据流如何在两个Transformation之间传输数据,数据流可以分为哪些类型?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" redistributing流\"},{\"Key\":\"B\",\"Value\":\" 一对一流\"},{\"Key\":\"C\",\"Value\":\" 一対多流\"},{\"Key\":\"D\",\"Value\":\" distributing流\"}]", "answer": "BC", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776080", "hash": "76d8765d2b7a5e30c261ba69c7231f97d019aa4e", "uid": "1090076", "paperid": "3631725", "question": " Structured Streaming在Output阶段可以定义不同的数据写入方式,包括下列哪些方式?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" Append Mode\"},{\"Key\":\"B\",\"Value\":\" Update Mode\"},{\"Key\":\"C\",\"Value\":\" General Mode\"},{\"Key\":\"D\",\"Value\":\" Complete Mode\"}]", "answer": "ABD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775968", "hash": "3e6f4a8584b33e3e98bac99297fdebe69cea2b0f", "uid": "1090076", "paperid": "3631725", "question": "FusionlnsightHD产品中,关于Kafka组件说法正确的有?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 删除Topic时,必须确保Kafka的服务配置delete.topic.enable配置为true\"},{\"Key\":\"B\",\"Value\":\" Kafka安装及运行日志保存路径为\\/srv\\/Bigdata\\/kafka\"},{\"Key\":\"C\",\"Value\":\" ZooKeeper服务不可用会导致Kafka服务不可用\"},{\"Key\":\"D\",\"Value\":\" 必须使用admin用户或Kafka admin组用户进行创建Topic\"}]", "answer": "ACD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776119", "hash": "78432665c0472a557a98c296fb101acc8022690e", "uid": "1090076", "paperid": "3631725", "question": "下图展示了HDFS的标签存储策略,观察下图,HBase的数据会被存储到哪些数据节点上", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" DataNode A\"},{\"Key\":\"B\",\"Value\":\" DataNode B\"},{\"Key\":\"C\",\"Value\":\" DataNode E\"},{\"Key\":\"D\",\"Value\":\" DataNode F\"}]", "answer": "AB", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776008", "hash": "e10dacc45a49b2faccc8612357074a9692b34b86", "uid": "1090076", "paperid": "3631725", "question": "以下选项中,属于HDFS架构关键特性的是?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 健壮机制\"},{\"Key\":\"B\",\"Value\":\" 多方式访问机制\"},{\"Key\":\"C\",\"Value\":\" HA高可靠性\"},{\"Key\":\"D\",\"Value\":\" 元数据持久化机制\"}]", "answer": "ABCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776088", "hash": "213be5d8f245678defdf17c85caf8bab98446941", "uid": "1090076", "paperid": "3631725", "question": "以下属于Streaming的特点旳是?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 数据先存储再计算\"},{\"Key\":\"B\",\"Value\":\" 属于事件驱动\"},{\"Key\":\"C\",\"Value\":\" 延迟低\"},{\"Key\":\"D\",\"Value\":\" 可做连续查询\"}]", "answer": "BCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776176", "hash": "eca4c3003e7d8aeddc148e34a46ce8922f88d1bf", "uid": "1090076", "paperid": "3631725", "question": "对于延迟事件出现时窗口已经关闭并产出了计算结果,以下处理方法不合理的是哪一项?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 将延迟事件收集起来另外处理\"},{\"Key\":\"B\",\"Value\":\" 延迟事件- -定不能忽略计算\"},{\"Key\":\"C\",\"Value\":\" 将延迟事件视为错误消息并丢弃\"},{\"Key\":\"D\",\"Value\":\" 重新激活已经关闭的窗口并重新计算以修正结果\"}]", "answer": "ABCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776034", "hash": "0a70dfb63b6d88438fd72e0365467dd7a3493e99", "uid": "1090076", "paperid": "3631725", "question": "以下关于Kafka Partition副本的特性描述正确的是?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" Follower通过拉取的方式从Leader中同步数据\"},{\"Key\":\"B\",\"Value\":\" 主副本叫做Leader,从副本叫做Follower\"},{\"Key\":\"C\",\"Value\":\" 消费者和生产者都是从Leader中读写数据,也可直接与Follower交互\"},{\"Key\":\"D\",\"Value\":\" 副本以分区为单位。每个分区都有各自的主副本的从副本\"}]", "answer": "ABD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775831", "hash": "b4451bb682bc6cf82bfd5f43d72752fd9bdb2ea9", "uid": "1090076", "paperid": "3631725", "question": "下面哪几种属于ElasticSearch的RESTful请求方式?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" Update\"},{\"Key\":\"B\",\"Value\":\" Delete\"},{\"Key\":\"C\",\"Value\":\" Get\"},{\"Key\":\"D\",\"Value\":\" Post\"}]", "answer": "BCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775908", "hash": "0abc8cac9e173d08b5dd4800d4f0cbdd063e37d3", "uid": "1090076", "paperid": "3631725", "question": "下列哪些组件必须依赖于Zookeeper才能运行?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" HDFS\"},{\"Key\":\"B\",\"Value\":\" HBase\"},{\"Key\":\"C\",\"Value\":\" Spark\"},{\"Key\":\"D\",\"Value\":\" YARN\"}]", "answer": "AB", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775957", "hash": "701bb8976b67240612e35edb6a758aa0e673aad8", "uid": "1090076", "paperid": "3631725", "question": "Fusionlnsight Hadoop集群中,集群规模有70个节点,如果采用推荐部署方案,在管理节点可能存在哪些分区?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" \\/srv\\/BigData\\/zookeeper\"},{\"Key\":\"B\",\"Value\":\" \\/srv\\/BigData\\/dbdata-om\"},{\"Key\":\"C\",\"Value\":\" \\/srv\\/BigData\"},{\"Key\":\"D\",\"Value\":\" \\/srv\\/BigData\\/jumalnode\"},{\"Key\":\"E\",\"Value\":\" \\/srv\\/BigData\\/hadoop\\/data5\"}]", "answer": "ABCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775922", "hash": "1f7c2d7b5cbd59608d60a3123d41e1396c451bc7", "uid": "1090076", "paperid": "3631725", "question": " Fusioninsight Manager与外部平台对接时,支持哪些接口?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" SNMP\"},{\"Key\":\"B\",\"Value\":\" VPN\"},{\"Key\":\"C\",\"Value\":\" BGP\"},{\"Key\":\"D\",\"Value\":\" Syslog\"}]", "answer": "AD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293830877", "hash": "b2a5902de21a5088f6acbc639cad4d756dfd9699", "uid": "1090076", "paperid": "3631725", "question": " 下面哪些属于set类型的命令?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" scard\"},{\"Key\":\"B\",\"Value\":\" sunion\"},{\"Key\":\"C\",\"Value\":\" zcount\"},{\"Key\":\"D\",\"Value\":\" hexists\"}]", "answer": "AB", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 12:10:55", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776085", "hash": "57e3fda7071862cb31fe1ca9815f6e286a02e99f", "uid": "1090076", "paperid": "3631725", "question": "以下关于Kafka Partition说法正确的有", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 引入Partition机制,保证了Kafka的高吞吐能力\"},{\"Key\":\"B\",\"Value\":\" 每个Partition都是有序且不可变的消息队列\"},{\"Key\":\"C\",\"Value\":\" Partition数量决定了毎个consumer group中并发消费者的最大数量\"},{\"Key\":\"D\",\"Value\":\" 毎个Partition在存储层面对应一个log文件\"}]", "answer": "ABCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776179", "hash": "a3fa865a810dbe03433a5b14ae468956be9b31c0", "uid": "1090076", "paperid": "3631725", "question": "ElasticSearch的平 衡算法可应用于哪些场", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 导入数据\"},{\"Key\":\"B\",\"Value\":\" 导出数据\"},{\"Key\":\"C\",\"Value\":\" 减容\"},{\"Key\":\"D\",\"Value\":\" 扩容\"}]", "answer": "ACD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775878", "hash": "6d4d387224687baaabb4409cf5e8284f83e6747b", "uid": "1090076", "paperid": "3631725", "question": "下面哪些属于Redis的优化方法?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 精简键值\"},{\"Key\":\"B\",\"Value\":\" 关闭持久化\"},{\"Key\":\"C\",\"Value\":\" 限制Redis内存大小\"},{\"Key\":\"D\",\"Value\":\" slowlog配置\"}]", "answer": "ABCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775988", "hash": "fde94bcac982ba73ec4e761b5a33c5b2b1c19dd8", "uid": "1090076", "paperid": "3631725", "question": " Fusioninsight HD V100R002C60版本集群中,以下哪些组件需要规划元数据分区?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" HDFS\"},{\"Key\":\"B\",\"Value\":\" Zookeeper\"},{\"Key\":\"C\",\"Value\":\" Streaming\"},{\"Key\":\"D\",\"Value\":\" Redis\"},{\"Key\":\"E\",\"Value\":\" HBase\"},{\"Key\":\"F\",\"Value\":\" Kafka\"}]", "answer": "ABC", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776053", "hash": "9eb739d5197b58427187fe2095b64899532a4610", "uid": "1090076", "paperid": "3631725", "question": "HDFS的基本系统构架中包含下列哪些节点?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" ResourceManager\"},{\"Key\":\"B\",\"Value\":\" NameNode\"},{\"Key\":\"C\",\"Value\":\" NodeManager\"},{\"Key\":\"D\",\"Value\":\" Data Node\"}]", "answer": "BD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775884", "hash": "b243e9d1537a9415e770d08537686ed1c7009f78", "uid": "1090076", "paperid": "3631725", "question": "Fusioninsight Manager会定时备份哪些数据?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" NameNode\"},{\"Key\":\"B\",\"Value\":\" LDAP\"},{\"Key\":\"C\",\"Value\":\" OMS\"},{\"Key\":\"D\",\"Value\":\" DBService\"}]", "answer": "ABCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776028", "hash": "ed6f3cfe44beff393efcb8030a7ae534edbab07a", "uid": "1090076", "paperid": "3631725", "question": "以下哪些数据源可以通过loader实现与Fusioninsight HD的数据交换?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" MySQL\"},{\"Key\":\"B\",\"Value\":\" NoSQL\"},{\"Key\":\"C\",\"Value\":\" FTP Server\"},{\"Key\":\"D\",\"Value\":\" SFTP Server\"}]", "answer": "ABCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776062", "hash": "e829be2bffca7c7bbc7ecd4ad695b1b3ad31cd35", "uid": "1090076", "paperid": "3631725", "question": " 在Loader历史作业记录中,可以查看以下哪些内容?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 作业状态\"},{\"Key\":\"B\",\"Value\":\" 作业开始\\/运行时间\"},{\"Key\":\"C\",\"Value\":\" 脏数据链接\"},{\"Key\":\"D\",\"Value\":\" 错误行\\/文件数量\"}]", "answer": "ABCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775870", "hash": "4b9c8e6415f3d82612078ff139d74f52b023bdb7", "uid": "1090076", "paperid": "3631725", "question": " 华为DWS能给客户提供哪些服务?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 支持GDS工具,加速数据入库\"},{\"Key\":\"B\",\"Value\":\" 保证数据和系统的高可靠性\"},{\"Key\":\"C\",\"Value\":\" 万亿数据关联分析秒级响应\"},{\"Key\":\"D\",\"Value\":\" 统一管理控制台\"}]", "answer": "ABCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776066", "hash": "4dc46f4a4aa07fb05f08ea114b07e99c3500aca7", "uid": "1090076", "paperid": "3631725", "question": "Spark有哪些特点?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 快\"},{\"Key\":\"B\",\"Value\":\" 巧\"},{\"Key\":\"C\",\"Value\":\" 灵\"},{\"Key\":\"D\",\"Value\":\" 轻\"}]", "answer": "ABCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775887", "hash": "4d872019f351a19fa4ffb1186fef2317255f19a5", "uid": "1090076", "paperid": "3631725", "question": "YARN通过ResourceManager对集群资源进行管理,它的主要功能有?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 集群资源调度\"},{\"Key\":\"B\",\"Value\":\" 应用程序管理\"},{\"Key\":\"C\",\"Value\":\" 日志管理\"},{\"Key\":\"D\",\"Value\":\" 以上说法都不对\"}]", "answer": "AB", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775952", "hash": "6fbade9bb64ea36dce316bd8a03bcfd914330f53", "uid": "1090076", "paperid": "3631725", "question": "下列哪些OS版本被推荐可以用来搭建Fusioninsight V1R2C60集群?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" SUSE11 SP1\\/SP2\\/SP3 for AMD64&amp;lnter64\"},{\"Key\":\"B\",\"Value\":\" CentOS6.6\"},{\"Key\":\"C\",\"Value\":\" Redhat-6.4-x86_64\"},{\"Key\":\"D\",\"Value\":\" RedHat-6.5-x86_64\"},{\"Key\":\"E\",\"Value\":\" RedHat-6.7-x86_64\"},{\"Key\":\"F\",\"Value\":\" Ubuntu6.3\"}]", "answer": "ABCDE", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293830876", "hash": "f063cc9b7baf6272f4770707910527247f0456a6", "uid": "1090076", "paperid": "3631725", "question": "以下关于传统企业面临的数据管理和架构描述正确的是?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 海量数据运维需要保证数据稳定,支持高并发的同时增加服务器负裁。\"},{\"Key\":\"B\",\"Value\":\" 传统的数据库没有考虑数据的多样性,尤其对结构化数据、非结构化数据和半结构化数据兼容。\"},{\"Key\":\"C\",\"Value\":\" 传统的数据库不适合处理PB级别的数据.\"},{\"Key\":\"D\",\"Value\":\" 传统的数据库对数据处理时间要求不高,而大数据需要实时处理数据\"}]", "answer": "ABCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 12:10:55", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776169", "hash": "c0b7f7e6190d618da48b811910f88b2b87b6a6e5", "uid": "1090076", "paperid": "3631725", "question": "数据节点是HDFS的工作节点,以下描述哪些是其功能?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 负责数据的存储和读取\"},{\"Key\":\"B\",\"Value\":\" 根据客 户端或者是名称节点的调度来进行数据的存储和检索\"},{\"Key\":\"C\",\"Value\":\" 记录了 所有针对文件的创建、删除、重命名等操作\"},{\"Key\":\"D\",\"Value\":\" 向名称 节点定期发送自己所存储的块的列表。\"}]", "answer": "ABD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775876", "hash": "6a9cb70cbf6e9b7756bdd148753ffc2450d58c26", "uid": "1090076", "paperid": "3631725", "question": " 以下关于Zookeeper的Leader选举说法正确的是?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 当实例数n为奇数时,假定n=2x+1,则成为leader节点需要x+1票\"},{\"Key\":\"B\",\"Value\":\" Zookeeper选举leader时,需要半数以上的票数\"},{\"Key\":\"C\",\"Value\":\" 当实例数为8时,则成为leader节点需要5票,容灾能力为4\"},{\"Key\":\"D\",\"Value\":\" 当实例数n为奇数时,假定n=2x+1,则成为leader节点需要x票\"}]", "answer": "AB", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776006", "hash": "db30b356a6a27d8fd74e8a1461149f65ad5c8185", "uid": "1090076", "paperid": "3631725", "question": "Loader可以实现以下哪些转换规则", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 空值转换\"},{\"Key\":\"B\",\"Value\":\" 拼接转换\"},{\"Key\":\"C\",\"Value\":\" 长整型时间转换\"},{\"Key\":\"D\",\"Value\":\" 增量转换\"}]", "answer": "ABCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775939", "hash": "4e231a29a400e1d844d92fc752049c132660ce5f", "uid": "1090076", "paperid": "3631725", "question": "Fusioninsight HD的HBase服务包含哪些进程?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" HMaster\"},{\"Key\":\"B\",\"Value\":\" Slave\"},{\"Key\":\"C\",\"Value\":\" HRegionServer\"},{\"Key\":\"D\",\"Value\":\" Data Node\"}]", "answer": "AC", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776018", "hash": "864d57786e63cf89d7095f7e43730f854bec4c7a", "uid": "1090076", "paperid": "3631725", "question": "华为大数据解决方案中平台架构包括以下哪些组成部分?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" Hadoop层\"},{\"Key\":\"B\",\"Value\":\" GaussDB 200\"},{\"Key\":\"C\",\"Value\":\" Datafarm层\"},{\"Key\":\"D\",\"Value\":\" Fusiolnght Manager\"}]", "answer": "ACD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775849", "hash": "b294d17f4beefdb6776c5f6bd8940ca2fdfd7c21", "uid": "1090076", "paperid": "3631725", "question": "以下哪些是Kafka实际的应用场景", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 日志收集\"},{\"Key\":\"B\",\"Value\":\" 网站活性跟踪\"},{\"Key\":\"C\",\"Value\":\" 资源管理\"},{\"Key\":\"D\",\"Value\":\" 聚合统计系统运营数据\"}]", "answer": "ABD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776033", "hash": "6d21435b6acdd6b92a042723974638818cdb9202", "uid": "1090076", "paperid": "3631725", "question": " 如图所示,Flink流式数据处理接口Datastream API支持的语言包括?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" Python\"},{\"Key\":\"B\",\"Value\":\" Java\"},{\"Key\":\"C\",\"Value\":\" C语言\"},{\"Key\":\"D\",\"Value\":\" Scala\"}]", "answer": "BD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775859", "hash": "9fb9927308b7284fd882d8d79be39a781676da64", "uid": "1090076", "paperid": "3631725", "question": " 以下哪些属于企业级大数据应用场景", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 内部运营管理\"},{\"Key\":\"B\",\"Value\":\" 供应链管理\"},{\"Key\":\"C\",\"Value\":\" 客户分析\"},{\"Key\":\"D\",\"Value\":\" 营销分析\"}]", "answer": "ABCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775829", "hash": "d1013c444825ac9593450e42456f38d7e384a57c", "uid": "1090076", "paperid": "3631725", "question": " 以下对于LdapServer组织模型表述正确的是?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 组织单位下不可以定义具体对象。\"},{\"Key\":\"B\",\"Value\":\" LDAPServer目录树中的毎一个节点都被称作条目,并且拥有自己的唯一可区别的名称DN (Distinguished Name) 。\"},{\"Key\":\"C\",\"Value\":\" LDAPServer目录树的树根一般定义域名DC (Domain Component) 。\"},{\"Key\":\"D\",\"Value\":\" LDAPServer目录信息是基于树形结构来进行组织和存储的。\"}]", "answer": "BCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775848", "hash": "6295f1baa7e407f076d17efcedd9585e5cfaab39", "uid": "1090076", "paperid": "3631725", "question": " 华为MRS能够给客户提供的服务有哪些", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 多节点部署\"},{\"Key\":\"B\",\"Value\":\" 统计分析与数据挖据\"},{\"Key\":\"C\",\"Value\":\" 基于Kerberos证的安全控制\"},{\"Key\":\"D\",\"Value\":\" 离线与实时故据处理\"}]", "answer": "ABCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776043", "hash": "a356d7ca8b0bacfc753443d2450086a5599556ed", "uid": "1090076", "paperid": "3631725", "question": " 关于worker(工作进程)、Executor(线程)、task(任务)说法正确的是?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 每个Executor(线程)可以运行参个task(任务)\"},{\"Key\":\"B\",\"Value\":\" 每个Executor(线程)可以运行不同组件(spout或bolt)的task(任务)\"},{\"Key\":\"C\",\"Value\":\" 每个worker可以运行多个Executor(线程)\"},{\"Key\":\"D\",\"Value\":\" 每个worker只能为一个拓扑运行Executor(线程)\"}]", "answer": "ABCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776170", "hash": "ac0d15697dce15e56b87365f8e23e9b083674708", "uid": "1090076", "paperid": "3631725", "question": " 多选 Hive组件 能支持多接口,以下哪个接口是不支持的", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" Beeline\"},{\"Key\":\"B\",\"Value\":\" ODBC\"},{\"Key\":\"C\",\"Value\":\" Restful\"},{\"Key\":\"D\",\"Value\":\" JDBC\"}]", "answer": "ABD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775873", "hash": "700b358313ae65ea6354af1687676b4ff8282bb6", "uid": "1090076", "paperid": "3631725", "question": " Flink支持的时间操作类型包括以下哪些选项?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 结束时间\"},{\"Key\":\"B\",\"Value\":\" 处理时间\"},{\"Key\":\"C\",\"Value\":\" 采集时间\"},{\"Key\":\"D\",\"Value\":\" 事件时间\"}]", "answer": "BD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776016", "hash": "3aac6a4dac93ef4b0bcadcd4c46f84a282903dce", "uid": "1090076", "paperid": "3631725", "question": " Zookeeper可以为Fusioninsight HD中哪些组件提供分布式管理支持?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" HBase\"},{\"Key\":\"B\",\"Value\":\" Loader\"},{\"Key\":\"C\",\"Value\":\" Hive\"},{\"Key\":\"D\",\"Value\":\" Spark\"}]", "answer": "ABCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776072", "hash": "59af6acf6393b98dc5016970a83e998b3aea24ee", "uid": "1090076", "paperid": "3631725", "question": "Hadoop集群规模很大时,数据的分布情况会非常关键,用户需要根据数据分布情况,决定集群是否扩容,数据是否需要做均衡等。以下关于Fusioninsight资源分布监控说法正确的有", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 帮助用户迅速找到资源消耗最高的节点,采用适当的措施\"},{\"Key\":\"B\",\"Value\":\" 通过毎个服务主页的资源分布查看界面,査看到关键的资源分布情况\"},{\"Key\":\"C\",\"Value\":\" 可以帮助用户快速聚集在最关键的资源消耗上\"},{\"Key\":\"D\",\"Value\":\" 通过DashBoard界面,可以查看到主机资源分布情况。例如内存占有率在50-75%的主机列表,并提供链接跳转\"}]", "answer": "ABCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776114", "hash": "7a888648231c9097351380182e81c6ec80ca637f", "uid": "1090076", "paperid": "3631725", "question": "FusininsightHD平台中,那些组件支持对列表加密?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" HDFS\"},{\"Key\":\"B\",\"Value\":\" Flink\"},{\"Key\":\"C\",\"Value\":\" HBase\"},{\"Key\":\"D\",\"Value\":\" Hive\"}]", "answer": "CD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775926", "hash": "f9f95fa11292efc4eb78e35de461a0579eff11e8", "uid": "1090076", "paperid": "3631725", "question": "Fusioninsight HD集群中包含多种服务,每种服务又由若干角色组成,下面哪些是服务的角色?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" HDFS\"},{\"Key\":\"B\",\"Value\":\" NameNode\"},{\"Key\":\"C\",\"Value\":\" DataNode\"},{\"Key\":\"D\",\"Value\":\" HBase\"}]", "answer": "BC", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775865", "hash": "c67d360e9a519bbd3e83ab40ee0825f585815bf7", "uid": "1090076", "paperid": "3631725", "question": "在Fusioninsight产品中,关于创建Kafka的Topic,以下哪些描述是正确的?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 在创建Kafka的Topic时,必须设置Partition个数\"},{\"Key\":\"B\",\"Value\":\" 在创建Kafka的Topic时,必须设置Partition副本个数\"},{\"Key\":\"C\",\"Value\":\" 设置多副本可以増强Kafka服务的容灾能力\"},{\"Key\":\"D\",\"Value\":\" 以上全都正确\"}]", "answer": "ABCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775941", "hash": "d5dd160a360e132b6b025202888f1b019a886784", "uid": "1090076", "paperid": "3631725", "question": "Hadoop的HDFS是一种分布式文件系统,适合以下哪种应用场景的数据存储和管理?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 大量小文件存储\"},{\"Key\":\"B\",\"Value\":\" 高容量、高吞吐量\"},{\"Key\":\"C\",\"Value\":\" 低延迟读取\"},{\"Key\":\"D\",\"Value\":\" 流式数据访问\"}]", "answer": "BD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776083", "hash": "8dd5c8215822e111668efeccf2d888722da8cee5", "uid": "1090076", "paperid": "3631725", "question": "NodeManager的内存和CPU的数量,是通过下列哪些选项进行配置?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" YARN.scheduler.capacity.root.QueueA.maximum-capacity\"},{\"Key\":\"B\",\"Value\":\" YARN.nodemanager.resource.cpu-vcore\"},{\"Key\":\"C\",\"Value\":\" YARN.nodemanager.vmem-pmom-ratio\"},{\"Key\":\"D\",\"Value\":\" YARN.modemanager.resource.memory-mb\"}]", "answer": "BCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776147", "hash": "7c544f731144f4302aac4fb8ee23d8aa40db2c97", "uid": "1090076", "paperid": "3631725", "question": "FusionInsight HD系统中使用Streaming客 户端shell命令查看拓扑或者提交拓扑失败,以下 哪些定位手段的正确的?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 查看Supervisor运行日志,判断是否Supervisor 异常\"},{\"Key\":\"B\",\"Value\":\" 查看worker运行日志\"},{\"Key\":\"C\",\"Value\":\" 查看客户端异常堆栈,判断是否客户端使用问题\"},{\"Key\":\"D\",\"Value\":\" 查看主nimbus的运行日志,判断是否nimbus服 务器异常\"}]", "answer": "ABCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775982", "hash": "f07befac7a2d299444d5f20eb443f98f8ec4d11e", "uid": "1090076", "paperid": "3631725", "question": " 以下关于Fusioninsight中CarbonData说法正确的有?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" carbon也是一种将数据源与spark集成的高性能分析引擎。\"},{\"Key\":\"B\",\"Value\":\" carbon使用轻量级压缩和重量级压缩的组合压缩算法压缩数据,可以减少60%-80%数据存储空间,大大节省硬件存储成本。\"},{\"Key\":\"C\",\"Value\":\" carbon是一种新型的Apache Hadoop本地文件格式,使用先进的列式存储、索引、压缩和编码技术,以提高计算效率,有助于加速超过PB数量级的数据査询,可用于更快的交互査询。\"},{\"Key\":\"D\",\"Value\":\" 使用carbon的目的是对大数据即席查询提供超快速响应。\"}]", "answer": "ABCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776130", "hash": "0d4d05d84b7b50406ac89079cbea41148ab3fda7", "uid": "1090076", "paperid": "3631725", "question": "在Fusioninsight产品中,关于Kafka组件说法正确的是?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 在创建Topic时,副本数不得大于当前存活的Broker实例个数,否则创建Topic将会失败\"},{\"Key\":\"B\",\"Value\":\" Kafka的Producer发送消息时,可以指定该消息被哪个Consumer消费\"},{\"Key\":\"C\",\"Value\":\" Kafka会将元数据信息存放到Zookeeper上\"},{\"Key\":\"D\",\"Value\":\" Kafka安装完成后就不能再配置敏据存放目录\"}]", "answer": "ABCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775947", "hash": "0668c40082db33dfe24b8350f6fcf6bcc82bf701", "uid": "1090076", "paperid": "3631725", "question": " Fusionlnsight HD产品在部署Kerberos和LDAP服务时,以下描述正确的是?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 部署Kerberos服务之前,必须先部署LDAP服务\"},{\"Key\":\"B\",\"Value\":\" LDAP服务必须和Kerberos服务部署在同一个节点\"},{\"Key\":\"C\",\"Value\":\" Kerberos服务和LDAP服务部署同一个节点利于数据访问,有助于性能提升\"},{\"Key\":\"D\",\"Value\":\" LDAP服务可以多个集群共享\"}]", "answer": "AC", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775853", "hash": "f75230c2e765f88956e8cde43d6f841fa0c0c114", "uid": "1090076", "paperid": "3631725", "question": "关于HBase组件的描述正确的是?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 是面向列的\"},{\"Key\":\"B\",\"Value\":\" 是一种NoSQL数据\"},{\"Key\":\"C\",\"Value\":\" 是分布式的\"},{\"Key\":\"D\",\"Value\":\" 存储数据是以K-V的形式\"}]", "answer": "ABCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775839", "hash": "b915d50833d7900032e18e1c156a266232fef5f4", "uid": "1090076", "paperid": "3631725", "question": "下面哪些属于ElasticSearch的扩展插件?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" hadoop\"},{\"Key\":\"B\",\"Value\":\" head\"},{\"Key\":\"C\",\"Value\":\" bigdesk\"},{\"Key\":\"D\",\"Value\":\" IKAnalyzer\"}]", "answer": "ABCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776015", "hash": "c44d35795e80f084a393e7fbaef4dcf42dbc40cf", "uid": "1090076", "paperid": "3631725", "question": "以下关于HBase存储模型的描述正确的是?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" 毎一个KeyValue都拥有一个Qualifier标识\"},{\"Key\":\"B\",\"Value\":\" 同一个key值key关联多个value\"},{\"Key\":\"C\",\"Value\":\" KeyValue中拥有时间戳、类型等关键信息\"},{\"Key\":\"D\",\"Value\":\" 即使是key值相同、Qualifier也相同的多个KeyValue,也可能有多个,此时使用时间戮来区分\"}]", "answer": "ABCD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293776089", "hash": "45f7ca32bc5fbf6bba6d6ccd8581ca9253607301", "uid": "1090076", "paperid": "3631725", "question": "关于Flume,下列说法错误的是?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" Flume级联节点之间的数据传输支持加密\"},{\"Key\":\"B\",\"Value\":\" Flume支持多级联和多路复用\"},{\"Key\":\"C\",\"Value\":\" Source到Channel到Sink等进程内部有加密的必要\"},{\"Key\":\"D\",\"Value\":\" Flume级联节点之间的数据传输不支持压缩\"}]", "answer": "CD", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293775885", "hash": "fab93069c3e715bc49dc052449faeb2f0f184e86", "uid": "1090076", "paperid": "3631725", "question": " Fusioninsight Manager界面显示Hive服务状态为Bad时,可能原因有哪些?", "chapter": "0", "difficulty": "2", "qtype": "2", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\" DBService 不可用\"},{\"Key\":\"B\",\"Value\":\" HDFS服务不可用\"},{\"Key\":\"C\",\"Value\":\" MetaStore实例不可用\"},{\"Key\":\"D\",\"Value\":\" HBase服务不可用\"}]", "answer": "ABC", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:23:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774802", "hash": "6cebf201e88d3c9c8fcbcf49ebdd336caed85ffd", "uid": "1090076", "paperid": "3631725", "question": "Flink与Spark Streaming类似,属于事件驱动型实时流系统", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774907", "hash": "eeb80b66170cb18d47cafb77682f876f05d7f2f3", "uid": "1090076", "paperid": "3631725", "question": "在Flink中,checkpoint机制能够保证应用在 运行过程中出现失效时,从某一个检查点恢复,在 此过程中,流快照是根据数据流入建立的", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774875", "hash": "1b3c9dd3b8f9b08f8495ec2e34924895050a3dc0", "uid": "1090076", "paperid": "3631725", "question": "HFS的出现解决了需要在HDFS中存储大量的小文件(10MB以下)。同时也要存储一些大文件 (10MB以上)的混合的场景", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774815", "hash": "7647e8598d31c98fee34e7237f15921d0da6e793", "uid": "1090076", "paperid": "3631725", "question": "Spark SQL表中,经常会存在很多小文件(大小远小于HDFS块大小),在这种情况下,Spark会启动更多的Task来处理这些小文件,当SQL逻辑中存在Shuffle操作时,会大大增加hash分桶数,从而严重影响性能。    ", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774787", "hash": "676dc70f302bd047d4c42698b13e7477b0c4aabd", "uid": "1090076", "paperid": "3631725", "question": " ElasticSearch可以作为类似于MySQL的关系型数据库使用。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774913", "hash": "fec3cddd82a21439dea8734b73f4481548e974b6", "uid": "1090076", "paperid": "3631725", "question": "MapReduce某- 任务 失败时可通过重试机制重新计算该任务。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774919", "hash": "df981fb90ebf2ef0627e06f69cf339a284a19ce0", "uid": "1090076", "paperid": "3631725", "question": "华为大数据平台中的LdapServer能支持查询、更新、认证等不同类别的操作。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774878", "hash": "2d4da8c4fc8e3c5c5949cd9602c88a1e22d49cb1", "uid": "1090076", "paperid": "3631725", "question": " ResourceManager采用高可用方案,当Active resourcemanager发现故障时,只能通过内置的zookeeper来启动standby的resourcemanager,将其状态切换为active。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774894", "hash": "2b74a6115f33dc81bfa2a6c31c15bf646a70b669", "uid": "1090076", "paperid": "3631725", "question": "Flink适用于高并发处理数据、毫秒级时延的应用    ", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774870", "hash": "659521ec3646b52bc227858af9ee0053a7818085", "uid": "1090076", "paperid": "3631725", "question": " kafka Consumer写数据总体流程是,Consumer连接指定 Topic Partition所在的 Leader Broker,用于主动获取方式从kafka中获取消息。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774789", "hash": "67061bbcdf6a3fb785721f7fc5cd591d6dc5408c", "uid": "1090076", "paperid": "3631725", "question": " 为了考虑性能最优化,建议将所有集群中LdapServer都与KrbServer部署在相同节点上。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774851", "hash": "45c15c10e750fc20e8f024dcf7ca987023849802", "uid": "1090076", "paperid": "3631725", "question": "HDFS支持大文件存储,同时支持多个用户对同一个文件的写操作,以及在文件任意位置进行修改。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774876", "hash": "584b42d50c41f4f0b66c7a31f46529480430cfb5", "uid": "1090076", "paperid": "3631725", "question": "HBase中OpenScanner的过程会创建两种不同的Scanner来读取HFile和MemStore的数据,HFile对应的Scanner为StoreFileScanner,MemStore对应的Scanner为MemStoreScanner。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774766", "hash": "fd0343d5e4356622d94ac71003bc0038353c20fb", "uid": "1090076", "paperid": "3631725", "question": "鲲鹏计算产业是基于Kunpeng处理器构建的全栈IT基础设施、行业应用及服务,包括PC、服务器、存储、操作系统、中间件、虚拟化、数据库、云服务、行业应用以及咨询管理服务等。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774903", "hash": "a2e8d99a615f251573a9a87023a2c1fbaded07ee", "uid": "1090076", "paperid": "3631725", "question": "Redis中的命令是区分大小写的。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774915", "hash": "bd82164816756027c1c36e07edc416f7044692b3", "uid": "1090076", "paperid": "3631725", "question": " Flink不仅能提供同时支持高吞吐和exactly-once语义的实时计算,还能提供批量数据处理。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774793", "hash": "590c0f38cf43e4d874db154b4954b9d3b611ea04", "uid": "1090076", "paperid": "3631725", "question": "在Zookeeper的服务模型中,Leader节点以主备模式存在,其他节点都属于Follower节点。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774853", "hash": "ff22554a2744e55e10aae64a5f772256c8430add", "uid": "1090076", "paperid": "3631725", "question": " Hive是一种数据仓库处理工具,使用类SQL的HiveQL语言实现数据查询功能,所有Hive的数据都存储在HDFS中。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774796", "hash": "7f9d492a2af0c989fafea2c1bcfc4fd182e8517f", "uid": "1090076", "paperid": "3631725", "question": "Fusioninsight HD平台中,HBase暂不支持二级索引", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774761", "hash": "0148370816968112c9d6e41b4af40ac24a9c2529", "uid": "1090076", "paperid": "3631725", "question": " HBase组件中,数据读写服务需要连接Master 执行。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774836", "hash": "5a43adb2406f59e24d70e77b99f5698389cb8821", "uid": "1090076", "paperid": "3631725", "question": "Hadoop的NameNode用于存储文件系统的元数据。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774762", "hash": "27f866395bda1c00620b3bcb4c5a4f2c3833e3e7", "uid": "1090076", "paperid": "3631725", "question": "HiveServer将用户提交的HQL语句进行编译 解析成对应的Yarn任务、Spark任务或者HDPS操 作,从而完成数据的提取、转换、分析。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774837", "hash": "3db53ce07e4e3e73748c0a0ef672c477d1480891", "uid": "1090076", "paperid": "3631725", "question": " 华为Fusioninsight中,HBase的表设计工具、连接池管理和增强的SDK,可以简化复杂数据表的业务开发。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774863", "hash": "430cc15ff137c702e92c469ff82aeb0bc5ea8e42", "uid": "1090076", "paperid": "3631725", "question": "ApplicationMaster采用轮询的方式通过RPC协议向ResourceManager申请和领取资源。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774821", "hash": "547722fdc64c200d4f8b218a5b13e44a54af66c1", "uid": "1090076", "paperid": "3631725", "question": "Spark和Hadoop都不适用于迭代计算的场景。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774805", "hash": "a62b6cad590338845fdc71e7d5df809f40103b49", "uid": "1090076", "paperid": "3631725", "question": "Fusioninsight HD中Loader作业提交到YARN后,作业不能手动停止。   ", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774785", "hash": "f08136b3efd2c88c5ef76f0137eb179fa76d7cbf", "uid": "1090076", "paperid": "3631725", "question": "Spark的中间数据放在内存中,对于迭代运算、批处理计算的效率更高,延迟更高。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774797", "hash": "b532f404cd95201d32a990d0c0aeaaa43c1f37fd", "uid": "1090076", "paperid": "3631725", "question": "Fusioninsight HD中使用HBase进行数据读取服务时需要连接HMaster", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774823", "hash": "585f622e037f89479f12fccffc3291b4419fdda4", "uid": "1090076", "paperid": "3631725", "question": "在Fusioninsight HD系统,Loader作业运行过程中,如果产生脏数据,Loader作业执行结果的状态一定是失败。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774770", "hash": "064a2624f512e89040ead7a1938d7502e8fdfef5", "uid": "1090076", "paperid": "3631725", "question": " Spark和Hadoop—样不适用于送代计算。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774884", "hash": "9966e8857bea45ccea32f5b3d92e1c9ba0894b13", "uid": "1090076", "paperid": "3631725", "question": " 现有3个机架,有一个文件需要存3份,其中副本1和副本2存放在与client相同的机架且不同的服务器上。根据HDFS的副本放置策略一定要存放在其他机架。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774832", "hash": "bcb2a6ce995a2a6923fdd7ffec524c3cf44a97fc", "uid": "1090076", "paperid": "3631725", "question": "Spark Streaming计算基于DStream,将流式计算分解成一系列短小的批处理作业。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774882", "hash": "d03f4231fc14e57d0d909e878607274217aae388", "uid": "1090076", "paperid": "3631725", "question": " Spark根据RDD的依赖关系来划分Stage,调度器从DAG图末端出发,逆向遍历整个依赖关系链,遇到窄依赖就断开,遇到宽依赖就将其加入当前Stage。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774820", "hash": "3a3c013a0b031298b1dea6df190eeac7315c6257", "uid": "1090076", "paperid": "3631725", "question": "如果YARNU群中只有Default、QueueA和QueueB子队列,那么允许将他们的容量分别设置为60%、25%、22%.", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774909", "hash": "927cb6b5f819ea116e509c06753185adadfc51c3", "uid": "1090076", "paperid": "3631725", "question": "Spark任务的一个Executor同时可以运行多个task", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774866", "hash": "a78fb6eb0e5cae9522f7fc83ac3f652c0e12dcca", "uid": "1090076", "paperid": "3631725", "question": " Hive支持普通视图和物化视图。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774791", "hash": "68439a6fa99ff2cd2789e7f85b83b24222910840", "uid": "1090076", "paperid": "3631725", "question": "对高价值高度聚合的信息和知识的批次处理是大数据行业主要商业诉求", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774886", "hash": "900c341483eef7f1463dabd057d5c0a2f31200f2", "uid": "1090076", "paperid": "3631725", "question": " 在YARN的任务调度中.一旦ApplicationMaster申请到资源后,便与对应的 ResourceManager通信,要求它启动任务", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774892", "hash": "e34a962692cbb950eda2f8385e91d91284463b63", "uid": "1090076", "paperid": "3631725", "question": "HDFS联邦机制下,各NameNode间元数据是不共享的。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774868", "hash": "8a2c90fe6f888f92082a5d7819360d4e3dc2790a", "uid": "1090076", "paperid": "3631725", "question": "Channel支持事务,提供较弱的顺序保证,可以连接任何数量的Source和Sink。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "475302867", "hash": "b3d5379a801843232ce2983b653d194f9a57a4b7", "uid": "1090076", "paperid": "3631725", "question": "ElasticSearch的Discovery模块不存在单点故障的问题。", "chapter": "0", "difficulty": "1", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "B", "analysis": "", "path": "", "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}", "created_at": "2022-05-14 07:58:23", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774862", "hash": "ab427ce1c3a4ea798cef1b9e81ff31b94b84f646", "uid": "1090076", "paperid": "3631725", "question": " kafka是一个高吞吐、分布式、基于发布订阅的消息系统,利用kafka技术可在廉价PC Server上搭建起大规模消息系统。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774834", "hash": "c055c6e8fe64b04ce2ef8f58eb561b73dbbb62b6", "uid": "1090076", "paperid": "3631725", "question": "Kerberos只能对集群内的服务提供安全认证。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774775", "hash": "88811134d18aedea54f1a2fc95fe046951e92a0a", "uid": "1090076", "paperid": "3631725", "question": "大数据体量的不断增加,对数据存储的物理安全性要求越来越高,对数据的多副本与容灾机制也提出更高的要求。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774772", "hash": "f8456d714930ba0b0b77d7176a89e45898403995", "uid": "1090076", "paperid": "3631725", "question": "在大数据平台中通过统一用户管理系统,可以实现平台中的各种开源组件应用系统的用户、角色和组织机构统一化管理,实现各种应用系统间跨域的单点登录注销和统一的身份认证功能。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774826", "hash": "375a505e23fff446e0afaa9cc4bae467f5fc4f11", "uid": "1090076", "paperid": "3631725", "question": "Hive在load时是不检查数据是否符合schema的,Hive遵循的是schema on read(读时模式),只有在读的时候Hive才检査、解析具体的数据字段、schema。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774778", "hash": "fd9e4e0ed730c5de1fd41d61cf071520a9af444f", "uid": "1090076", "paperid": "3631725", "question": " Mapreduce过程中,默认情况下,一个分片就是一个块也是一个mapTask.", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774833", "hash": "56b17ef6f7f7a080fcbf86726f12c17cfff478fe", "uid": "1090076", "paperid": "3631725", "question": " Fusioninsight HD系统中,HBase支持动态扩展列。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774911", "hash": "cc6f22ece94488015f535696e363948544cfa326", "uid": "1090076", "paperid": "3631725", "question": "Tez是一个支持有向无环图的分布式计算框. , Hive使用Tez引擎进行数据分析时, 会将用户提交的HQL语句解析成相应的Tez任务并提交Tez执行。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774900", "hash": "11ea96df61262526691183599167fc1bfd792f8d", "uid": "1090076", "paperid": "3631725", "question": " ZooKeeper所有节点都可以处理读请求。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774825", "hash": "6860af5dc4b99f06a0c40843e833353c72915b5a", "uid": "1090076", "paperid": "3631725", "question": "大数据需要传统行业思维的转变,要把数据收集、分析中作为业务流程的重要组成,数据端驱动业务流程优化,实现智能化和自动化,并依托数据资产实现跨界拓展   ", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774828", "hash": "7cc700b09163433b6beedaba9e3452e459f56279", "uid": "1090076", "paperid": "3631725", "question": "topology的处理逻辑都在bolt中。    ", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "475296417", "hash": "069a6271be1091fd9175f340356c979fa225bc07", "uid": "1090076", "paperid": "3631725", "question": "在MapReduce编程中，业务逻辑一般需要自行写代码实现mapper和reducer.", "chapter": "0", "difficulty": "1", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}", "created_at": "2022-05-14 07:49:37", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774856", "hash": "ce54c2bf4399902e149108c96199222526aa9da0", "uid": "1090076", "paperid": "3631725", "question": "假设HDFS在写入数据时只存2份.那么在写入过程中,HDFS Client先将数据写入DataNodel1再将数据写入DataNode2。 ()   ", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774890", "hash": "db12eef090d9a1654b6dfa86781b450fffbd9922", "uid": "1090076", "paperid": "3631725", "question": "Kafka中partition replication之间同步数据,从partition的leader复制数据到follower需要线程(replicationFetcherThread ) ,Follower (一个follower相当于consumer)主动从leader批量拉取消息的,这极大提高了呑吐量。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774861", "hash": "b1ce6a295017e89e1699c00d722a7f633ad5a065", "uid": "1090076", "paperid": "3631725", "question": " Kafka所有消息都会被持久化到硬盘中,同时 Kafka通过对Topic Partitio设置Replicetion来保障数据可靠。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774810", "hash": "b6c533c327ee3f0bcd57d634a71bfd674754bad2", "uid": "1090076", "paperid": "3631725", "question": " Spark应用运行时,如果某个Task运行失败导致整个app运行失败。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774777", "hash": "2fd52b7b35cc765d28462fd0a42de8555e64c2cc", "uid": "1090076", "paperid": "3631725", "question": " Watermark是Apache Flink为了处理 EventTime窗口计算提出的一种机制,本质上是一种时间戳。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774917", "hash": "c39422e5f4db3cab0c8c0b15b9358877b3964c46", "uid": "1090076", "paperid": "3631725", "question": "KrbServer可为其他组件提供了kerberos功能,用于防止窃听、防止replay攻击、 保护数据完整性等场合。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774849", "hash": "b8c030e7c8a982159a0fcee84bc4894c698d8146", "uid": "1090076", "paperid": "3631725", "question": " Fusioninsight HD集群三层组网时,管理节点、控制节点、数据节点建议安装在不同的网段内,可以提高可靠性。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774835", "hash": "4c4402dd2c01a6ad9a6c34c1edcb8b5ef8809f67", "uid": "1090076", "paperid": "3631725", "question": "HBase的最小处理单元是Region,User Region和RegionServer之间的路由信息是保存在Zookeeper中。/", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "B", "analysis": "", "path": "", "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774871", "hash": "ba496042a804333c76b1ca3712cf49127fdee9c9", "uid": "1090076", "paperid": "3631725", "question": " Spark Streaming容错机制是指RDD中任意的partition出错,都可以根据其父RDD重新计算生成,如果父RDD丢失,则需要去磁盘中査找原始数据。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774806", "hash": "590f36054c3d847ede38e835512473fbec29196c", "uid": "1090076", "paperid": "3631725", "question": " Flink支持Local模式和Cluster模式部署,其他模式部罟暂不支持。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774880", "hash": "b103e02cb508237d7661145ab4984377c62adfe7", "uid": "1090076", "paperid": "3631725", "question": "Flume的数据流可以根据headers的信息发送到不同的Channel中。   ", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774891", "hash": "6f9399424f50da29f67acc0e4f174426a879d1c3", "uid": "1090076", "paperid": "3631725", "question": "Hive不支持超时重试试机制。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774896", "hash": "451fb7eb6f08bb59f302f440b8675f2e1b53c345", "uid": "1090076", "paperid": "3631725", "question": "HBase的数据文件HFile中一个KeyValue格式包含Key,Value,TimeStamp,KeyType等内容", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774888", "hash": "37494736f92de1faaaae5be77fe16253e3eec53a", "uid": "1090076", "paperid": "3631725", "question": "容量调度器在进行资源分配,现有同级的2个队列Q1和Q2,他们的容量均为30,其中Q1已使用8,Q2已使用14,则会优先将资源分配Q1。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774767", "hash": "b5de6d3c1cafa85b80ad51f38be70ca4d8fcfec3", "uid": "1090076", "paperid": "3631725", "question": "华为云MapReduce服务提供租户完全可控的 一站式企业级大数据集群云服务,完全兼容开源接 口,结合华为云计算、存储优势及大数据行业经 验,为客户提供高性能、低成本、灵活易用的全栈 大数据平台,轻松运行Hadoop,Spark. HBase, Kafka、Storm等大数据组件,实现实时与离线的分 析挖掘,发现全新企业商机。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774914", "hash": "2f224b983e84b3063e68c1f1fae9e473c7242a76", "uid": "1090076", "paperid": "3631725", "question": " Hive是建立在Hadoop.上的数据仓库基础构架。它提供了一系列的工具,可以用来进行数据提取转化加载(ETL) , 这是一种可以存储、查询和分析存储在Hadoop中的大规模数据的机制。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774893", "hash": "56d3719eba0675f5eaaac0b93e8eb6c56819fa9f", "uid": "1090076", "paperid": "3631725", "question": " Hive在load是不检索数据是否符合schema的,Hive遵循的是schema on read(读时模式)只有在读时模式的时候才检査Hive的数据字段schema。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774846", "hash": "36e36bddbe31b297a4e979c549746c49fc9834c9", "uid": "1090076", "paperid": "3631725", "question": " FusionlnisghtHD集群安装成功后,不允许修改服务、角色和实例的配置。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774908", "hash": "019cf6b602e0eb8da4d8afc286640236b61096b4", "uid": "1090076", "paperid": "3631725", "question": "Hive中的“Group by”指的是通过一定规则 将一个数据集划分成若干个小的数据集,然后针对 若干个小的数据集进行数据分组处理。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774902", "hash": "43e0fd3fa2f0ce3d8f79f2b3e4e36c36bc98ea22", "uid": "1090076", "paperid": "3631725", "question": "HBase的分布式存储的最基本单元是Region。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774807", "hash": "5f948dd09b64b700f74f7ed71626f10733128523", "uid": "1090076", "paperid": "3631725", "question": " Spark是基于内存的计算引擎,所有Spark程序运行过程中的数据只能存储在内存中", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774898", "hash": "5b4cef951b09a6f582e7dd9b12068a013a53361a", "uid": "1090076", "paperid": "3631725", "question": "下图展示了文件A、B、C、D的存放位置,其中A和B具有关联性,它们的存储位置符合Colocation同分布策略。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774843", "hash": "57461870ca0688cd4aa97e3b5e498e1c67498047", "uid": "1090076", "paperid": "3631725", "question": " Kafka Producer读数据总体流程是,Producer连接任意存活的Broker,请求指定topic、partition的leader元数据信息,然后直接与对应的Broker直接连接,发布数据。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774841", "hash": "eea4cb03e1f0489216ee3e4ebf6fa763e2efbfa8", "uid": "1090076", "paperid": "3631725", "question": "Fusioninsight HD部署过程中,执行precheck检查每个节点时必须调用CheckNode. Config配置文件。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774759", "hash": "0b316b51ce4c2676cc1c703b74174db0ff88eab0", "uid": "1090076", "paperid": "3631725", "question": " Spark任务的Container可以运行多个task.", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "B", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774769", "hash": "25cee5e54e73b36ade9867d20fadf0a2fe20d377", "uid": "1090076", "paperid": "3631725", "question": " MRS服务中,Zookeeper服务不可用会导致kafka服务不可用。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293774897", "hash": "16d34ee3657870417d7390aca5b1fae8e5b5dacf", "uid": "1090076", "paperid": "3631725", "question": " Kafka日志的清理方式有两种:delete和 compact。默认值是delete。", "chapter": "0", "difficulty": "2", "qtype": "3", "parentid": "0", "options": "[{\"Key\":\"A\",\"Value\":\"\\u6b63\\u786e\"},{\"Key\":\"B\",\"Value\":\"\\u9519\\u8bef\"}]", "answer": "A", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:21:53", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025802", "hash": "c084a8c7611526db8129b56f8a6c3c69e05d8323", "uid": "1090076", "paperid": "3631725", "question": "YARN中队列的默认资源调度器是( )？ ", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "容量调度器", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025810", "hash": "452cafe7245af4cf956a5ef70dcca47e5121136e", "uid": "1090076", "paperid": "3631725", "question": "在YARN的任务调度流程中，（）是 Application Master负责的任务？ ", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "申请和领取资源", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025808", "hash": "647af6276e4f64a9d637163b0e67f47becd91cad", "uid": "1090076", "paperid": "3631725", "question": "YARN中默认的资源调度器是（） ", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "容量调度器", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025821", "hash": "425d2caf193208db3a7d6f9ae363e6e092c672ac", "uid": "1090076", "paperid": "3631725", "question": "Hive架构中,（）组件负责对表，列再Partition等的元救据进行读写及更新操作 ", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "MetaStore", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025798", "hash": "9f5cc52f08a37e65cd05355f6653baf48060ce23", "uid": "1090076", "paperid": "3631725", "question": " ( )场景不是 Flink组件擅长的？ ", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "数据存储", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025794", "hash": "af4772aea84061d9403010bbf2bd0ea6eec4cfa7", "uid": "1090076", "paperid": "3631725", "question": " Regionserveri故障时，由（）对已故障的 Regionserver上的 Region进行迁移。 ", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "HMaster", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025814", "hash": "0cf683da02b0d5fae6cb7f0ed867aa3c0553dfba", "uid": "1090076", "paperid": "3631725", "question": "某MapReduce程序运行时.AppMaster发生故障。下列哪些选项对该任务描述正确?（）（） ", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "App Master再次启动|任务仍可运行", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293805161", "hash": "d2e09594c093393251800c591b7c7627d82b3c4f", "uid": "1090076", "paperid": "3631725", "question": "HBase通过（  ）快 速判断用户数据不存在。", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "describe", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:48:43", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025829", "hash": "401dcda1cedfd343b8543bea28dc1f3308bd6018", "uid": "1090076", "paperid": "3631725", "question": "Flume用于收集数据,其传输的数据的基本单位是? （）", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "event", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293805148", "hash": "e29565f18508fd5bdec659ec1c48b6a70a3f3993", "uid": "1090076", "paperid": "3631725", "question": "ElasticSearch采用（    ）方式索引数据", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "倒排索引", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:48:43", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025824", "hash": "a47a26a556b38d339612243e797505bd5600d5c3", "uid": "1090076", "paperid": "3631725", "question": " RDD有宽窄依赖,当宽依赖发生时产生（）降低集群性能 ", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "Shuffle", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025811", "hash": "f3faf8b7543f6db0923d4918f81f3ae5c329e03e", "uid": "1090076", "paperid": "3631725", "question": "HDFS的副本放置策略中，同一机架不同的服务器之间的距离是（）？ ", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "2", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025823", "hash": "6aeee84b1c0d19a8c584640b0e365663242dbcbd", "uid": "1090076", "paperid": "3631725", "question": "Flink状态保存主要依靠（）机制，该机制会定时对程序中的状态进行备份。 ", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "Checkpoint", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025800", "hash": "760a5b7d5b4b27ce855c2bcd1f825699c3ce04d8", "uid": "1090076", "paperid": "3631725", "question": "Elasticsearch采用( )方式索引数据 ", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "倒排序，从Value找Key", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293805156", "hash": "10a73fc773e6c5c730b6fd9ec173b47fc467a7b1", "uid": "1090076", "paperid": "3631725", "question": ".Fusioninsight HD系统审计日志不可以记录下面哪些操作()", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "査询历史监控", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:48:43", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025818", "hash": "043263194a82df67ac7ad9f9ad0f55ca96bc15e3", "uid": "1090076", "paperid": "3631725", "question": "Kafka集群包含一个或多个服务实例,这个服务实例被称为（） ", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "Broker", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025817", "hash": "05f670fd4f329490d79c8133a5b82cbe2a32c594", "uid": "1090076", "paperid": "3631725", "question": " HBase要实现数十亿行数百万列的存储规模,需要以下哪个选项支持?() ", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "HDFS", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025807", "hash": "4988b04d2bce870cf579a5ddeaf057e76c45e60b", "uid": "1090076", "paperid": "3631725", "question": "创建 Loader作业时，可以在（）步骤中设置Map数？ ", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "输出", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293805160", "hash": "7ed6e2eef5c14281e6a7b4c1b2397cc53c26f4f9", "uid": "1090076", "paperid": "3631725", "question": "RegionServer故障时,由对已故障的RegionServer上的Region进行迁移。（）", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "HMaster", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:48:43", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025797", "hash": "d3985870ca719238d976b5e8d2eac491fbfa9d8a", "uid": "1090076", "paperid": "3631725", "question": "Redis主要消耗( )物理资源？ ", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "内存", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025826", "hash": "df79afe4b21368cd5ecbfdf8ece0a4a0422e6347", "uid": "1090076", "paperid": "3631725", "question": "Yarn做资源调度时,maptasak 和reduceTask是运行在（）中 ", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "Container", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293805154", "hash": "e44e1d5c526af1894d932b6f47ddae3615b6351b", "uid": "1090076", "paperid": "3631725", "question": "创建Loader作业时,可以在以下哪个步骤中设置Map数?（  ）", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "输出", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:48:43", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293805150", "hash": "c084a8c7611526db8129b56f8a6c3c69e05d8323", "uid": "1090076", "paperid": "3631725", "question": "YARN中队列的默认资源调度器是（   ）", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "容量调度器", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:48:43", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025809", "hash": "3b59614b5564902286d759844523c81386cac549", "uid": "1090076", "paperid": "3631725", "question": "Fusioninsight HD系统审计日志不可以记录（）操作 ", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "查询历史监控", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293805153", "hash": "23b537984f3807b5bcf3c54557790a3e2ec7a814", "uid": "1090076", "paperid": "3631725", "question": "下列选项中无法通过大数据技术实现的是?（  ）", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "商业模式发现", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:48:43", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025822", "hash": "d76cfc05e6df1d2cf8f2771d582ec0ee26ee1b03", "uid": "1090076", "paperid": "3631725", "question": "Flume在传输数据过程中,可以对数据进行简单过滤。主要通过设置（）在Source和Channel之间(写入Channel之前》对不关心的数据进行过滤。 ", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "Interceptor", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025795", "hash": "d2e09594c093393251800c591b7c7627d82b3c4f", "uid": "1090076", "paperid": "3631725", "question": "Hbase通过( )快速判断用户数据不存在。 ", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "describe", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025799", "hash": "3ef8597a62263225cacd616dcf7da743a2cd60a1", "uid": "1090076", "paperid": "3631725", "question": "如果需要由数据生产者决定数据发送给目标Bolt的某一个确定的Task,应选择( )消息发布策略 ", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "直接分组", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293805149", "hash": "b48aba26a9c71455301e8593c1114a12e6ec243b", "uid": "1090076", "paperid": "3631725", "question": "如果想把Key中存储的数字值加1,该使用（   ）命令?", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "incr", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:48:43", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025816", "hash": "58e17b392adc62fa81683d6e7927a2cbe958e92b", "uid": "1090076", "paperid": "3631725", "question": "下列哪些选项是action算子?(）（） ", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "collect|reduce", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025806", "hash": "c0a9df857aae0aeba795f9246e93b44ee36e5617", "uid": "1090076", "paperid": "3631725", "question": "传统数据处理的数据规模旳单位是（）？ ", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "G B", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025819", "hash": "b1f38240ef5122867d3242e5952137171b95692d", "uid": "1090076", "paperid": "3631725", "question": "统一认证的过程中，Kerterosl的所有数据，包含用户的密码。用户的附属信息均需要从（）获取 ", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "Ldap", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025803", "hash": "9ff97c53a226ac28eb2bc54ab3e1384c41cdd036", "uid": "1090076", "paperid": "3631725", "question": "创建 Loader作业中，可以在（）步骤中设置过滤器类型？ ", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "输入设置", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293805158", "hash": "95236426b3ded295ed3f40dd4a129b8588a695b5", "uid": "1090076", "paperid": "3631725", "question": "在YARN的任务调度流程中,下列哪个是 ApplicationMaster负责的任务?（）", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "申请和领取资源", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:48:43", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "475302040", "hash": "99b59a23d25350446086c78cf909a9828e0c1e83", "uid": "1090076", "paperid": "3631725", "question": "在同一个节点上部署多个Elasticsearch实例，可根据不同的（）和端口号来区分不同的Elasticsearch实例。", "chapter": "0", "difficulty": "1", "qtype": "4", "parentid": "0", "options": "[]", "answer": "IP", "analysis": "", "path": "", "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}", "created_at": "2022-05-14 07:58:02", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025796", "hash": "884e99d7d091917dce76751c5baf984d8e3bd218", "uid": "1090076", "paperid": "3631725", "question": "用于记录 Kafka中消息读取位置的是( )： ", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "日志文件", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293805162", "hash": "884e99d7d091917dce76751c5baf984d8e3bd218", "uid": "1090076", "paperid": "3631725", "question": "用于记录Kafka中消息读取位置的是（）", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "日志文件", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:48:43", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025813", "hash": "9c677426ad074c91cbf0e2d556d25e4444e0134e", "uid": "1090076", "paperid": "3631725", "question": " Yarn支持以下哪些调度器（）（）（） ", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "Fair|FIFO|Capacity", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025804", "hash": "20c4541081b2d56490e8be5b1122ffe881b5e689", "uid": "1090076", "paperid": "3631725", "question": "（）创建 Loader作业时必选项？ ", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "优先级", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025815", "hash": "327a9470f2239bab26c1fff86b62f80ee9005add", "uid": "1090076", "paperid": "3631725", "question": "在WebHcat架构中,用户能够通过安全的HITPS协议执行以下哪些操作?（）（）（） ", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "执行Hive DDL操作|运行MapReduace任务|运行Hive HQL任务", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025825", "hash": "dca674f949836a9586928da72ba266a32448b00c", "uid": "1090076", "paperid": "3631725", "question": "Hash类型的值存储了字段和字段值的映射,字段和字段值只能是（） ", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "字符串", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025805", "hash": "23b537984f3807b5bcf3c54557790a3e2ec7a814", "uid": "1090076", "paperid": "3631725", "question": " 下列选项中无法通过大数据技术实现的是（）？ ", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "商业模式发现", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025801", "hash": "b48aba26a9c71455301e8593c1114a12e6ec243b", "uid": "1090076", "paperid": "3631725", "question": "如果想把Key中存储的数字值加1该使用( )命令？ ", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "incr", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293805146", "hash": "d3985870ca719238d976b5e8d2eac491fbfa9d8a", "uid": "1090076", "paperid": "3631725", "question": "Redis主要消耗（    ）物理资源?", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "内存", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:48:43", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025820", "hash": "ef663d154776bcb2af173adddfd5e31064792379", "uid": "1090076", "paperid": "3631725", "question": " Flume中按照数据获取的方式,可将Source分为驱动型Source和（）Source. ", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "轮询", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293805246", "hash": "8d270d711476b3f0e5b353b55a5bf7cfc884d8d6", "uid": "1090076", "paperid": "3631725", "question": "9.传统数据处理的数据规模旳单位是?   （   ）", "chapter": "0", "difficulty": "1", "qtype": "4", "parentid": "0", "options": "[]", "answer": "GB", "analysis": "", "path": "", "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}", "created_at": "2021-12-03 11:49:01", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025827", "hash": "884e99d7d091917dce76751c5baf984d8e3bd218", "uid": "1090076", "paperid": "3631725", "question": "用于记录Kafka中消息读取位置的是（） ", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "日志文件", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025828", "hash": "b7029c75d7ff8ef96554f0c362e08aa4255af8da", "uid": "1090076", "paperid": "3631725", "question": "HBase通过快速判断用户（）数据不存在。 ", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "BloomFilter", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025812", "hash": "731bc58d54d638dfe795509d6cf9ffba89031040", "uid": "1090076", "paperid": "3631725", "question": "Flink运行模式有哪些?（）（）（） ", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "Local模式|Standalone模式|YARN模式", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025792", "hash": "d2e09594c093393251800c591b7c7627d82b3c4f", "uid": "1090076", "paperid": "3631725", "question": "HBase通过（ ）快 速判断用户数据不存在。 ", "chapter": "0", "difficulty": "2", "qtype": "4", "parentid": "0", "options": "[]", "answer": "describe", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025841", "hash": "7fa7a1572bdbefb73e5d550c8340e0a2bd8ec507", "uid": "1090076", "paperid": "3631725", "question": "当某RagionKerver故障后,Haster若要恢复数据必须依赖下列哪个选顶? ", "chapter": "0", "difficulty": "2", "qtype": "5", "parentid": "0", "options": "[]", "answer": "HLog", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025843", "hash": "4aade88bdb15258fc03737633667c84ea59b2dc4", "uid": "1090076", "paperid": "3631725", "question": " F1ink流式处理的数据源类型包括? ", "chapter": "0", "difficulty": "2", "qtype": "5", "parentid": "0", "options": "[]", "answer": "Socket streams|Files|collections", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025839", "hash": "ac3478d69a3c81fa62e60f5c3696165a4e5e6ac4", "uid": "1090076", "paperid": "3631725", "question": "请将MRS中Flume操作步骤按照先后顺序进行正确排序", "chapter": "0", "difficulty": "2", "qtype": "5", "parentid": "0", "options": "[]", "answer": "<p><img src=\"https://up.zaixiankaoshi.com/docs/a5/08/a5083970db0e4d69239ff78d34e59fbb.png\" alt=\"a5083970db0e4d69239ff78d34e59fbb.png\"></p>", "analysis": "", "path": "", "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025831", "hash": "2e39a15fc754e0f6fda0a91812a1f0cd64aa84ab", "uid": "1090076", "paperid": "3631725", "question": " Kafka中日志的清理方式包含以下哪两种? ", "chapter": "0", "difficulty": "2", "qtype": "5", "parentid": "0", "options": "[]", "answer": "delete|compact", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025835", "hash": "fc28413a7d770b7465bccd290cc037b26bc93409", "uid": "1090076", "paperid": "3631725", "question": "HDFS支持通过以下哪些访问方式来访问数据？ ", "chapter": "0", "difficulty": "2", "qtype": "5", "parentid": "0", "options": "[]", "answer": "HTTP|Shell|JAVA AP", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "386859164", "hash": "f5fe56436457600fb8f283868e7af3954e537b9e", "uid": "1090076", "paperid": "3631725", "question": "华为VUE考试须知：<p>1.考试共计60 题，满分 1000 分，考 600 即可通过，考试题型分为：单选 多选 判断 填空拖 拖拽（题库是简答题），各种类型的题目数量不固定，随机抽取；</p><p>2.题库全部掌握后再预约考试，考前一天预约离自己最近的考点即可;</p><p>3.考试题型为单选和多选、判断、填空、拖图，题目不会告知单选还是多选，你可以通过选项判断：单选选项前面是“圆圈”，多选选项前是“方框”；</p><p>4.考试题目和选项均随机乱序；</p><p>5.证件：身份证+（学生证 工作证 信用卡 社保卡护照）其中一个共等2个证件</p><p>6.提前10分钟到达考场 （如遇到特殊情况，迟到可以和考场联系）</p><p>7.考试时长：115分钟，做完即可交卷离开考场；</p><p><br></p><p>华为中兴认证考试题库  微信号：msh-rz888</p>", "chapter": "0", "difficulty": "1", "qtype": "5", "parentid": "0", "options": "[]", "answer": "<p>华为中兴认证考试题库  微信号：msh-rz888</p>", "analysis": "", "path": "", "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}", "created_at": "2022-03-05 08:05:11", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293805147", "hash": "fabfd4cfead6a2f68415f3dd5dcff63dbc22e82a", "uid": "1090076", "paperid": "3631725", "question": "如果需要由数据生产者决定数据发送给目标Bolt的某一个确定的Task,应选择以下哪种消息发布策略", "chapter": "0", "difficulty": "2", "qtype": "5", "parentid": "0", "options": "[]", "answer": "直接分组", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:48:43", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293826886", "hash": "aefe1197cae8d32c7dcdda9f2b931c74d1d095be", "uid": "1090076", "paperid": "3631725", "question": "HDFS数据读取流程包括下面几步，请选择正确的顺序", "chapter": "0", "difficulty": "1", "qtype": "5", "parentid": "0", "options": "[]", "answer": "<p>3----.获得此输入流之后，客户端调用read方法读取数据。输入流选择最近的DataNode建立连接并读取数据。</p><p> 5-----.客户端调用close.关闭输入流。</p><p> 2-----.通过RPC远程调用NameNode获得、NameNode中此文件对应的数据块的保存位置</p><p> 4------.如果已达到数据块末端。那么关闭与这个DataNode的连接，然后重新查找下E.一个数据块。直到数据全部读完。</p><p> 1----.客户端调用FileSystem实例的open方法，获得这个文件对应的输入流。</p>", "analysis": "", "path": "", "extra": "{\"ordered\":\"0\",\"case_sensitive\":\"0\"}", "created_at": "2021-12-03 12:07:05", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293805151", "hash": "7e32e821aa9f122482384416edff5d301a43b066", "uid": "1090076", "paperid": "3631725", "question": "创建Loader作业中,可以在以下哪个步骤中设置过滤器类型?", "chapter": "0", "difficulty": "2", "qtype": "5", "parentid": "0", "options": "[]", "answer": "输入设置", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:48:43", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025837", "hash": "1de450e8221f53ac1adef2fa0638fc0f39b24b0f", "uid": "1090076", "paperid": "3631725", "question": " 在数据流处理过程中,每个事件的时间可以分为以下哪三种? ", "chapter": "0", "difficulty": "2", "qtype": "5", "parentid": "0", "options": "[]", "answer": "procossing time|event time|ingestion time", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025833", "hash": "5f5281951945c624012490471ad374a0c51ca81b", "uid": "1090076", "paperid": "3631725", "question": "以下属于Hive内置的字符串函数有哪些? ", "chapter": "0", "difficulty": "2", "qtype": "5", "parentid": "0", "options": "[]", "answer": "trim|substr|length", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025836", "hash": "7cefea89273c574da688e9f6666980be67777b8f", "uid": "1090076", "paperid": "3631725", "question": "HDFS中,抽象的块可以带来哪些好处? ", "chapter": "0", "difficulty": "2", "qtype": "5", "parentid": "0", "options": "[]", "answer": "适合数据备份|支持大规模文件存储|简化系统设计", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025844", "hash": "4b7e3e947ad8de5e3e73563d62d9cf680c837bbc", "uid": "1090076", "paperid": "3631725", "question": " Flinak的时间窗口根据实现原理的不同可分为以下哪三类窗口? ", "chapter": "0", "difficulty": "2", "qtype": "5", "parentid": "0", "options": "[]", "answer": "滑动窗口(S1iding Window)|滚动窗口(Tumbling Tindow)|会话窗口( Session Window)", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025842", "hash": "920fda10d118cc1c0b04349187c23d4f134fe37c", "uid": "1090076", "paperid": "3631725", "question": "Capacity调度器为每个队列分配资源。下列哪个选项是队列内的资源调度策略 ", "chapter": "0", "difficulty": "2", "qtype": "5", "parentid": "0", "options": "[]", "answer": "FIFO", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "293805152", "hash": "9536f0c33e3114279663755e968f219123d00889", "uid": "1090076", "paperid": "3631725", "question": "以下哪一项不属于创建Loader作业时必选项?", "chapter": "0", "difficulty": "2", "qtype": "5", "parentid": "0", "options": "[]", "answer": "优先级", "analysis": "", "path": "", "extra": "", "created_at": "2021-12-03 11:48:43", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025834", "hash": "f6ca7537daf362cdadc84f6d89204ce80dd5c4ba", "uid": "1090076", "paperid": "3631725", "question": "ElasticSearch扩容的场景包括哪些? ", "chapter": "0", "difficulty": "2", "qtype": "5", "parentid": "0", "options": "[]", "answer": "ElasticSearch单实例的索引数据太大|物理资源消耗过大", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025830", "hash": "df57e12ac0f8bd0a070db4b9e819c92a555f0b0b", "uid": "1090076", "paperid": "3631725", "question": " 以下选项哪些是华为数据中台解决方案? ", "chapter": "0", "difficulty": "2", "qtype": "5", "parentid": "0", "options": "[]", "answer": "AI开发平台ModelArts|视频分析VAS", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025840", "hash": "3115f60bde5a4768e924415aa403ab7a5e93c2a6", "uid": "1090076", "paperid": "3631725", "question": " 若使用Redis对—个有序集合进行排序,哪个数据类型? ", "chapter": "0", "difficulty": "2", "qtype": "5", "parentid": "0", "options": "[]", "answer": "sorted set", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025838", "hash": "5ef111f53e986576f2b806ad7bea9cbbfa2a79b9", "uid": "1090076", "paperid": "3631725", "question": "Flume中数据压缩特性主要是基于以下哪种目的? ", "chapter": "0", "difficulty": "2", "qtype": "5", "parentid": "0", "options": "[]", "answer": "增强安全性", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}, {"id": "445025832", "hash": "932d1d1c22db8becf53971a56138cbe161159a27", "uid": "1090076", "paperid": "3631725", "question": " Kafka分布式消息传递基于可靠的消息队列，包含以下哪两种主要的消息传递模式? ", "chapter": "0", "difficulty": "2", "qtype": "5", "parentid": "0", "options": "[]", "answer": "发布订阅模式|点对点传递模式", "analysis": "", "path": "", "extra": "", "created_at": "2022-04-20 10:04:03", "note": "", "note_id": "0", "self_analysis": "", "ptype": "4"}], "time": "1664258307", "encrypt": "6vKXvD9qRutGE7sfeI5QVq=="}